949622	I'm also using Ubuntu 10.04 and I can connect to my machines using their name. Say I have computers named ernie and bert that are on the same network: ernie:~$ ping bert.local ernie:~$ echo hello > file.txt ernie:~$ scp file.txt bert.local:~/copied-from-ernie.txt You can use this in nautilus too. Enter ssh://bert.local into the nautilus location bar in ubuntu (hit Ctrl-L to select the location bar) and hit enter. If you have different user names use ssh://username@bert.local I think you can do something similar in the Finder location bar. You have to install/enable sshd for this to work: Ubuntu: sudo apt-get install openssh-server (you may need to restart) Mac: System Preferences --> Sharing. Check the "Remote Login" box.
1042982	This was true once, but it isn't anymore. From MS-DOS # Windows command-line interface - Wikipedia: All versions of Microsoft Windows have had an MS-DOS like command-line interface (CLI). This could run many DOS and variously Win32, OS/2 1.x and Posix command line utilities in the same command-line session, allowing piping between commands. The user interface, and the icon up to Windows 2000, followed the native MS-DOS interface. Consumer Windows (up to 3.11, Win9x, WinME) ran as a Graphical User Interface (GUI) running on top of MS-DOS. With Windows 95, 98, and ME the MS-DOS part was integrated, treating both operating systems as a complete package. The command line accessed the DOS command line (usually command.com), through a Windows module (winoldap.mod). A new line of Windows, (Windows NT), boot through a kernel whose sole purpose is to load Windows. One can not run Win32 applications in the loader system in the manner that OS/2, UNIX or Consumer Windows can launch character mode sessions. So no, in every Windows from the NT family (e.g., XP, Vista, 7, 8), the command prompt and MS-DOS are visually similar, but quite different.
1248376	It depends on which windows build you are on, for me in 2018 on Windows 10 Pro 64-bit, Version 1709 (OS Build 16299.522) and also Version 1803 (OS Build 17134.165) the location is still: C:\Users\<username>\AppData\Local\lxss The trick is when you're at C:\Users\<username>\AppData\Local you will not see an lxss folder (unless you happen to have unchecked "Hide protected operating system files (Recommended)" in your folder options). However just append \lxss in the windows explorer address bar and it will take you to the folder. (Note I did not have a %LOCALAPPDATA%\Packages\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc or anything similar that was mentioned in Michael Bonds answer) Update Turns out there is legacy WSL which is what I had installed. Now WSL is provided via a Microsoft store app. There are versions for Ubuntu 18.04 LTS and also now a few other flavors of Linux (e.g. Debian). If you want to be up-to-date you should uninstall legacy WSL and install the Microsoft store version. Where your home folder is will depend on which of these types of WSL you have installed. With the Microsoft store version it will, as mentioned in other answers, be located at: %LOCALAPPDATA%\Packages\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc \LocalState\rootfs
1657693	In addition to other answers: since you want to produce a GIF file, I assume you want to display the image on a web page. If so, I would not bother converting your PNGs at all. Just google for "javascript slideshow" and use one of the millions of free scripts. Or write your own, this is really trivial. The benefits of doing it this way are: only one image is loaded in the browser at any time, the slideshow starts fast and does not consume much RAM on the user's machine. the solution scales to millions of images. Or billions, if you're patient enough to watch them all :) You can add controls to your page to pause, rewind, change the delay or go to a particular frame.
2366388	Speed varies widely by cyclist, depending on fitness, road conditions and traffic. Some of my observations (cruising speed based on a flat, paved road in good condition): 20km/h (12.4 mph) - many "occasional" cyclists ride around this speed 25km/h (15.5 mph) - most commuters 30km/h (18.6 mph) - fast commuters, slower roadies 35km/h (21.7 mph) - fast roadies any faster than that on a long flat and they're probably a racer (based on who I pass and who passes me when riding around 30km/h) Average speed will usually be slower than you think, once traffic stops and hills are factored in, especially over longer distances (like 80km). On my 21km commute I'll hit 30+ on every long stretch I can, but my average still only works out to 24km/h. For longer rides I cruise around 27-28 km/h, which is more sustainable; averaging 22-24 over a very long ride (200km) is a great pace for me.
75667	The first quote you made is from a very low-quality politics forum (GagaDaily). It looks like an ignorant misuse of "infamous". You can't use that word in a "good" way. To use "infamous", about something well-known, is to say that it is a bad thing. It means "wicked, disgraceful, evil, despicable, very wrong" etc. There is no other meaning. To use the word to mean simply "well-known" or "controversial" is an error. To call MLK's well-known speech "infamous" is to make an extremely racist and bigoted utterance. Or possibly just being ignorant. What could be called infamous is Pence's use of the speech to further the ultra-right agenda. Many people think that what Steve King said in July 2016 really was infamous. infamous adjective ​ famous for something considered bad: The list included the infamous George Drake, a double murderer. He's infamous for his bigoted sense of humour. Infamous (Cambridge Dictionary)
630418	I think the models you wrote are not incorrect, although I do wonder why you chose to treat Sites as fixed effects rather than random effects. There is nothing special about these sites, right? For example, you don't care about any differences among these particular 9 sites? If not, they are probably best considered random. 9 is not a lot of levels for a random factor, but hey, I'm sure it's expensive to get a lot of different sites. Since FAM, GEN, and SPEC are explicitly nested in your dataset (e.g., each FAM has its own unique set of GEN labels associated with it), another way to write your models would be: TWL1 <- lmer(TWL ~ SITE + (1|FAM)+(1|GEN)+(1|SPEC)) CPI1 <- lmer(CPI ~ SITE + (1|FAM)+(1|GEN)+(1|SPEC)) ACL1 <- lmer(ACL ~ SITE + (1|FAM)+(1|GEN)+(1|SPEC)) Although, as I hinted above, the models where all effects are random might make more sense: TWL1 <- lmer(TWL ~ (1|SITE)+(1|FAM)+(1|GEN)+(1|SPEC)) CPI1 <- lmer(CPI ~ (1|SITE)+(1|FAM)+(1|GEN)+(1|SPEC)) ACL1 <- lmer(ACL ~ (1|SITE)+(1|FAM)+(1|GEN)+(1|SPEC)) Or even possibly the models where sites are random and the plant categories are fixed? Not sure about these but they seem at least not-obviously-crazy to me: TWL1 <- lmer(TWL ~ FAM + GEN + SPEC + (1|SITE)) CPI1 <- lmer(CPI ~ FAM + GEN + SPEC + (1|SITE)) ACL1 <- lmer(ACL ~ FAM + GEN + SPEC + (1|SITE)) I'm not totally sure what "70% of the basal area" means, but if it implies that future replications of the study would most likely end up with the same set of plant categories (although obviously different individual plants), then maybe this last specification is defensible. But I leave that to your scientific judgment. As for whether you want to compare models using likelihood ratio tests, it really just depends on what you are wanting to know. If your goal is to talk about proportions of variation due to each of the effects in your study, the models with all random effects would probably be easiest because you can compute those proportions simply by taking the ratio of each variance component over the sum of all the variance components.
2247937	The terminology is confusing here, because "major" and "minor" have two different meanings. One meaning is "major and minor scales". The other, which is taken directly from Latin, is that "major" means "big" and "minor" means "small". A "second" means an interval between two successive note-letters in a scale - taking into account any sharps or flats in the scale, of course. In both major and minor scales, there are two different sizes of seconds - one and two semitones wide. The could just be called small seconds and big seconds, but the conventional Latinized names are minor seconds and major seconds. The same naming system applies to thirds, sixths, and sevenths as well. Fourths, fifths, and octaves are different. First, they sound different from the other intervals. Historically, the sound of 4th, 5ths and 8ves was described as "perfect" compared with "imperfect" for all the other intervals. The "perfect" intervals are the same size for almost all positions in major and minor scales. The very few exceptions (like F to B in C major and minor) are called "augmented" or "diminished", which just means "bigger than perfect" and "smaller than perfect". Final note: in the harmonic minor scale, there is one second that is three semitones wide (A flat to B natural, in C harmonic minor). The term "augmented" is used for that, i.e. "bigger than a big second". Similarly, B natural to A flat is "smaller than a small seventh", and called a "diminished" seventh.
2345014	While JACKs suggestion disguises the box well and removes the need for drywall work, it also is a potential code violation and makes it so someone in the future might not even know the box is there (it will look like a return air vent for an hvac system). That said, they make code-friendly covers called "Access Panels" explicitly for this purpose--you can even buy ones with spring clips that allow the panel to be secured directly to the drywall so you don't even have to figure out how to fasten it in place. This solution might not blend in as well as a return air grille since return air ducts in ceilings are more common, but access points to electrical boxes also shouldn't be hidden.
399428	Moaning Myrtle parents (who were Muggles, as she was a victim of the Heir of Slytherin because of that) came to Hogwarts to pick up her body. Therefore, it's technically possible. "Come on, Rubeus," said Riddle, moving yet closer. “The dead girl’s parents will be here tomorrow..." - Chamber of Secrets, CHAPTER THIRTEEN, The Very Secret Diary Weasley's were at Hogwarts both during HBP, and, more importantly, CoS when Ginny was taken to the Chamber: ... moments later, found themselves outside Professor McGonagall’s office. ... It was Mrs. Weasley, who had been sitting crying in front of the fire. She leapt to her feet, closely followed by Mr. Weasley, and both of them flung themselves on their daughter. - Chamber of Secrets, CHAPTER EIGHTEEN, Dobby’s Reward Montague's parents picked him up after being stuck in the Vanishing Cabinet. To cap matters, Montague had still not recovered from his sojourn in the toilet; he remained confused and disorientated and his par-ents were to be observed one Tuesday morning striding up the front drive, looking extremely angry (OotP) I'm sure some of the parents (Cedric's for sure) were spectators for the Tri-Wizard in GoF. While there's no canon info about parents visiting in regular circumstances, it's clear that (1) parents COULD visit, and (2) Muggle parents COULD get in. So, the actual answer is two-fer: We don't know if parent visits were allowed as part of regular school routine in the first place. Based on my experience with American schools, that seems highly discouraged, and I guess Brit schools would be the same. However, IF such visits were allowed for Wizard parents, it's 100% clear Muggle ones could be included in that (and, under a Headmaster like Dumbledore or Minerva, WOULD be included).
545657	The anode is the electrode where the oxidation reaction \begin{align} \ce{Red -> Ox + e-} \end{align} takes place while the cathode is the electrode where the reduction reaction \begin{align} \ce{Ox + e- -> Red} \end{align} takes place. That's how cathode and anode are defined. Galvanic cell Now, in a galvanic cell the reaction proceeds without an external potential helping it along. Since at the anode you have the oxidation reaction which produces electrons you get a build-up of negative charge in the course of the reaction until electrochemical equilibrium is reached. Thus the anode is negative. At the cathode, on the other hand, you have the reduction reaction which consumes electrons (leaving behind positive (metal) ions at the electrode) and thus leads to a build-up of positive charge in the course of the reaction until electrochemical equilibrium is reached. Thus the cathode is positive. Electrolytic cell In an electrolytic cell, you apply an external potential to enforce the reaction to go in the opposite direction. Now the reasoning is reversed. At the negative electrode where you have produced a high electron potential via an external voltage source electrons are "pushed out" of the electrode, thereby reducing the oxidized species $\ce{Ox}$, because the electron energy level inside the electrode (Fermi Level) is higher than the energy level of the LUMO of $\ce{Ox}$ and the electrons can lower their energy by occupying this orbital - you have very reactive electrons so to speak. So the negative electrode will be the one where the reduction reaction will take place and thus it's the cathode. At the positive electrode where you have produced a low electron potential via an external voltage source electrons are "sucked into" the electrode leaving behind the the reduced species $\ce{Red}$ because the electron energy level inside the electrode (Fermi Level) is lower than the energy level of the HOMO of $\ce{Red}$. So the positive electrode will be the one where the oxidation reaction will take place and thus it's the anode. A tale of electrons and waterfalls Since there is some confusion concerning the principles on which an electrolysis works, I'll try a metaphor to explain it. Electrons flow from a region of high potential to a region of low potential much like water falls down a waterfall or flows down an inclined plane. The reason is the same: water and electrons can lower their energy this way. Now the external voltage source acts like two big rivers connected to waterfalls: one at a high altitude that leads towards a waterfall - that would be the minus pole - and one at a low altitude that leads away from a waterfall - that would be the plus pole. The electrodes would be like the points of the river shortly before or after the waterfalls in this picture: the cathode is like the edge of a waterfall where the water drops down and the anode is like the point where the water drops into. Ok, what happens at the electrolysis reaction? At the cathode, you have the high altitude situation. So the electrons flow to the "edge of their waterfall". They want to "fall down" because behind them the river is pushing towards the edge exerting some kind of "pressure". But where can they fall down to? The other electrode is separated from them by the solution and usually a diaphragm. But there are $\ce{Ox}$ molecules that have empty states that lie energetically below that of the electrode. Those empty states are like small ponds lying at a lower altitude where a little bit of the water from the river can fall into. So every time such an $\ce{Ox}$ molecule comes near the electrode an electron takes the opportunity to jump to it and reduce it to $\ce{Red}$. But that does not mean that the electrode is suddenly missing an electron because the river is replacing the "pushed out" electron immediately. And the voltage source (the source of the river) can't run dry of electrons because it gets its electrons from the power socket. Now the anode: At the anode, you have the low altitude situation. So here the river lies lower than everything else. Now you can imagine the HOMO-states of the $\ce{Red}$ molecules as small barrier lakes lying at a higher altitude than our river. When a $\ce{Red}$ molecule comes close to the electrode it is like someone opening the floodgates of the barrier lake's dam. The electrons flow from the HOMO into the electrode thus creating an $\ce{Ox}$ molecule. But the electrons don't stay in the electrode, so to speak, they are carried away by the river. And since the river is such a vast entity (lots of water) and usually flows into an ocean, the little "water" that is added to it doesn't change the river much. It stays the same, unaltered so that everytime a floodgate gets opened the water from the barrier lake will drop the same distance.
551774	A Lewis acid is defined as an electron-pair acceptor. So for something to act as a Lewis acid, it needs to want electrons. Prime examples are $\ce{H+}$, the hardest Lewis acid around (zero polarisability, very high charge per volume ratio) and practically every metal cation out there: $\ce{Al^3+, Zn^2+, Fe^3+, Ag+}$ just to name a few. Consider boron, a rather electropositive element — it counts as a metalloid so it is somewhere between non-metals and metals. We are binding it to fluorine, the most electronegative element, and we’re doing that three times. It should be evident that there is hardly any electron density left on boron. How happy would it be, if some other atom gladly donated their electron pair to share? Now what are we going to do if there is no Lewis base around? Well, initially boron will still be there, depleted of all its valence electrons by fluorine (or nearly at least). This is where fluorine discovers its charity side: All three fluorines donate just a tad of electron density so that the baby boron in the middle will stop crying. This is what you referred to as ‘back bonding’ and Ivan calls ‘mesomeric stabilisation’. But the point is: That doesn’t help against the electron deficiency in any way, it’s more like boron’s final counter-measure against loosing electrons.
661454	In mathematics, "sparse" and "dense" often refer to the number of zero vs. non-zero elements in an array (e.g. vector or matrix). A sparse array is one that contains mostly zeros and few non-zero entries. A dense array contains mostly non-zeros. There's no hard threshold for what counts as sparse; it's a loose term, but can be made more specific. For example, a vector is $k$-sparse if it contains at most $k$ non-zero entries. Another way of saying this is that the vector's $\ell_0$ norm is $k$. The usage of these terms in the context of neural networks is similar to their usage in other fields. In the context of NNs, things that may be described as sparse or dense include the activations of units within a particular layer, the weights, and the data. One could also talk about "sparse connectivity", which refers to the situation where only a small subset of units are connected to each other. This is a similar concept to sparse weights, because a connection with zero weight is effectively unconnected. "Sparse array" can also refer to a class of data types that are efficient for representing arrays that are sparse. This is a concept within the domain of programming languages. It's related to, but distinct from the mathematical concept.
747027	It would help to know what motivates the question, to make sure I'm getting at what you are trying to find out, but here goes: The advisors I have known would wait for the student to bring up a health situation before talking about it. They would consider the overweight in conjunction with other aspects of the student's well-being. Being overweight by itself wouldn't be a concern. If it were accompanied by symptoms of pre-diabetes, heart disease, OCD, depression, etc., then the advisor would be concerned about the big picture (including, but not limited to, the weight problem). The concern would be about the student, not about the group. The gender of the student would be irrelevant. This is my assessment, regarding the advisors I have personally known.
40614	As I understand them, there are some connotations that you might not know as a learner. I have provided pictures of what they could mean, without further context. Cycling. Biking. (Short for mountain biking.) I think there is also the possibility of understanding biking to mean riding motorcycles, the Harley-Davidson types. Ride bicycles. This is what I personally imagine: casual, roadside riding. Ride bikes. Often means 3, but can also mean motorcycle riding. (Motorcycles are sometimes called bikes.) Now 1-4 are what I imagine without context. I suspect you mean something along the lines of 3. So if your audience expects bike-riding, like in 3, then I believe using "Let’s go biking/ride bicycles/ride bikes." should all work fine. I think I would personally say "Let's go bike-riding." Again, it could mean motorcycle, but if your audience expects something like 3, then it should work fine. Bicycle-riding works too.
632897	The real difference between OLS and GLS is the assumptions made about the error term of the model. In OLS we (at least in CLM setup) assume that $Var(u)=\sigma^2 I$, where I is the identity matrix - such that there are no off diagonal elements different from zero. With GLS this is no longer the case (it could be, but then GLS = OLS). With GLS we assume that $Var(u) = \sigma^2 \Sigma$, where $\Sigma$ is the variance-covariance matrix. Many text books introduce GLS with WLS, which is the GLS function that eliminates heteroskedasticity (or tries to). This means that the usual t/F statistics can be valid for the GLS estimation, but not for the OLS. This is less troublesome today, since you can just compute robust variance estimates and base you inference on that - same as you normally would. This implies that difference between OLS and GLS is in the variance of the estimates. And the real reason, to choose, GLS over OLS is indeed to gain asymptotic efficiency (smaller variance for n $\rightarrow \infty$. It is important to know that the OLS estimates can be unbiased, even if the underlying (true) data generating process actually follows the GLS model. If GLS is unbiased then so is OLS (and vice versa). You can very easily proof this, but basically the assumptions for consistency/unbiasedness do not rely on the variance of the estimates at all. A more subtle point is that, unless you know the actual GLS function, it is not unbiased but only consistent. I would therefore argue that choosing between OLS and GLS based on estimates and $R^2$ is the wrong way to think about it. The estimates of both OLS and GLS should be close to one another, if not numerically then in the size of the “impact”. If they are not, then it would most likely indicate that you have a function form misspecification(s), of that you have left out variables. I don’t know whether or not, excluding the GLS weights covariates is justified in your case - but perhaps it worth trying to include them in the OLS estimation and see what happens? It might make the reader less “suspicious” about your conclusion (but this is pure speculation on my part).
1122600	Format - applies to files Protocol - applies to communications In both instances you are talking about the index of various bytes in a stream and what they are supposed to represent. Protocol can get more involved, as many protocols work in a "request-response" fashion where the client issues a well-formed request, and then a server responds with a well-formed response. So there may be different schema for request, response. Requests may change client or server "state" and thus the schema may be different again given a particular state. File formats are typically always following the same schema unless they are a different version, though they can be complex as well - later bytes in a file format may depend on earlier bytes (the .PST file format or the Windows Registry hive format, for example).
2228273	Chemically, they're very different, having to do with carbon chain lengths, the discussion about which will not help you decide. @WedaPashi gave an awesome answer, so, I'll add to it by saying this: First, you must know your stove; I assume you're asking about backpacking stoves who use jets, not generators. If so, the denser fuels (us-kero/uk-paraffin, diesel) require smaller jet holes and shorter jets, which carburate with a lower air mix, whereas the medium fuels (coleman/white gas, gasoline/petrol, aviation fuel) use a slightly larger jet hole, and a slightly longer jet which allows more air mixture. Finally, the lightest fuels (propane, butane, and mixes of each) require larger holes and longest jets, as these fuels are under higher pressures and mix more with air. The reasoning has to do with needing more oxygen to combine with denser chains in the fuels, and you need more oxygen for the lighter fuels. That doesn't help you choose a stove, it just explains the differences, which answers the first part of your question. Next, you need to know local ordinances or laws. For example, some places forbid use of liquid gas (white gas, gasoline, diesel, kero, alcohol, etc) and prefer you to use LG - propane or butane - or fuel tabs (or wood). Places with high water tables or many waterways tend not to allow these liquid fuels, to mitigate the danger of a spill. Others forbid use of canisters, due to litter concerns. And you may be subject to rules within your group - the boy scouts, for example - who explicitly forbid use of alcohol, due to the fact that it burns too cleanly, and flames are difficult to see. So from a practical point of view, the heavier fuels (white gas, gasoline, diesel, kero) is best (or required) used in cold weather. Next, cost could also be a factor in your choice of stove. Prices for each tend to favor the canisters, as you can get cheap butane stoves for about $8 from Etekcity, which are surprisingly durable, light, and - oddly - almost too small. They fit inside the concave impression at the bottom of the fuel canister. The heavy gas stoves by Optimus and MSR are quite durable also, and tend to have the ability to burn a variety of different fuels, but they cost $100 and up - the new optimus optiful cost $180 and literally burns anything except alcohol. Next, consider the safety and cleanliness of the fuels you'll be burning. If your stove burns white gas (coleman) it will also burn gasoline (petrol) and aviation fuel. If your stove burns kerosene (paraffin) it will generally burn diesel. But that doesn't mean you should burn all these fuels: gasoline/petrol, diesel, and aviation fuel - they're notoriously poisonous and dirty. Gas/petrol is also explosive, and if you spill it, you're gonna smell it for days - it won't evaporate away due to the mixtures added to it. Kerosene is also a dirty fuel, but once it gets started, it burns relatively cleanly. So, you should prime these stoves with alcohol to mitigate the soot build up. However, kero is an extremely stable fuel and isn't as flammable as the others. Still deciding on a stove or fuel? The stove mechanics also makes a difference. For the multi-fuel stoves, you almost always have to change the jets. Kero/diesel, gas/coleman, propane/butane are the three jets you'll need. But here I question the need for such a stove: carry what you need for the fuel you'll need. If you think you need to burn everything, then by all means, bring all the jets and tools to exchange the jets, but that makes the trip a little more complicated. (Unless you go with the expensive Optimus Optifuel, which requires NO jet changes). But you still have to worry about clogged jets, and field maintenance on these delicate things can be a menace. One lost part, and you're screwed. My advice is to bring the stove with least amount of fuels you'll need and can bring. Don't bring the one which can burn aviation fuel if you won't be anywhere near an airport. Remember, in an emergency, you can always burn a wood fire, no matter the stove which ran out of fuel. For what it's worth, this is a great read: FAQ - Technical details on Stoves EDIT: More reading material: What's the difference between gasoline, kerosene, diesel, etc? How Refiners Decide to Make Gasoline vs Distillates Pure naphta (Coleman fuel) vs Unleaded petrol Naphtha to Gasoline
2366385	How long is a piece of string? Your speed is totally dependent on your surface, equipment, bike type ... and you! I keep a record of most of my training ride (for the last few years with GPS, but summary data going back further) and compete with myself. If you're interested in what you should/could be doing, maybe liaise with a local club. On my commute my rolling average with lots of braking and accelerating, is a good mph or two lower than training rides (further, but quieter roads) with race pace being another mph or two higher; cyclo-cross and off-road is completely terrain dependent so your mileage really will vary enormously And if you have professional road aspirations, you'll want to average at least 25-27mph.
19810	Another use of swag in the same story: Obama likewise seems to think that a bit of swag, plus a public taunt, aimed at Putin when the former KGB man is down on his luck will have the desired geopolitical effect. The word actually means what the dictionary definitions, including the one posted by CopperKettle, say it means. However, sometimes authors are unaware of what words actually mean (how other people use them). If the author is using swag as short for swagger he is either using it in error or trying to use it to have two meanings at once. In either case his usage is so esoteric it escapes the common reader. A third possibility is that I am unaware that swag is short for swagger.
442051	Darth Vader is Kylo Ren's maternal grandfather. A maternal grandparent is someone who is your mom's parent. Your paternal grandparents are your father's parents. Your mom's parents are your maternal grandparents.(source) Another way of saying it is "my grandfather on my mother's side" (or maternal grandfather) vs "my grandfather on my father's side" (or paternal grandfather). You are correct that Vader is not Kylo's paternal grandfather (as that whould be Han's dad, and Vader is not Han's dad), but Vader is still Kylo's maternal grandfather (as that would be Leia's dad, and Vader is Leia's dad1). Here's a chart I made to help make it abundantly clear: 1 We know Vader is Leia's father from Return of the Jedi, when Luke learns that Leia is his twin sister. LUKE: Leia's my sister! KENOBI: Your insight serves you well.
1070763	As noted in the other answers, it's hot-plug, as per the specification (most recently freely available version is 1.3a, references are to that version here). Damage may be physical, or electrical. Physically, type A connectors should be good for over 10,000 insertions (as good as micro-USB), see §4.1.6 Connector Mechanical Performance. Since it's possible to get imperfect (simultaneous) mating of all pins, one side may not initialise correctly during hot-plugging, that ought not cause damage. HDMI is robust against shorting any combination of pins or connection (§4.2.11 Robustness Requirements). §8.5 Hot Plug Detect Signal describes the connection and HPD process. There is a dedicated pin for hot-plug, the HPD pin, damage to this will cause problems (but you can say that about any pin). After HPD is asserted, an E-EDID data exchange should occur. Warnings that come with HDMI devices or cables instructing you to power-off before connecting may be intended to minimise electrical discharges and other effects due to potential differences between grounds (the cause of "ground loops"). In my experience, aside from old or bad wiring, the main sources of ground loops are cables originating from different providers: cable, phone and electricity. Ethernet with metalized 8P8C (RJ45) connectors could also cause problems (more about ethernet and grounding). Low quality SMPS (switched-mode power supplies) in cheap electrical equipment are another problem (earth leakage, dubious isolation, undesirable modes of failure). It may be prudent to interconnect devices with different input sources while the devices are powered off, but still plugged in so that they are grounded. So to answer your question: if your TV has a direct connection to an analogue coax cable provider, there might be a ground loop which could in principle cause damage to circuitry when making connections. If your laptop is not plugged in to a charger (or ethernet) this is less likely to occur. One additional consideration might arise due to HDCP (content protection) – when you have more than two HDMI-capable devices the order in which you plug things in may cause different end results. Whether that conflicts with your understanding of hot-pluggable is up to you ;-)
1165763	The internet is filled with conflicting information because a lot of it applies to different scenarios. General background: Firstly, there's a paired device and a connected device and then an actively communicating device. Your links above confuse these and no distinction, but there is a difference in functionality. A device can be paired, but not connected. Similarly, it can be connected but not transmitting. Think of a paired device as a saved wireless network that you're not connected to. Then there are host devices and client devices. This is a generalization, but consider PCs, mobile phones, and tablets (and consoles) to be hosts, and headsets, controllers, mice, keyboards, etc. to be clients. Then there's profiles, a profile indicating a type of connection (e.g. audio, HID, etc.) With that in mind, the following apply: In general, host devices support up to 7 simultaneously connected devices and a practically unlimited number of paired. Host devices are like a wireless router - you can connect many different devices at a time. Client devices typically support a limited number of pairings, anywhere between 1 and 5, and only one single connection. They act like a wireless client - you can save many different networks but only connect to one at a time. Some profiles only support one connection at a time on some devices - for example, some Bluetooth speakers can only connect to one computer at a time. A phone for example usually can only connect to one HSP (headset) at a time but can connect multiple HIDs (keyboards, mice, etc.). Also, to explain/clarify some of your links/references: All Bluetooth adapters can support 7 devices, period. Mostly true - the standards only allow up to seven simultaneous connections on a normal device. But you can pair any number of devices. You can hook up 7 devices, but only if they're all different types of devices. False, but in some scenarios, you cannot simultaneously use two devices with the same Bluetooth profile. This generally applies to audio devices only (i.e. headsets) which may be all that some people are familiar with. For example, a phone can connect to one headset, or one music stream, or one of each, but not two headsets or two speakers. A PC can, however, connect to many phones at a time. You can hook up unlimited devices, no restrictions. (source - a Bluetooth Dongle tech-support) False. You can usually pair unlimited devices on a host, but you cannot connect to them all simultaneously (again, think of the number of saved wireless networks, that aren't all connected at the same time) Only devices that support "multipoint functionality" can have multiple hooked up at once, and the choice of adapter doesn't make a difference. Partly true. This only applies to client devices, such as headsets, controllers, keyboards, etc.. These limited devices can only connect to one host at a time if they do not have multipoint. A host can accept multiple clients even if those clients do not support multipoint. Only Bluetooth 4.1 adapters support multiple devices. False. No idea where he got this from, it's plain rubbish. You can only use one device per Bluetooth adapter. False. Pretty much everything in that entire statement is wrong. So the final answer is yes, you can connect four controllers (clients) to one adapter (host) at a time. Even without the above information, it's fairly obvious as per @oldmud0's answer, if [controller] uses Bluetooth, then how does the PlayStation establish a connection to all 4 controllers with a single radio [if Bluetooth didn't support it]?
2372603	Randonneuring or Audax riding is about riding audaciously long distances for the pleasure of riding audaciously long distances. (www.audax.org.au) One method involves riding at 22.5km/h (14mi/h) in a peleton for up to 1000km. Another method involves riding at any pace above 15km/h (9.32mi/h) (up to 600km) or 13.33km/h (8.32mi/h) (1000 / 1200km). I would suggest that the reasonable speeds for very long distance riding are 15km/h total average including breaks up to 600km, or 13.33km/h for 1000/1200km/h rides. As a result I feel good when I make 15km/h of actual time when riding long distances, and try to improve my riding so that I'd be able to make 15km/h of actual time including sleep for longer distances.
2382959	Assuming your terrain is relatively flat: Average cyclists will be 10-15 km/h, so that's 8.5 and 6 minutes. I've walked past a grannie cyclist while out exercising my dog, so she would be doing under 6 km/h and at that speed would take 21 minutes to get to the station. A fast road bike does 40 km/h and the pros can do 50-55 km/h sustained, so that's 2.1 minutes and 1.5 minutes respectively. The world land speed record on a bike is well above 130 km/h and at that speed you'd be at the station in ~38 seconds. The formula is ( Distance in km ) / ( Speed im km/h ) * 60 returning a time in minutes. This assumes no stopping for lights or traffic or crossing.
326	The first and most important point to note it that it's very informal (more so than using contractions such as my it's there, for example). The main reason for using it at all stems from that "extreme informality". It normally conveys a relaxed attitude on the part of the speaker. Depending on context, it can be more or less emphatic than "No". You only use nope to mean [my answer is] "No" – it never replaces no in any other contexts. And you wouldn't normally use it where you want to be very emphatic (shouting "No!" at the top of your voice). Which example illustrates a defining characteristic – "Nope" isn't often followed by an exclamation mark! Finally, I'd echo John Lawler's words: "nope" occurs only as a one-word answer to Y/N questions. That's to say, a written form such as: "Nope I don't want to" doesn't look right. We expect a full stop (or at the very least a comma) after "Nope" because in real-world speech there always would be a pause there. But that doesn't happen with: "No I don't want to!" because it's perfectly possible to speak those words without pausing appreciably after "No" (without necessarily placing extra stress on "don't", either; I just italicised it as one possible enunciation).
589	"You too" is an abbreviation of a repeat of the sender's statement, for example: Merry Christmas! [Merry Christmas to] You too! This is entirely valid spoken English (it's very informal in written English), but be careful of when you don't want to return the greeting in its exact form. For example, the following is fine when both you and your friend are heading home from work: Have a safe trip home! You too! But the previous conversation is wrong (but usually obviously and inoffensively wrong) if the first person is not travelling home, for instance if the second person were leaving the first's house after a visit. In such a circumstance, one would normally have to think of an alternative response, for example: Have a safe trip home! Thanks! Have a great evening!
387344	A Warren (also Holds in earlier times that you'll get to in later books) are places (worlds/dimensions). They have distinct geographies, may be inhabited, have occupants (i.e. creatures that live in them), and are generally ruled by a god (or sometimes something else). Mages draw power from Warrens (by opening a mental doorway/window to them), but they are also able to physically enter them, travel through them (interacting with any inhabitants), and exit somewhere else. Mages can take non-mages on these travels, and occasionally a non-mage will enter a Warren for some reason. In Memories of Ice, you'll find out that: Warrens were created in some way from the flesh and blood of the Elder God K'rul, and have a strong connection (possibly sourcing power from) dragons (Eleint). Dragons typically inhabit Warrens.
432766	In the comics, Barry Allen has been shown to run faster than light, as per @Keen's answer to this related question. Exactly how fast has never really been measured -- as far as I know, they've never tried to apply the Star Trek "warp" scale to Barry. In the DC universe, there are five "speed barriers" (really, critical velocities): the sound barrier, the light barrier, the time barrier, the dimension barrier, and the Speed Force barrier. Barry is one of the very few people who can break through all five barriers, meaning he can run significantly faster than light -- fast enough to travel into the Speed Force itself. (In general, he rarely moves faster than a few Mach levels, because it causes major problems for his surroundings.) In the TV show, we just don't know. In the Flash episode "Legends of Today", Harrison Wells and Caitlyn Snow actually discuss Barry's top speed so far. Caitlyn claims that Barry was travelling at something around Mach 2 when he time traveled. (We have to assume, then, that the time travel is an effect of the Speed Force itself, and not a side-effect of supra-light travel.) Wells claims that Zoom is "at least 10 times" as fast as that, and that Barry will have to get himself up to that point to face Zoom. I think we can expect that as the season progressed, Barry will struggle to become faster than he has been up to this point, but there's no indication where that speed increase will happen.
553756	The pattern is better expressed this way: Row 1: 2 elements Row 2: 2+6 elements Row 3: 2+6 elements Row 4: 2+6+10 elements Row 5: 2+6+10 elements Row 6: 2+6+10+14 elements Row 7: 2+6+10+14 elements The reason comes down to how the electrons fill the available energy levels. The thing that differentiates one element from another is the proton number, and each time a proton is added and a new element defined it requires one more electron to neutralise the charge. That electron naturally occupies the lowest available energy level in the atom. The energy levels available are defined by the quantum state, including the quantum numbers $n, l,$ and $m_l$. $n$ is the principle quantum number and relates to the period the element is in, or the shell. $l$ is the angular momentum quantum number which defines the sub shell s, p, d, f, of which there are $n$ subshells whose values are $l=0,\dots {n-1}$. The magnetic quantum number $m_l$ further subdivides the subshell into orbitals, of which there are $2l+1$ orbitals whose values are $m_l=-l,\dots {+l}$. subshell number of orbitals subshell label l value (number of ml values) electron capacity s 0 1 2 p 1 3 6 d 2 5 10 f 3 7 14 Each orbital (i.e. each value of $m_l$) may contain 2 electrons The available quantum numbers are: n l values (subshells) ml values total shell electron capacity 1 0 (s) 0 2 2 0,1 (s,p) -1,0,1 2+6 3 0,1,2 (s,p,d) -2,-1,0,1,2 2+6+10 4 0,1,2,3 (s,p,d,f) -3,-2,-1,0,1,2,3 2+6+10+14 The pattern is there, but it doesn't seem to match up because by row 7 you would have 98 electrons in the shell and might expect the row to contain 98 elements. This is not the case! The energy levels for the $l$ values with large deviations from $0$ (i.e. orbitals with high angular momentum) become increasingly far apart, so even though 3d orbitals exist in the third row, they are so much higher in energy than the 3p orbitals that they are higher even than the 4s orbitals. This happens again in row 4 where 4f orbitals are so much higher in energy than 4d orbitals, they are even higher than 5s. The different in energy is not always so large in specific cases, so there are examples where bonding or ligands or symmetry cause the energy levels to switch around, but otherwise the trend is true. If they can produce (or discover) some elements in the next row, we might expect to see the 5g shell finally start to get filled and have a new block in the table, but realistically it doesn't look like they will be stable atoms. I think I'm missing the reason why we arrange the elements into this table in the first place. The periodic table is arranged so that all elements in the same column have the same number of outer electrons. This is useful because elements with the same outer shell configuration of electrons react in similar ways, so they are grouped together in columns. This has the effect of creating 'periods' that begin with a reactive metal and end with an inert gas. Row 1 has two elements, and it's special in a way because it's the first in the series. Hydrogen has 1 electron, and a maximum capacity of 2 electrons. This means it behaves in a similar way as other elements that only have 1 electron in their outer shell (group 1), and also in a similar way to elements that only need 1 more electron to complete their outer shell (group 7). Where do we position it then? Often it is placed somewhere in the middle. Helium then has a full outer shell, which means it has many similarities to other elements with a full outer shell and goes in group 8 (or group 0) on the right. Edit: The alternative period table that you mention, the left-hand version, is laid out so as you read it from left to right you fill up the orbitals. This takes in to account that situation I describe where 3d orbitals are higher than 4s, and using this left-hand table you clearly see that. However this alternative table does not allow you to easily read the valance shell configuration like the Mendelev one does. Other types of table highlight different kinds of properties or relationships, which can be more useful in certain situations. The labels on the left (1s; 2s; 2p 3s; etc) relate to the outer subshell in that row, so Carbon is in the "2p" section of that chart while Magnesium is in the "3s" section on the same row.
1173439	I just upgraded someone to a 2-in-1 laptop with limited hard-drive space. We used a Google Email account, and had no issues with storage space. I'm trying to move one of my older in-laws away from WLM as well – it isn't supported very well by Microsoft – but they don't want to learn anything new. If you want to keep using a Microsoft account, I would start up an "outlook.com" email account, and transfer everything to there. Microsoft has instructions here. It might be your easiest migration path. http://windows.microsoft.com/en-us/outlook/import-desktop-app From the link: Import email from a desktop app If you've been using a desktop app to manage your mail, like Outlook, Outlook Express, Windows Live Mail, or the version of Windows Mail that came with Windows Vista, your email messages and contacts are on the hard drive of your old PC. You can import them into Outlook.com using the Mail Migration add-on. Import your email and contacts On the PC that has your email and contacts, install the Mail Migration add-on for Internet Explorer. Choose which accounts you want to import. By default, the add-on will import all email and contacts from all email accounts on your PC. Click Import. Set up your Outlook.com account in the Mail app If you liked using Outlook, Outlook Express, Windows Live Mail, or Windows Mail, and your PC runs Windows 8.1 or Windows RT 8.1, try the Mail app. For more help with adding email accounts, contact customer support.
1263601	I just needed to find /etc/environment using Ubuntu 16.04 looking into Windows 10 NTFS storage. I found it here: C:\Users\USER_NAME\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu16.04onWindows_79rhkp1fndgsc\LocalState\rootfs\etc\environment I changed /mnt/c/ to C:\ for Windows nomenclature. I also changed all occurrences of / to \ for same reason. You need to replace USER_NAME with your Windows User Name. I had to use sudo -H Nautilus to get permissions to view the User Files stored in WSL. NEVER update your Linux files in WSL using a Windows application. It will corrupt your Linux data. From the Linux (Ubuntu 16.04) side the nomenclature would be: $ sudo cat /mnt/c/Users/USER_NAME/AppData/Local/Packages/CanonicalGroupLimited.Ubuntu16.04onWindows_79rhkp1fndgsc/LocalState/rootfs/etc/environment PATH="/mnt/e/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games" export LIBGL_ALWAYS_INDIRECT=Yes export DISPLAY=localhost:0.0
2372677	Average speed is extremely dependant on: Your fitness (main factor) Weather (particularly wind) Road surface quality Interruptions like traffic lights, dog-walkers on bike-lanes Accumulated fatigue over multiple days How hilly the terrain is (although this can be balanced out by the faster descent) As you mentioned, best way to see is using a GPS and seeing how fast you go.. I've found over the course of about 6-months of riding, my average speed over long rides is around the average of my shorter rides (I'm classifying "long" as around 150-200km, and "short" as maybe 30-80km) For example, here is a plot of my distances vs average speed: (the axis's are in km/h and km) The >50km rides averaging 25-30km/h are mostly group rides. Ignoring those, beyond about 80km begin to converge to an average of 20km/h (although at 80km I've ranged from about 15-25km/h, but this includes when I just started riding..) These numbers are all specific to me, and even still they vary (particularly over time): These averages are spread over a few different bikes (start to April was on a hybrid bike, April to mid May was on one road bike, and the rest was on a different road bike) - but, the spikes are almost all related to either terrain (there's a large dip in July related to a Strava hill-climbing challenge), fatigue (the dip in August was another Strava challenge, to cycle long distances over consecutive days), or other factors mentioned above Sorry for the rather rambly answer, but it hopefully conveys that average speed depends on a lot of factors, and it's hard to give a specific answer
2395052	Nipple wrench flat sizes don't correspond to spoke gauge in as clean or universal of a way as you're suggesting. This depends a little on where you are in the world (and in history), but 2mm aka 14g spokes are by far the most common for bicycles, and there are three different common size nipples associated with them: 0.127", 0.130", and 0.136". (These correspond respectively with the black, green, and red spoke wrenches that several tool companies use.) Of these, the 0.127" wrench flat size is the standard one for 2.0mm spoke nipples by all the modern premium quality spoke makers (DT, Sapim, Wheelsmith, Marwi), and the other two are used seemingly at random by various lower-tier spoke/nipple producers. Nipples for 1.8mm/15g spokes also almost always have the 0.127" wrench flat size. 2.3mm/13g spoke nipples can have either the 0.136" size or one of the more "oversize" standards like 0.156". So there is no 1:1 mapping, especially because looking back into history there can be found any number of now-unusual permutations. The gauges listed on ring-type spoke wrenches are arbitrary and outmoded in actual use even if once they were based on some kind of real system. Also, spoke wrenches in shop use get a lot of reps and do develop slop and eventually wear out.
553445	The D-L system corresponds to the configuration of the molecule: spatial arrangement of its atoms around the chirality center. While (+) and (-) notation corresponds to the optical activity of the substance, whether it rotates the plane of polarized light clockwise (+) or counterclockwise (-). D-L system tells us about the relative configuration of the molecule, compared to the enantiomers of glyceraldehyde as the standard compound. Compounds with the same relative configuration as (+)-glyceraldehyde are assigned the D prefix, and those with the relative configuration of (-)-glyceraldehyde are given the L prefix. It's kind of another way to tell the configuration of molecules beside the Cahn–Ingold–Prelog convention (R/S system), with little difference. (D-L system labels the whole molecule, while R/S system labels the absolute configuration of each chirality center.) In short, the D-L system doesn't have direct connection to (+)/(-) notation. It only relates the stereochemistry of the compound with that of glyceraldehyde, but says nothing about its optical activity. We may have compound with same relative configuration as (+)-glyceraldehyde (thus, it's given the D prefix), yet it rotates the polarized light counterclockwise (-), such as D-(-)-ribose. And also, don't confuse the D-L system with d- and l- naming. d- and l- is the exact same with (+) and (-) notation. Additional explanation D-L system (also called Fischer–Rosanoff convention) is mainly used for naming α-amino acids and sugars. It compares the relative configurations of molecules to the enantiomers of glyceraldehyde. This convention is still in common use today. Rosanoff in 1906 selected the enantiomeric glyceraldehydes as the point of reference[1]; any sugar derivable by chain lengthening from what is now known as (+)-glyceraldehyde (or named D-glyceraldehyde) belongs to the D series. In other words, we used a D to designate the sugars that degrade to (+)-glyceraldehyde and an L for those that degrade to (-)-glyceraldehyde. In assigning the D and L configurations of sugars, we could direcly look for the OH group of the bottom asymmetric carbon in the Fischer projection. If it's located on the right, we designate it with D, and vice versa, since they would have the same relative configurations with glyceraldehyde for the bottom asymmetric carbon. Reference [1]: IUPAC and IUBMB. Joint Commission On Biochemical Nomenclature. Nomenclature of Carbohydrates. 1996, 7.
588553	First of all, a CI for a given confidence percentage (e.g.95%) means, for all practical purposes (though technically it is not correct) that you are confident that the true value is in the interval. If this is interval is "narrow" (note that this can only be regarded in a relative fashion, so, for comparison with what follows, say it is 1 unit wide), it means that there is not much room to play: whichever value you pick in that interval is going to be close to the true value (because the interval is narrow), and you are quite certain of that (95%). Compare this to a relatively wide 95% CI (to match the example before, say it is 100 units wide): here, you are still 95% certain that the true value will be within this interval, yet that doesn't tell you very much, since there are relatively many values in the interval (about a factor 100 as opposed to 1 - and I ask, again, of purists to ignore the simplification). Typically, you are going to need a bigger interval when you want to be 99% certain that the true value is in it, than when you only need to be 95% certain (note: this may not be true if the intervals are not nested), so indeed, the more confidence you need, the broader the interval you will need to pick. On the other hand, you are more certain with the higher confidence interval. So, If I give you 2 intervals of the same width, and I say one is a 95% CI and the other is a 99% CI, I hope you will prefer the 99% one. In this sense, 99% CIs are more accurate: you have less doubt that you will have missed the truth.
943048	AFAIK, focus on OS X is dictated by the application doing the stealing as well as the application which currently has focus (it is possible, for example, to program an "autocratic" UI application, such as a game). That said, it may be practical in your situation to modify the focus-stealing app itself. Inside the app bundle is an Info.plist. Add the LSUIElement key and set it to 1. This will (should) remove all trace of UI or dock icon, though it will still be visible in activity monitor. If you need to interact with this app's UI on a regular basis, this probably isn't practical. It might be just what you need, however, if you don't need to do more than launch it. Assuming it works with that app, that is.
1043023	Your friend is right. MS-DOS is/was an Operating System (Microsoft Disk Operating System is what the acronym stands for.) The UI for DOS is called a (the) command prompt. The first few versions of Windows ran on top of DOS (making them technically operating environments, though I'm not sure anybody makes that distinction anymore), but later OSes, starting with the NT Kernel, didn't - DOS was gone. However, people still needed the functionality provided by the command prompt, and instead of command.com we got command.exe (and these days cmd.exe), which when run gives us a command prompt. But, that's not the only (nor anywhere near the first) command prompt that people have used. Command Prompts are also called Shells, and Unix has many, and the commands are different and often very powerful. Speaking of Power, Microsoft has created a new command prompt for Windows called PowerShell which is incredibly powerful and interesting. See Wikipedia for more: http://en.wikipedia.org/wiki/Command-line_interface#Operating_System_Command-Line_Interfaces
1255297	As an alternative to @harrymc's answer, you can also use the Windows command line tool BCDEDIT to configure the Windows Boot Manager from an elevated command prompt. The following instructions assume you are booted into Windows 7. to open an elevated command prompt, press Win+R to open the Run dialog, then type: cmd /admin to list the Boot Manager settings, type: bcdedit To remove another entry, take note of the entry's identifier hex string (e.g. {00000000-0000-0000-000000000000}) and type: bcdedit /delete {00000000-0000-0000-000000000000} /remove To rename the description of the {current} entry to "Windows 7", type: bcdedit /set {current} description "Windows 7" If you wish to not display the Boot Manager on boot if you only have one entry, you can use this command: bcdedit /set {bootmgr} displaybootmenu no
1261341	They're not the same! Apparently lots of people don't realise that the DOS Prompt, and the Windows Command Prompt are not the same thing. They're actually two different programs - COMMAND.COM and CMD.EXE respectively. Know Your Command Prompts Firstly due to differences in the platform (DOS vs Windows) and interpreter (command.com vs cmd.exe), there will be obvious dissimilarities like DOS runs in fullscreen without a windowed mode, so no mode con:cols=COL lines=ROW command to resize the console, and no title command DOS doesn't support multitasking, multiuser, registry, permissions, long file names, symlinks/hardlinks, network, Unicode, dynamic disks and advanced volumes support... so no tools to manage those But there are also major differences in the capabilities and syntax of internal commands between command.com and cmd.exe, as well as some external tools in the two environments. In MS-DOS there are No functions, code blocks () and local scopes which mean for, if... must be followed by a single command on the same line no exit /b or goto :eof no setlocal and endlocal goto can only jump to a label, call can only start another batch file commands can't be grouped together like ( command1 command2 ) >output.txt No escape character ^. Printing special characters would be a pain, and no possibility of running multiline commands No special formats of if no if cmdextversion and if defined no numeric and case-insensitive string comparison if [/i] string1 compare-op string2 No command history and command argument completion No indirect expansion (e.g. call set %%var%suffix%=string) of variables and no delayed expansion (e.g. echo !var%suffix%!) No advanced string manipulation no ~xxxV variable support no substring %variable:~num1,num2% or string replacement support %variable:str=newstr% No partial variable name matching for set, and no set /a so you can't do arithmetic no set /p which means reading user input is a pain no set "var=value" syntax No %* for the whole command line No for /d, for /r or for /l. No for /f so reading input from files is also difficult. The only form of for in DOS is FOR %variable IN (set) DO command [command-parameters] No findstr, and find doesn't support Unicode No special environment variables like %CD% %DATE% %TIME% %RANDOM% %ERRORLEVEL% %CMDEXTVERSION% %CMDCMDLINE% %HIGHESTNUMANODENUMBER% Limited directory changing ability No pushd/popd No cd /d. Also no cd path with spaces and cd "path with spaces" due to the lack of long file name support No color No forfiles No assoc (because there are no GUI and files must be opened manually from command line, so no file association is needed) A lot of useful external commands in Windows like where, sort, more (in some DOS versions), choice... are also missing in DOS And this is what MS' Rich Turner said Also, Cmd != MS-DOS! I also want to point out a common misconception perpetuated by articles like the ones above: Cmd <> MS-DOS! In FACT: Microsoft last shipped a "new" version of MS-DOS (v8.0 in Windows ME), on September 16th, 2000 - 16 years ago (as of this writing)!! MS-DOS was an operating system (albeit a relatively simple OS by today's standards) whose primary user-interface was a command-line shell, until Windows 3.x & 9.x arrived and ran on/around MS-DOS MS-DOS' command-line shell's scripting language was relatively terse and moderately powerful, but lacked many of the richer, and more advanced features we enjoy in modern-day PowerShell, Bash, etc. While later versions of MS-DOS grew in sophistication and added/replaced some older assembly with new code written in 'C', much of MS-DOS remained written in x86 assembly for efficiency, and because it was the only way at the time to gain access to many hardware devices and peripherals. This made MS-DOS non-portable to non-x86 CPU's. If you're so inclined, you can actually download the source code for MS-DOS v1.1 and v2.0 to see just how much of the earlier versions of MS-DOS were written in x86 assembly (hint: pretty much all of it)! https://devblogs.microsoft.com/commandline/rumors-of-cmds-death-have-been-greatly-exaggerated/ Further reading Limitations of MS-DOS 6.22 Commands and Their Availability From MS-DOS 6.22 through Windows 8 New (and Removed) Commands in Windows 8 How do modern .bat files differ from old MS DOS .bat files? Windows batch files: .bat vs .cmd? cmd.exe: comparison with MS-DOS Prompt A command line interface is not a "DOS prompt" In conclusion, functionality-wise they may be a little bit similar, but otherwise hugely different
1369213	There will be resistors on some levels. If you like ICs, you can buy IC which contains multiple resistors: http://www.digikey.com/product-detail/en/4604X-101-103LF/4604X-101-103LF-ND/3593680 Or you could use fixed-gain amplifier which has resistors + amplifier in one package. But this will be an overkill, as your output is already from amplifier, plus most fixed-gain amplifiers have gain > 1 Or you can use ADC which takes -10V..+10V range and returns I2C data such as MAX127/MAX128. Or you could just connect amplifier directly to Arduino. Output will only exceed 5V if temperature is > 590C. What is the max temperature of the thing you are trying to measure?
1814979	If you run ipconfig /all, it probably shows something like this near the top: DNS Suffix Search List: example.com If you just want to resolve names without having to type the domain, i'd make it look like this (i.e. list all of your domains here): DNS Suffix Search List: example.com subdomain.example.com Now when your computer tries to resolve a "short" name like mysite, first it will try mysite.example.com (since that's the first domain in the search list), and if it can't resolve that, it will try mysite.subdomain.example.com. Of course, you can order the domains any way you want. If you have a Windows 2003 domain, then you'll probably want to configure the DNS search list via group policy so that you don't have to configure it manually on every machine.
2411996	Your problem is not the airbag, it's you. You aren't taking a rational approach to risk. This not to insult you, because humans generally are very bad at taking a rational approach to risk - if NASA can screw up risk management (most notably on Challenger) then anyone can. :) You won't find anything in the news to say it's "perfectly safe" or even "close", because that's not news. "Safety feature saves thousands of lives a year" is not a news story. "Safety feature goes wrong once and causes minor injuries" is a news story. But you're following the perfectly normal human characteristic of assuming visibility equals importance, and that's a bad assumption. In this case, it could quite literally be a fatal assumption for you and your passengers. I'm afraid you're describing a classic case of "a little information is a dangerous thing". You've absorbed that there's a minuscule risk in one direction, so that a few people a year suffer minor injuries, and you've absorbed the concept of an airbag being "a small bomb". But you're missing the concept of what happens to the human body when you crash at speed, and that hundreds of people at day crash at speed, and walk away because of airbags. You're also assuming you are capable of "driving more carefully". The statistics are pretty good on how nearly everyone thinks they're better than average at driving - and clearly 50% of people saying that are wrong! Even if you are, being careful doesn't protect you against external problems - what happens when you hit a patch of oil on the corner? Or what happens if someone else crosses into your lane and wipes you out? Being more careful doesn't provide any protection against that. If you only drive at 20mph then crack on with taking out your airbags. You're not going fast enough to need them. If you ever drive at more than 20mph though, you'd better believe they'll save your life. I'm prepared to bet you do drive at more than 20mph. The one exception to this is if your passenger is a child. Airbags are designed to blow out where an adult's head and body would be, but that's not going to work out well for a kid. It works out even less well if your kid is in a rear-facing seat, when the seat takes the full force in entirely the wrong place. Most cars do allow you to disable the passenger side airbag, and those that don't, there's some kind of transponder which disables it if there's a child seat fitted.
492282	Many photographers (especially those with full frame sensors or 35mm film cameras) opt for a 50mm prime lens because it is considered 'normal', i.e. not wide-angle or telephoto. Because these lenses are so popular, they are also produced on a relatively large scale, which also makes them cheaper than other lenses of the same speed. With that said, there is probably a deeper underlying question to be answered: Why is a 50mm lens considered 'normal'? There are actually a few factors that contribute to this. If we look at a single human eye from a mathematical perspective (pun not initially intended), the focal length comes out to be around 17.2mm. [as a side note, its aperture is around f/2.1]. Our eye is, indeed, a wide angle lens. Now, the eye's sensor size (the retina) is smaller than the 35mm film sensor that the '50mm normal' is based on. This will make the equivalent focal length of the eye longer, but not by enough to get it to 50mm, there is another factor at play... The images that we take with our 50mm 'normal' lens are generally displayed on a screen, or printed (or developed) and displayed on a wall or in an album. Very rarely do we ever get so close to an image that it takes up our full Field Of View (if we did that, we would not consider the image we saw as 'normal' anymore). We generally hold a photo at a distance that makes it look 'normal' (optimally, at a distance equal its diagonal). Because the image only takes up a portion of our FOV when viewed this way, we are adding an additional crop factor, making the equivalent focal length even longer. Only when we consider all these factors do we come up with a 'normal' focal length value of about 50mm. And remember, that value is only when the image is projected onto a 35mm sensor! for other camera types you need to multiply the magic 50 by your sensor's crop factor to get the 'normal' focal length for your camera. Refs: http://www.photosig.com/articles/585/article
575352	The (+) and (-) refers to the flow of electrons in the power supply. In a galvanic (Voltaic) cell, the cell itself is the power supply. In an electrolytical cell, the cell is attached to an external power supply. So while the designation of anode and cathode is directly linked to the direction of the flow of electrons in a cell, how (+) and (-) relate to anode and cathode depends on whether the reaction goes towards equilibrium or not (in the case of rechargeable batteries, whether you are draining or charging the battery). Depending on the direction of the reaction, anode and cathode labels change, while (+) and (-) labels stay the same. An example illustrates this. Here are two lead acid batteries connected together in a way where the charged one charges the empty one: The (+) and (-) label relates to the direction electrons would flow if they are discharging (of course, the dead battery can't discharge further, so you could not tell experimentally). The anode and cathode labels refer to the specific situation. So if you attach a higher voltage power supply to the charged battery instead of the dead battery, you would charge it further. This would reverse the chemical reaction in that battery, and the anode and cathode labels would have to be switched. In a different scenario, you could take two 12 volt batteries and connect them in series (connect (+) of one with (-) of the other one). This would give you a 24 volt battery, and if you attach a consumer to it, cathode would be (+) and anode would be (-) for both of them. For the lead acid battery, (+) and (-) never changes, so it is fine to label the electrodes permanently. In a concentration cell, (+) and (-) depends on the concentration of redox species in the two half cells, so you could not label them "with permanent marker".
1270491	There's a bit of confusion here; that /32 doesn't refer to the size of any (sub)network, but to the range of addresses that particular routing table entry applies to. Usually the two are the same (because you route a network or subnet as a unit, right?), but macOS does things a little different for other hosts on the same local network. Let me add some lines before the ones you quoted: Destination Gateway Flags Refs Use Netif Expire default openwrt.lan UGSc 10 0 en0 ... 192.168.1 link#4 UCS 2 0 en0 192.168.1.1/32 link#4 UCS 2 0 en0 openwrt.lan 46:94:fc:63:fc:7 UHLWIir 11 3610 en0 1200 192.168.1.125/32 link#4 UCS 2 0 en0 Note that 192.168.1 (short for 192.168.1.0/24) is routed over en0 (aka link#4); not via any gateway, just over the interface itself. This is the network that the Mac itself is on. 192.168.1.1 and 192.168.1.125 are both specific addresses within that network range. If you compare those /32 entries with the 192.168.1 entry, they're basically redundant duplicates; they say the same thing, just about specific addresses instead of the entire network range. I don't know why macOS creates these redundant address-specific entries, but it's probably related to another thing you can see in the listing above: macOS lists its ARP table entries in the routing table. The "openwrt.lan" entry above (which I'm pretty sure is actually 192.168.1.1, just listed by name rather than number) says that it's routed via en0 to the MAC address 46:94:fc:63:fc:7. So what you're seeing in the route listing is a mix of actual network routes (like the "default" and 192.168.1 entries), and per-host entries (the /32 and MAC-targeted entries).
2258558	More often than not, they're synonyms. When counting the rhythm of a piece, they are the points at which you may tap your foot, or click you finger. Be aware, though, that people's perception of where a pulse is may vary. Some may clap on 1, 2, 3 and 4. others on 1 and 3, yet others on 2 and 4. It's all pretty straightforward till we come to complex time, such as 6/8, where often two different feels or counts (call them pulses or beats if you like) are present in the same piece. 1 2 3 4 5 6 is one manifestation; 1 - - 2 - - is another. And the difference between 2/4/and 4/4 is sometimes not easy to discern, making the pulse or beat a little muddy. Some refer to a crotchet (quarter note) as a one beat note - I tend to - as it is the basic diet for a lot of rhythms. So in a 4/4 piece - way the most common - it could be said that there are 4 beats to the bar, or the pulse is 1 2 3 4.
485821	Based on your description of a spacesuit with bare legs I believe you are looking for BBC serialisation of The Tripods by John Christopher. I also believe it was broadcast on PBS as I notice one or two references to PBS in my google search for the show. As the show was made by the BBC in the mid 1980s your time frame is correct for this show too. The aliens were depicted as three legged torsos with a single eye. The scene you describe is with the aliens inspecting candidate humans who will be their servants. They do indeed grab at the exposed legs and flesh of the humans. This scene is in episode 5 of season two. You can watch the entire season on youtube but the scene you are describing appears at 9 minutes into the episode.
553791	Simple Answer: The elements are ordered into periods based on which electron shells are being filled (from left to right). In the first period, the first electron shell is being filled. In the second period, the second shell is being filled. And so on. There are 8 elements in period 2 because all those elements have electrons in the second shell and no electrons in the third shell. Elaboration: Electron configuration describes the electrons of an atom in more detail. The elements in the same period all have the same thing at the beginning of their electron configuration. Here are some examples so you can see the pattern: Li - Period 2 - [He] 2s1 Be - Period 2 - [He] 2s2 Ne - Period 2 - [He] 2s2 2p6 Na - Period 3 - [Ne] 3s1 Cl - Period 3 - [Ne] 3s2 3p5 This is the only way I can think of explaining it without going into detail about what the electron configuration means and how it can be used. But as to why there are 8 elements in period 2, all of those 8 elements have an electron configuration that starts like this: [He] 2s Alternate Table: Which one is the right periodic table? There is no right table. These tables are just organizational tools, and you can organize the elements based on a different criteria if you want to. No matter how you organize the table of elements, the elements are still going to have the same properties and react the same way anyway.
560392	In addition to the point made by airhuff, which is that greenhouse gases essentially prevent the earth from emitting infrared radiation into space, this slight effect shifts the equilibria of greenhouse gases which actually amplifies the effect. That is to say, when people speak of $\ce{CO2}$ being a big problem, this mostly because of an indirect effect. $\ce{CO2}$ slightly warms the earth which increases the amount of water vapor present in the atmosphere (in an average sort of way because this fluctuates quite a bit). This is a problem because water is a much more potent greenhouse gas than $\ce{CO2}$ and it absorbs at different wavelengths in the IR than $\ce{CO2}$ does. This matters because the amount of IR which $\ce{CO2}$ absorbs is fairly close to saturation. That is, doubling the amount of $\ce{CO2}$ does not mean doubling the amount of IR radiation absorbed and redirected back towards earth. The relationship is much closer to logarithmic than linear. But, this is only true for the wavelengths at which $\ce{CO2}$ absorbs, so introducing more water vapor allows a wavelength of IR to be absorbed which may not be saturated. This is only one mechanism by which greenhouse gases warm the earth. The atmosphere is an extremely complicated system. None of this mentions how well certain gases mix in the atmosphere and how long they stay there and anything about methane for that matter. All of these things have been written about in scholarly articles and books, so those are gonna be the places you find the nitty-gritty details and data. Also a note on what I mean when I say carbon dioxide is roughly saturated in terms of absorbance. It is true that carbon dioxide quite effectively absorbs IR light, but it can never truly be saturated. This is because the relationship is logarithmic, so it always increases, but just more slowly as you add more $\ce{CO2}$. Second, it has been said that convection can play an important role here because one shouldn't really think of bulk concentration of carbon dioxide but really the concentration in different layers of the atmosphere. This complication actually allows $\ce{CO2}$ to absorb more radiation than you might otherwise expect.
677655	Setting aside your initial explanation of the time-series context, it might be useful to look at this as a simple case of observing two data points. For any two observed values $x_1 , x_2$ the sample standard deviation is $s = |x_2 - x_1| / \sqrt2$. This statistic is exactly as informative as giving the sample range of the two values (since it is just a scalar multiple of that statistic). There is nothing inherently wrong with using this statistic as information on the standard deviation of the underlying distribution, but obviously there is a great deal of variability to this statistic. The sampling distribution of the sample standard deviation depends on the underlying distribution for the observable values. In the special case where $X_1, X_2 \sim \text{IID N}(\mu, \sigma^2)$ are normal values you have $S \sim \sigma \cdot \chi_1$ which is a scaled half-normal distribution. Obviously this means that your sample standard deviation is quite a poor estimator of the standard deviation parameter (biased and with high variance), but that is to be expected with so little data.
942513	A formula is statement written by the user to be calculated. Formulas can be as simple or as complex as the user wants. A formula can contain values, references to cells, defined names, and functions. All formulas must start with the equals sign. =1+2+3 A function is a piece of code designed to calculate specific values and are used inside formulas. Functions to sum values, calculate a trigonometric cosine, and to calculate the current time are built into excel. Additional functions can be defined using Visual Basic. Functions are typed alongside parenthesizes, where in the arguments if any are listed in between. To use functions in a formula, for example =COS(3.14) will return the calculated cosine. =NOW() returns the current time. =SUM(1+2+3) *2 will multiply the sum by 2 Source
1480196	For most home A/V gear, yes, the black is ground (chassis ground). You can check this with an ohmmeter. Why? Typical A/V gear will use a line-derived high voltage supply with a half-bridge driver, capacitively coupled to the output. Again, why? A line-powered amp has lots of voltage to work with. There is plenty of headroom to avoid voltage clipping, even at high power levels using just a single-ended drive. So it's just not worth the extra expense of using a full-bridge driver - even a switchmode one - for normal consumer A/V gear like a receiver. Car stereos - not so much. Higher power in-dash ones will use a full-bridge drive to maximize the use of the 12V available. Example: single-ended 12V power amp into 4 ohms: Largest AC RMS output: 12V / 2 * 0.707 = 4.24V Power into 4 ohms = 4.24^2 / 4 = 4.5W Bridged 12V power amp into 4 ohms: Largest AC RMS output: 12V / 2 * 0.707 = 4.24V Bridged: 4.24V * 2 = 8.48V Power into 4 ohms = 8.28^2 / 4 = 18W That's a big win for a car stereo, so it's worth the extra expense. Now, car power amps are a different matter. These will use DC-DC step-up make higher rails to achieve higher voltage swings at the output. Some may use bridge, some will not.
109060	On the surface, Owl Eyes is a perceptive character. He sees things that others miss. In reality, though, he's more easily fooled than anyone. The large glasses, of course, tie him to the Eckleburg billboard. There's a continuous contrast between surface and reality in the book, with the nagging question of how to tell the difference. Bigger glasses? Eckleburg's are the biggest, and they don't see what's going on right in front of them. We first meet "Owl Eyes" in Gatsby's library. His real name is never given, but he may represent Ring Lardner. He's looking at volume one of Stoddard's Lectures, one of those books nobody reads but claims they have. He notices it's a book, not a prop, but the pages haven't been cut. (In those days printers saved time by folding up large sheets and binding those together, which left the edges of the book a series of folds rather than pages. To read, then, you needed a paper knife to cut through these folds.) Gatsby has never read the book, and if he hasn't read volume one, he hasn't read any. The book is real, the house is real, but Gatsby is not. Owl Eyes sees that the book is a book, but that's all. He sees the surface but not the reality. "You can't judge a book by its cover" is inverted--he sees inside the book but not inside its owner. We next meet Owl Eyes in the driveway after he's crashed his car. He cheerfully admits he doesn't know how to drive. However, he's managed to block everyone else from leaving, and he has no clue about how to fix the situation. Again, he sees the surface (he knows how to drive) but not the reality (he can't deal with the consequences of a crash). Finally, he shows up at Gatsby's funeral. The only person who feels that much sympathy, besides Nick, is the person who can't see. Gatsby is a cardboard cutout. Owl Eyes has come to his parties and believes the facade is real, but Gatsby died because he wasn't the person he appeared to be. He wasn't a person at all, just a void he hoped Daisy would fill.
419767	In short, the subtractor was Adrian's last-ditch weapon against a being that has almost godlike powers. He's smart enough to have built an open sided Intrinsic Field Subtractor and there's at least a (very) slim chance that it might work and that the fields research that gave John his powers might also have the power to destroy him. When it doesn't work, Adrian isn't especially surprised, nor does he have a backup plan. John does at least give him an 'A' for effort, while pointing out that his "ultimate weapon" is actually a bit crap. In Before Watchmen: Dr. Manhattan #4, we see that Dr Manhattan had an earlier conversation with Veidt about his abilities. Note he states that he tries to avoid taking himself apart as that would... "...constitute the destruction of the body"
558622	A mixture is when two or more substances combine physically together. However, in water, two hydrogen atoms combine with one oxygen atom chemically, forming a new substance that has properties different from hydrogen alone or oxygen alone. For example, if you combine iron powder and sulfur powder physically (just mixing them together without applying heat), you can find that the mixture retains the properties of the original components, i.e. you can still use a magnet to attract the iron inside the mixture. However, if you heat it up, the iron and the sulfur would combine chemically, and a new compound would be formed, which we call "iron sulfur" ($\ce{FeS}$). This is a new compound and loses the properties of the original compounds. For example, it is not attracted by magnets. Therefore, water is not a mixture; it is a compound and it is pure.
651844	Compilation and expansion of comments: Let's presume your data is Normally distributed. If you want to form two-sided error bars (or confidence intervals), say at the 95% level, you will need to base that on the Student t distribution with n-1 degrees of freedom, where n is the number of data points. You propose to have 2 data points, therefore requiring use of Student t with 1 degree of freedom. 95% 2-sided error bars for n = 2 data points require a multiplicative factor of 12.71 on the sample standard deviation, not the familiar factor of 1.96 based on the Normal (Student t with $\infty$ degrees of freedom). The corresponding multiplicative factor for n = 3 data points is 4.30. The situation gets even more extreme for two-sided 99% error bars (confidence intervals). As you can see, at either confidence level, there's a big "savings" in the multiplicative factor if you have 3 data points instead of 2. And you don't get dinged as badly by the use of n-1 vs. n in the denominator of sample standard deviation. n Confidence Level Multiplicative Factor 2 0.95 12.71 3 0.95 4.30 4 0.95 3.18 5 0.95 2.78 infinity 0.95 1.96 2 0.99 63.66 3 0.99 9.92 4 0.99 5.84 5 0.99 4.60 infinity 0.99 2.58
1249780	About the filesystem mounted on /mnt/c What exactly is /mnt/c/Users/ compared with C:\Users<username>? It seems they are one in the same---so what is /mnt/c/? In contrast to Windows, Linux (and the other systems based on Unix) use a single folder structure independent of the number of disks you have. If you have multiple disks, all these disks must me mounted into the folder structure at some point. Typically, all the disks (different than the used to boot the system) are mounted in a folder named /mnt or /media WSL has an special type of filesystem named DrvFS that gives you access to the disks used in windows. You can use DrvFS to mount, not only your windows filesystem, but also network disks and other media types. In WSL, by default, the C: disk in windows is mounted under /mnt/c If you have another disk, for instance a D: disk in windows, it will be mounted under /mnt/d The files you can see in /mnt/c are the same you have in C:. If you modify some file, you will get the changes in the windows too. You may use the mount command to access other types of media (e.g. removable drives or network shares). About the location of /home/<username> How can I view the files in /home/ using the Windows File Explorer? Not that I'd really ever want to---I'm just trying to get a feel for how Windows is organizing this Subsystem for Linux thing. In WSL, all the linux filesystem is located under a Windows folder. The location of the folder depends on the version of Windows and of the WSL distribution you are using. Initial versions of WSL store the linux filesystem in %LOCALAPPDATA%\Lxss\rootfs WSL distributions installed from the Windows Store, starting in Windows Build 16215 (mid of 2017), use a folder like %LOCALAPPDATA%\Packages\{package}\LocalState\rootfs. The name of the package varies depending on the distribution (e.g. it is different for Ubuntu than for Debian). For Ubuntu on Windows it is CanonicalGroupLimited.UbuntuonWindows_{code}, for example. Linux distributions installed using other tools, such as lxRunOffline or WSL-DistroLauncher may store the linux filesystem into any location. You may check many options to know the location of the WSL folder. For instance, I think the easiest option is to use lxRunOffline to know the installation folder. ## You can use lxrunoffline to check which WSL distributions have installed ## using: lxrunoffline list C:\> lxrunoffline list backup Ubuntu-18.04 ## And you can use it to get the location of any of these WSL installations ## using: lxrunoffline get-dir -n <name of distribution> C:\> lxrunoffline get-dir -n backup c:\wsl\installed\backup C:\> lxrunoffline get-dir -n Ubuntu C:\Users\Jaime\AppData\Local\Packages\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\LocalState Once you know the location of the installation folder, the /home/<username> is under <installation folder>\rootfs\home\username. For instance, if your installation folder is c:\wsl\ubuntu the /home/<username> is in c:\wsl\ubuntu\rootfs\home\username NOTE: Both Linux and Windows stores file permissions in different ways. Nowadays, the WSL DrvFS stores the Linux permissions as Streams (metadata) attached to the files you can see in Windows. Microsoft does not recommend to modify linux files using Windows programs. It is possible that some Windows applcations damage the linux permissions without notice it.
2247928	On the face of it, it doesn't make sense. But intervals are taken from the major scale notes. Thus a major 3rd is, say, from C to E. When an interval is made smaller by a semitone, it's called a minor. Thus a minor 3rd is C to Eb. Yes, it happens to be in the minor scale/key as well. This applies to most intervals, but not perfect ones - fifths, for instance. Major 7ths would be C to B, whereas C to Bb is a minor 7th. The major second, in your question, is C to D, so when that is changed into C to Db, it's called a minor 2nd. Note that C to C# is NOT the same, even if, on most instruments, it sounds it. The way it gets written down is important. It doesn't mean that the Db is in the minor scale. The 6th is another confusing one. C to A is major 6th, and C to Ab is minor 6th. However, a minor 6th CHORD doesn't have a minor 6th interval. It's spelled C Eb G A - with a minor triad, but a major 6th interval. Going back to perfects - there are no minor 5ths. If C to G is a perfect 5th, then C to Gb is called a diminished 5th.Perfect 4ths are treated the same. So, in summary - 2nds,3rds, 6ths and 7ths can all be major or minor, and if they are made even smaller, by another semitone, they are called diminished. Perfect 4ths and 5ths change to diminished when they are one semitone smaller.
493574	It's actually just happenstance. The 35mm film still format was developed from an existing 35mm cine format, shot "sideways" to increase the image size, and the 2-inch cine lens was a cheap off-the-shelf lens at the time. Both decisions were cost-saving measures; 35mm film allowed the use of film ends, the unexposed bits at the end of, say, a 400-foot roll of film, and the 2-inch lens (a common, simple, easy-to-produce design) had the needed image circle while still being cheap enough. All of these decisions were made before a 35mm rangefinder camera was made, let alone a SLR. 50mm is actually rather long for a "normal lens". Consider that a 35mm frame is 24mm by 36mm. A square medium format camera has a frame that is 56mm by 56mm, and the "normal" lens for that format is 80mm; 150mm is considered "normal" for a 4x5 (inch) camera (think Speed Graphic).
808564	I'm wondering where you got your list. It appears that other days might be better choices. As an example, for Porto-Vecchio, April 20,2019 is a day late: Apr 19, 2018 sunset: 20:07, moonrise: 20:13, diff: 0:06 The moon rises about 50 minutes later on consecutive days. In addition, the sunset time might be changing by a couple of minutes a day as well. Since sunset only happens once a day, then we'd expect the rise after a full moon to be anywhere in that ~50 minute period late. On average then, I'd expect the closest sunset/moonrise of a month to usually be a quarter of that range (cut in half because closest could be before or after, and another half for variation) or about 15 minutes. There are a lot of sites with accurate sunset/moonrise times, but I don't know of any that directly give the delta between them. Could probably create one with some python scripts, but not something I've done.
997293	Tricky! A DNS Server typically is for converting FQDN (www.xxx.com) to IP Addresses (192.168.0.1). (A DNS Server also does a lot more, it can perform reverse lookups, and in recent years does a lot of other tasks with text tags, geo-ip and a lot more). On the other hand, "Name Server" is typically used to locate a DNS Server. For example, On a Whois record, a Name Server is typically the address for the DNS server that hosts the records for that domain. A further more complicated example is, if you queried www.superuser.com, you would go to your dns server and a recursive DNS lookup would occur on the superuser's nameserver. As for how many are there - how long is a piece of string! This is an impossible question to answer... As a guess, I would put it in to the hundreds of thousands, if not low millions (for publicly accessible DNS Servers).
1018185	Yes, both GnuPG and the commercial PGP.com are implementations of the same OpenPGP standard; in fact, GnuPG was specifically designed to be PGP-compatible. The only differences you might encounter are: Different supported algorithms. For example, GnuPG supports the Camellia encryption algorithm, while PGP.com does not. This is almost never a problem, though, as every PGP certificate ("PGP key") lists all algorithms that the owner's software supports (or more precisely those which the owner prefers to be used), so a message's sender can always pick a supported one. Various quirks and differences in really old versions of PGP (especially the original releases from before OpenPGP was standartized). However, both GnuPG and PGP.com can easily read (if not always write) messages in the old formats. tl;dr: Yes, they are compatible.
1683181	First, you may want to use the shell terminal in order to try to access your folders, so you can confirm if they exist or not, and, if they exist, see if they're empty or not. To do so, open a shell terminal window and run this supercommand: cd ~ && ls -las --color |more You'll see a colorful list of all the contents of your home folder (/home/cosmin). Even hidden files and folders will be shown to you. Press the spacebar key to scroll 1 page down and see more of the contents of your home directory. Repeat the process until the end. This will allow you to check if your personal directories - like Downloads, Documents et cetera - are still there. If they are, you can cd into them and check their contents. For instance, if the Downloads folder is present inside of your home folder, then this supercommand: cd ~/Downloads && ls -las --color |more ...will show you what's inside of that folder. If your folders are not present, then they were deleted. I'm sorry, they're gone, you'll have to recreate them. Please read this post about how to create new user accounts, manually create user folders et cetera. If your folders are present, then close your file manager and run this command in the shell terminal: xdg-user-dirs-update Now try to access your folder again. If it didn't work, run this other command: xdg-user-dirs-update --set DOCUMENTS $HOME/Documents If it works, just repeat the process with your other directories: xdg-user-dirs-update --set DOWNLOAD $HOME/Downloads xdg-user-dirs-update --set MUSIC $HOME/Music xdg-user-dirs-update --set PICTURES $HOME/Pictures xdg-user-dirs-update --set VIDEOS $HOME/Videos ...and so on. For more info, run this shell command: info xdg-user-dirs-update If xdg-user-dirs-update doesn't solve the problem, you may want to try something more extreme, like the following supercommand: sudo rm -rfv ~/.cache ~/.config ~/.local ~/.profile && sudo telinit 6 The supercommand above will delete your profile's cache, GUI configuration files, profile data and preferences, then restart the system. Afterwards, you may try running those xdg-user-dirs-update --set... commands again. If nothing works but your personal folders (Downloads, Documents etc.) exist and are not empty, make a backup of them. E.g. if you plug in a flash drive mounted at /media/cosmin/BACKUP, then you can run this command: sudo cp -R ~ /media/cosmin/BACKUP ...or you may prefer to copy folders one by one: sudo cp -R ~/Downloads /media/cosmin/BACKUP sudo cp -R ~/Documents /media/cosmin/BACKUP sudo cp -R ~/Pictures /media/cosmin/BACKUP ...and so on. After the backup, use the control panel in order to: Create a new user account and give it administrative privileges (this is gonna be your new account). Then delete the (now old) account "cosmin". Copy the contents from your backup back to your personal folders. Note: do NOT overwrite the folders! E.g. if the new account is cosmin2, then instead of copying /media/cosmin/BACKUP/Downloads over /home/cosmin2/Downloads, you'll have to access /media/cosmin/BACKUP/Downloads and copy everything that's inside this folder, then paste them inside of /home/cosmin2/Downloads.
2018126	Is there some kind of "subdomain listing" query for DNS? There is no query for this specific purpose, but there are a few indirect methods. A non-incremental zone transfer (AXFR). Most server operators lock down zone transfers to specific IP addresses to prevent unaffiliated parties from snooping around. If DNSSEC is enabled, iterative NSEC requests can be used to walk the zone. NSEC3 was implemented to make zone walking more computationally intensive. There's also a trick that will let someone know if an arbitrary subdomain exists. example.com. IN A 198.51.100.1 www.sub.example.com. IN A 198.51.100.2 In the above example, www lies within sub. A query for sub.example.com IN A will not return an ANSWER section, but the result code will be NOERROR instead of NXDOMAIN, betraying the existence of records further down the tree. (just not what those records are named) Should secrecy of DNS records ever be relied upon? No. The only way to reliably hide data from a client is to ensure that it can never get the data to begin with. Assume that existence of your DNS records will be spread among whoever has access to them, either by word of mouth or by observing the packets. If you're trying to hide records from a routable DNS client, You're Doing It Wrong™. Make sure the data is only exposed to the environments that need it. (i.e. use privately routed domains for private IPs) Even if you have such a division set up, assume that knowledge of the IP addresses will be spread around anyway. The focus on security should be on what happens when someone gets the IP address, because it's going to happen. I'm aware that the list of reasons for IP address secrecy being a pipe dream could be expanded on further. IP scanning, social engineering...the list is endless, and I'm mostly focusing on the DNS protocol aspects of this question. At the end of the day, it all falls under the same umbrella: someone is going to get your IP address.
2380369	It's not just the number of lumens you have (*) -- its the distribution. You need to aim your light at the ground at an appropriate angle, not into the eyes of motorists. If you have something like a flood light like the coast guard uses, thats no good to aim -- bicycle-specific lights will be easier to aim in a proper manner. If your light is aimed properly, pedestrians shouldn't really have a problem as well and you shouldn't be blinding cars. Look at the beamshots on @nhinkle's bikelightdb for seeing what appropriate aim looks like. (*) You didn't mention the model of light. Just because it says x lumens doesn't mean you're getting x lumens. Also, in regards to distribution, there were some cheap Chinese lights (~10-20 USD) which had very high light output and were very cheap a few years ago (used big batteries and stuff). These were somewhat problematic as you couldn't aim the beam. An aside: As a driver, I find these new blue-white LED lights on Audis and similar a bit distracting. So the color can be a bit distracting, but no bike light is nearly that intense anyway so the point is somewhat moot.
2408399	Manual transmission BOXES last much longer than automatics. The clutches, however, vary with the driver. If the driver is good, then the manual is just as good as the automatic. If not, then the automatic's clutches will last longer. This is true because there is at least one clutch for each gear in an automatic, and you can't replace them without rebuilding the entire transmission. You also can't normally operate the transmission if even one of them is unserviceable...they will cause the others to fail. Cost of rebuilding is $1000-$2500. The manual has one large clutch. Replacing it requires temporarily removing the entire transmission. But good manual transmission drivers commonly have clutches that run over 100,000 miles (or even many hundreds of thousands). Cost of replacing a clutch is $450-$600. The clutch itself only costs $100-$150. The rest is labor. The way to make an auto transmission last longer is to keep the fluid cooler. For most systems this involves a separate transmission cooler unit, possibly a cooling fan, and one of various types of transmission temperature sensor and gauge. Yes. It is more expensive to maintain an automatic because it will eventually require fluid and filter changes which may not be within the capability of a Do-It-Yourself-er. The automatic will also be less fuel efficient in otherwise identical vehicles, by the very nature of the automatic's fluid coupling with the engine through the torque converter versus the manual transmission's physical coupling through the clutch. You should note that Automatic transmission fluid change may not be required for the first 100K miles in some models. Materials in models that can be changed by a DIY-er usually cost $30-60 for fluid and about $20 for filter and gasket. For a shop to do it usually costs from $100-$300 (or even more) depending on the transmission. But it is rare for an automatic to go much beyond 150K miles or so without a rebuild...because of the accumulated effects of heat on clutch material, soft parts, and normal wear on springs that most manuals don't have. The way to extend that time is by controlling transmission temperature. So your friend is right, if we are talking about a driver who does not drive in a way that burns out clutches, and if he is going to keep the vehicle for a long time. Otherwise...it depends on how many clutches he burns out. Or you might be right, if we are talking about stop-and-go traffic in an auto with a great transmission cooling system, or if you only intend to keep the vehicle for 30K or so miles as most people do.
212506	I think the easiest way to do make physical contact impossible is for one (or both) species to evolve beyond the corporeal state. Your species might even be subspecies rather than independent species. Moreover, the story can be scientifically plausible. For example, several centuries ago your humanoids finally managed to upload their minds to a global network. Half of the population decided to abandon their bodies and continue existence in a digitised form. The other half, 'naturalists', opposed them claiming that this decision goes against everything humanoids stand for... The Great Schism led to a long war with countless victims. But eventually, there were no more 'digitisers' left that could be killed. 'Naturalists' went back to 'natural and sustainable' lifestyles, while 'digitisers' enjoy their perfect virtual reality. However, they still hate each other, even though even virtually immortal 'digitisers' are starting to forget what was all the fuss about...
402988	Karlon Stark's split was a thousand years ago. So that's a thousand years separation of bloodline. For some reason we have seen no cadet Stark houses, and their absence is something of a mystery. But even if Ned Stark's family is indeed the last pure blooded Starks, there are still many families that have married into the Starks and may lay claim should the Stark line become extinguished. The Westerlings may claim it through marriage to King Robb Stark, although the circumstances surrounding the whole deal might put a spanner in the works since you'll probably need the support of the North to hold Winterfell. The Tullys through marriage with Ned Stark is another claimant, and while we don't know who Ned's mother was her house would be another claimant.
834948	Main references: Courses on deep learning: Andrew Ng's course on machine learning has a nice introductory section on neural networks. Geoffrey Hinton's course: Coursera Neural Networks for Machine Learning (fall 2012) Michael Nielsen's free book Neural Networks and Deep Learning Yoshua Bengio, Ian Goodfellow and Aaron Courville wrote a book on deep learning Hugo Larochelle's course (videos + slides) at Université de Sherbrooke Stanford's tutorial (Andrew Ng et al.) on Unsupervised Feature Learning and Deep Learning Oxford's ML 2014-2015 course NVIDIA Deep learning course (summer 2015) Google's Deep Learning course on Udacity (January 2016) NLP-oriented: Stanford CS224d: Deep Learning for Natural Language Processing (spring 2015) by Richard Socher Tutorial given at NAACL HLT 2013: Deep Learning for Natural Language Processing (without Magic) (videos + slides) Vision-oriented: CS231n Convolutional Neural Networks for Visual Recognition by Andrej Karpathy (a previous version, shorter and less polished: Hacker's guide to Neural Networks). Toolkit-specific tutorials: DL4J (Java) Theano (Python, Y. Bengio) Machine Learning with Torch7 (Lua, LeCun) H2O Deep Learning (Java) Caffee (C++, UCB) Nervana’s Deep Learning Course
1043024	No. (Unless your definition of equality does not extend past »It is a text interface and I can run programs from it.«) What is run when you click Command Prompt in the Start Menu is the Windows Command Processor, a.k.a. cmd.exe. Its built-in commands and scripting syntax (including many quirks) are based on the ancient command.com from CP/M and later MS-DOS, but apart from that they are completely separate things. Also, command.com is a 16-bit program while cmd.exe is a native Windows console application. Things were different in Windows 95, 98 and ME where command.com would be run in a MS-DOS VM with Windows acting as the hypervisor (yes, they had that sort of thing at the time already). There you had an entire virtual machine running DOS. But on Windows NT, 2000, XP, Vista and 7 – no. DOS only lives on there in ntvdm.exe which is the NT Virtual DOS Machine which is just a thin emulation layer capturing calls that the CPU cannot execute directly (which is why it works faster but worse than DOSBox). In any case, even command.com was just a shell for DOS. It wasn't the operating system. Inside, I actually cringe each time I see people referring to a window with gray-on-black text as MS-DOS. In the vast majority of cases they don't actually know what they're referring to.
1231122	Outbound means you initiate the connection and the traffic starts flowing outward of your computer to the destination you intended. Example you connect to a server. Inbound means someone else from outside of your computer initiate the connection to your computer, so the traffic starts flowing inward to your machine. Example your server gets requests from people. This doesn't mean the actual dataflow. Inbound doesn't mean always inward traffic, and outward doesn't mean always outward traffic, because ports like TCP needs both directions in order to establish the connection, and therefore Windows firewall doesn't block one direction, but the direction of the person or the device that starts the dataflow. So if you only block outbound traffic of Chrome, it means Chrome can't initiate traffic to outside, but Google can initiate traffic to Chrome.
2358452	This is two three-way switches from the looks of things, but wired in a nonstandard fashion From the wires you have, this does appear to be a fairly basic three-way switch circuit with both switches on loops from the light fixture, but with the way the second switch is wired, and the way you were able to get it working, it's not a standard three-way switch. Instead, it's what's called a "California" or "Coast" 3-way setup that brings always-hot to a traveler terminal on both switches and switched-hot to the other traveler terminal on the switches, then connects their commons together. This yields a working 3-way switch arrangement, as depicted below (illustration courtesy of Wtshymanski/Wikipedia), and has the advantage of providing always-hot and switched-hot at both switch locations, but has the downside that you can't add another switch to it.
500870	It's important to realize that "bridge camera" is not a technical term. It's a marketing term *, made up to sell more-expensive cameras to intermediate photographers who are beyond point and shoots but are intimidated by the cost or complexity of a SLR. Generally, the things sold as bridge cameras are bulky point and shoots which kind of look like they might be an SLR. Usually, they have superzoom lenses built-in. Somewhat ironically (or maybe just unfortunately), this isn't what someone needs if they really wants a "bridge" to go from naïve to knowledgeable photography. There's a little more on this in the answers to this question Is there any bridge camera with an interchangeable lens? (To which the answer is: by definition, no.) I think this term really should be obsolete in this decade, as the market has many great actual intermediate cameras that are definitely not point-and-shoot in the sense of no control or advanced functionality. The new Canon G1 X, which has a large (basically micro-4/3rds sized) sensor but a non-interchangeable zoom lens is a poster-child for this, but also pretty much all the lower-range mirrorless interchangeable lens cameras too. Basically, there's a whole bunch of advanced cameras which are not DSLRs but also beyond point and shoot. One could apply the term "bridge" to all of these, but I don't think it's very useful. I recommend ignoring this term and talking about specific cameras (or groups of cameras — all the small-sensor superzooms are basically identical) or specific features (like a large sensor in a compact camera body). * See newspaper article from 1998 about the "new" type of camera.
956540	Even though the BIOS isn't detecting a system fan doesn't mean there isn't one. Not all fans, especially on older systems, are designed to actually transmit data to and from the BIOS, so it's possible you have a model that just turns on when there's power supplied to it, and shuts down when there's not. The only real downside to having a dumb fan rather than a smart fan, other than the disconcerting "0 RPM" message, is efficiency. A dumb fan will be on all the time, whether or not your system actually needs it. With smart fans, the BIOS can turn it on full during heavy use, shut it down when the system's idle, and warn you when it's not working properly. Even if it's missing entirely, it's not 100% necessary unless your system has a tendency to overheat without one. Older computers in general don't generate near as much heat as modern systems, so their cooling requirements are far less imposing than anything you'd find today.
1147141	Black and white (monochrome),has only two "colors", black (ink or toner) and white (no ink or toner). It is used for things like text, where you want everything that is a printed character to be black and the background white (unprinted). Grayscale contains shades of grey and is used for reproducing images. In photographic and similar processes, it is a continuous scale from black to white. On consumer laser and inkjet printers, the printer creates the shades using patterns of micro-dots that generally require magnification to see. These patterns are typically designed to reproduce approximately 256 discrete shades. On a multi-function printer, say you want to photocopy some text. When you scan the page, the paper and wrinkles will have some color (not pure white), and areas of the text might be faint. If you print that in grayscale, you will get an accurate "photograph" of what the scanner saw. If you want maximum readability, you would use black and white, which would force everything darker than a certain threshold to black and everything else would be white. This will be easier to read and a better representation of how the original came out of the printer.
1693487	One could solve the issue in the following way: cat file | some_sed_command | tee file >/dev/null No. The chances file will be truncated drop, but there's no guarantee cat file | some_sed_command | tee file >/dev/null will not truncate file. It all depends on which command is processed first, as as opposed to what one may expect, commands in a pipe are not processed left-to-right. There's no guarantee about which command will be picked first, so one might as well just think of it as randomly picked and never rely on the shell not picking the offending one. Since the chances for the offending command to be picked first in between three commands are lower than the chances for the offending command to be picked first in between two commands, it's less likely that file will be truncated, but it's still going to happen. script.sh: #!/bin/bash for ((i=0; i<100; i++)); do cat >file <<-EOF foo bar EOF cat file | sed 's/bar/baz/' | tee file >/dev/null [ -s file ] && echo 'Not truncated' || echo 'Truncated' done | sort | uniq -c rm file % bash script.sh 93 Not truncated 7 Truncated % bash script.sh 98 Not truncated 2 Truncated % bash script.sh 100 Not truncated So never use something like cat file | some_sed_command | tee file >/dev/null. Use sponge as Oli suggested. As an alternative, for thighter environments and / or relatively small files one may use a here string and a command substitution to read the file before any command is run: $ cat file foo bar $ for ((i=0; i<100; i++)); do <<<"$(<file)" sed 's/bar/baz/' >file; done $ cat file foo baz
2104867	No DNS records are required to send email, however, not having appropriate mail-related DNS records for your domain is likely to result in getting discarded by spam filters. Your shop.mydomain.com server should be probably be treated as a host authorized to send mail rather than as a child domain. I know of at least one service that will up the spam probability score if an MX record is not present for the domain. Having other DNS entries, like valid PTR records for mail servers and records for Sender Policy Framework (SPF) and DomainKeys Identified Mail (DKIM) for the domain will also help. There is a good article by rackAID, 3 DNS Records Every Email Marketer Must Know, that outlines the basics of DNS interaction with spam filtering.
2223587	I'd try and be more specific towards the kind of the fuel we are talking about: White Gas / Naphtha Burns clean without any smell and/or effect on food taste. Accidental Spilling of the fuel is not much to be worried about. Evaporates very quickly, without leaving an odor. That said, make a note that the spilled fuel is very flammable White gas is safer to store and transport than probably most of the other products. Additional information: White gas is a more volatile distillate of petroleum, to which no poisonous automotive-oriented chemicals have been added. It is much safer to store and use, with far superior shelf-life than gasoline/petrol (https://www.britannica.com/science/naphtha). Propane/Butane/Isobutane Gas A Propane gas stove would most likely be a Canister type? So, pressurized fuel? : Might be more dangerous if canister is leaking? Most of the products that are available are the ones that work on Propane and Primarily Isobutane. They burn hot and clean. Pressurized fuel = No Pumping, preheating required. No spill play at all as the canister holds the pressurized gas, so self-seals when the stove is detached: Safe! As you don't pour the fuel into the canister yourself, its difficult to gauge remaining fuel level. Performance degrades when the fuel is consumed beyond a certain level because the pressure is not enough to inject the fuel into the jets. Take an example of a aerosol deodorant. So, when nearly emptied, the remaining fuel is apparently useless. Fuel is more expensive. If its Butane, it doesn't work in freezing conditions. If its Propane, it will work under conditions roughly upto -32 C. I know someone who has used it at that temperature. Kerosene Stove function really well in extremely cold temperatures. Burns hot, better than Alcohol stoves. Relatively inexpensive fuel. Needs proper storing, since it evaporates slowly if spilled. Prone to spills during the pouring process. But, spilled fuel won't ignite easily. Not Odorless. Many of the Kerosene based stoves need pumping and pre-heating. Some points about common terms used in different parts of the world. Thanks to A E for suggesting this concept and the data provided. I have done a mere copy+paste from comments. It would be helpful if this question/answer also contains the translation for non-American readers. In the UK, 'Coleman fuel' is same as what is known as 'White Gas' in America. 'Propane' and 'Butane' are two universal terms for two different chemical compounds. (Some people find it hard to understand what this means, So, it means, Propane is not equal to Butane, those are two different chemical comppounds. The compound which people around you call as 'Propane', probably almost everywhere in the world its called 'Propane', same goes for a different compound called Butane.) US 'Kerosene' is UK 'paraffin', the same in India is 'Kerosene' and more popularly known as 'Rockel'. US 'Gasoline' is UK 'Petrol'. In the UK, they also have 'White spirit' which should not be confused with 'White gas', it's not the same thing. 'White Gas/Coleman Fuel' is called 'Naphtha' in Eastern Canada, and English-speaking chemistry labs.
2258568	A pulse is the heartbeat of the rhythm/music that you hear - and feel - when listening to music and this is what people usually tap along to when listening. The beat is the repeated note value of the time signature. They can often (and are usually) the same thing, or at least they cross over. However I shall give some examples: In a piece with time sig 4/4, the beat is 4 crotchet beats every bar. The pulse is most likely also going to be this however if some notes are more pronounced you may tap your foot 2 beats/bar. In a piece with time sig 6/8, the beat is 6 quaver beats/bar whereas the pulse is usually 2 beats/notes at intervals of dotted crotchets. It will be felt as: 1-and-a-2-and-a, 1-and-a-2-and-a, etc. where '1' is where you tap your foot, the pulse.
911574	YES. A micro-atx motherboard will work fine with an ATX case and power supply. Atx cases normaly included the standoff mounts for smaller mirco-atx motherboards. In fact, I have a micro-ATX motherboard in a full size ATX case and power supply. MicroATX was intended to be backward compatible. http://en.wikipedia.org/wiki/MicroATX microATX was explicitly designed to be backward-compatible with ATX. The mounting points of microATX motherboards are a subset of those used on full-size ATX boards, and the I/O panel is identical. Thus, microATX motherboards can be used in full-size ATX cases. Furthermore, most microATX motherboards generally use the same power connectors as ATX motherboards,[6] thus permitting the use of full-size ATX power supplies with microATX boards. microATX boards often use the same chipsets (northbridges and southbridges) as full-size ATX boards, allowing them to use many of the same components. However, since microATX cases are typically much smaller than ATX cases, they usually have fewer expansion slots.
1006946	Cluster Slack Space You cannot access each individual byte on a storage medium separately. To do so would be terribly inefficient because the system needs some way of keeping track of which ones are used and which are free (i.e., a list), so doing so for each byte separately would create too much overheard (for each individual byte, i.e. 1-to-1, the list would be as big as the medium itself!) Instead, the medium is broken up into chunks, blocks, units, groups, whatever you want to call them (the technical term is clusters), each of which contains a—consistent—number of bytes (you can usually specify the size of the clusters since different uses call for different sizes to reduce waste). When a file is saved to disk, the size of the file is divided by the cluster size and rounded up if needed. This means that unless the filesize is exactly divisible by the cluster size, some of the cluster ends up being unused and thus wasted. When you view the properties for a file, you see the true size of the file as well as the size it takes up on disk which includes any “slack”, that is, the “cluster tips” that are unused. This is usually not much per-file and the size on disk will usually be almost equal to the actual size, but when you add up the wasted space from all the thousands of files on a drive, they can add up. Therefore, when you view the size of a large folder, especially one with many tiny files that are smaller than a cluster, the size on disk (i.e., the amount of disk space marked as used) can end up being significantly larger than the actual size (i.e., the amount space the files actual require). In a case like above, what you can try is to reduce the cluster size so that each file wastes less space. Generally, a drive with mostly lost of little files should use the smallest cluster size possible (to reduce waste) and a drive with mostly large files should use the largest cluster size possible (this way the bookkeeping structures end up being smaller). Even at a lower level, if each cluster is only a single sector, unless a file is an exact multiple of the size of the sectors on the drive (usually 512 bytes traditionally, now often 4,096 with Advanced Format disks), then there will still be unused space between the end of the file and the end of the sector. Compression Another scenario where you might see a difference between the actual file size and size on disk is with compression. When a drive is compressed (e.g., using DriveSpace, NTFS compression, etc.) then there will be a difference between the size of the actual file (which needs to be know), and the actual size that the file occupies (i.e., uses or “takes up”) on the disk. Shortcuts and Hardlinks Yet another scenario that could result in a difference is with hardlinks. With file-systems that support hardlinks, when a duplicate file is created, instead of making a whole new file that takes up space for itself, the file-system creates a shortcut to the file so that both (or all three, etc.) copies point to the same physical file on disk. Therefore, when there are two files pointing to the same data, they each have the same size, but take up only slightly more than the space to store a single copy.
1165140	I think this is much more complex than a single answer. There are many different types of Bluetooth connections, not all of these connections are interchangeable. It also depends heavily upon which version of Bluetooth is being used in the devices, both the reciever for the PC and the controller. As you can see from the Bluetooth 4.2 specification, which is 2,772 pages, it is quite complex. Bluetooth 4.2 specification document: https://www.bluetooth.org/DocMan/handlers/DownloadDoc.ashx?doc_id=286439 I doubt a definitive answer can be given to this question as to all Bluetooth devices in all scenarios. I would however in this case as it's quite a simple scenario, purchase a single Bluetooth adapter and try to connect four controllers. I suspect that it will work from what I have deduced from the Bluetooth specification but I would ensure that you purchase a 4.2 Bluetooth adapter. Apple Website FAQ The official Bluetooth specifications state seven is the maximum number of Bluetooth devices that can be connected at once. However, three to four devices is a practical limit, depending on the types of devices and profiles are used. Some devices require more Bluetooth data, so they are more demanding than other devices. Data-intensive devices may reduce the total number of devices that can be active at the same time. If a Bluetooth device becomes slow to connect or does not perform reliably, reduce the total number of connected devices. Apple Website Bluetooth FAQ As can be seen from the official Apple website they state that the maximum number of connected devices is 7. The official Bluetooth spec says that up to 255 sleeping devices can be connected. This would indicate that the maximum number of parallel active connections is 7, however due to the complexity of the connections and amount of data to be transferred in most scenarios the practical limit is 3 or 4. Bluetooth signal can also be effected largely by other household devices such as Wifi, Microwaves and Household Phones. A true answer to this would be difficult to come by in relation to your exact scenario due to the large number of variables, however we can see that theoretically seven devices can have active connections in parallel and as reported by Apple the practical limit in the majority of scenarios is 3 or 4.
1571996	In theory, an Android phone doesn't need a computer to upgrade. In practice, this is usually the case - all I had to do to upgrade was home, menu, settings, about phone, software version, check for updates, apply. (It was something like that, but it's also sometimes a little different by phone as well.) It should be noted that occasionally, a company will force you to use their proprietary desktop software to upgrade your phone. They will almost certainly distribute their software for only Windows, and so unless it works in WINE or Mono it won't work in Linux. What kind of Android phone do you have? Also, if you plan on rooting and using a custom ROM, all you need for this is to put the ROM on the micro-SD card in the phone, which can be done on whatever OS you like. Again, it's an entirely phone-contained process after you root. Rooting works on Windows, Mac, and Linux; you need to have the android SDK setup and Mono set up and use SuperOneClick.
2411982	There is a recall on my car, but I'm so far ignoring it. There is a recall on your car. Do not ignore it. This is not a task an amateur can tackle, but an amateur can bring their vehicle to their dealer to have the defective parts professionally replaced and the problem solved without compromising vehicle safety or legality. Is disabling, or even removing, the two inflators a task that an amateur can tackle? Note that given the relatively low incidence of defective parts (see also the airbag-related injury note in the article you linked to, noting also the seriousness of the "Who should consider..." section), combined with other chances, you are replacing an extremely low, albeit highly sensationalized, safety risk (potentially defective airbag) with an extremely high safety risk (no airbag), a high risk of performing the procedure incorrectly, and an extremely high financial risk of voiding your insurance in certain jurisdictions (which also places other vehicles involved in the collision in high financial risk, as well as presents possible difficulties for injured persons seeking medical care). This is not a sensible trade. That is not to say that the defects should be ignored or are not important. However, the solution is to honor the recall to correct the problem while maintaining safety, not to disable safety. However, the choice is yours as are the potential consequences. If you insist on proceeding with what appears to be an objectively misguided plan, I would first consult the service manual for your specific make and model of vehicle, which will give you the technical details you need, as it will differ per vehicle. You may at least want to inform your passengers that you have disabled their airbags to allow them to make their own informed choice about whether or not to get in the car with you.
2422778	The fitment front and rear are going to be extremely different. Not only is the diameter and braking surface completely different sizes, the rear disks have a separate machined area inside the hat (the part where it attaches to the hub) which is used for the parking brake. The front one has no such provision. For your husband's 2000 Chevy Silverado, the following are different rear brake rotors by part numbers: Economy: Durago - PN: BR55066 Bendix - PN: PRT5265 Centric - PN: 12166041 Power Stop - PN: AR8641 ACDelco - PN: 18A952A Daily Driver: Bosch - PN: 25010532 Centric - PN: 12066041 Raybestos - PN: 56827 ACDelco - PN: 18A952 Heavy Duty: Bendix - PN: SDR5265 ACDelco - PN: 18A952SD You should be able to look these up on Amazon, RockAuto.com, or just Google the part numbers. I had thought the Silverado/Sierras came with either drum or disks, but I'm not seeing a drum listed for the 2000 model year. My 2006 and my son's 2005 Silverados both have drum rears. Before you order anything for your husband's truck, ensure it has disks.
43156	UPDATE February 01, 2018, the OED has recently added the word swag in its dictionary. Oxford Online Dictionaries reports A new entry has been added for swag, derived from swagger, and used in slang to denote ‘bold self-assurance in style or manner’, or ‘an air of great self-confidence or superiority’. The OED’s first citation for this particular sense comes from the track ‘December 4th’ on Jay-Z’s The Black Album (2003): ‘My self-esteem went through the roof, man. I got my swag.’ This is the fifth OED citation attributed to Jay-Z. A glossarial example of the word from the previous year, in a self-described dictionary of hip-hop terminology, defined swag as simply ‘walk’. ORIGINAL POST (October 12, 2016) “Obama displayed similar swag and bluster …” In his sixth State of the Union Address, President Obama said: We’re upholding the principle that bigger nations can’t bully the small — by opposing Russian aggression, supporting Ukraine’s democracy and reassuring our NATO allies. Last year, as we were doing the hard work of imposing sanctions along with our allies, some suggested that Mr. Putin’s aggression was a masterful display of strategy and strength. Well, today, it is America that stands strong and united with our allies, while Russia is isolated, with its economy in tatters. That’s how America leads — not with bluster, but with persistent, steady resolve (Applause). From whitehouse.gov, January 20, 2015 The swag appears to be a clipped form of swagger, which the article accuses President Obama of doing. In the speech, the ‘swag’ refers to America standing strong, unafraid of Russia, and determined to enforce sanctions. The bluster, according to the author, is Obama's words whose tone was possibly concealing a threat to Putin. The fact that Obama asserted America did not engage in bluster, was telling the audience that America was not afraid of taking further action if necessary. bluster talk intended to seem important or threatening but which is not taken seriously and has little effect swagger to walk, esp. with a swinging movement, in a way that shows that you are confident and think you are important Cambridge Dictionary
81132	The primary meaning of unicorn is the mythological animal of a horse with a single horn. Because they don't exist, "a unicorn" represents any unattainable thing. The business sense of a startup company with a valuation of more than $1 billion was formed to express their rarity wikipedia In current British politics, a unicorn is an unattainable thing, often used in discussions about Brexit: "they can promise unicorns without worrying about having to deliver them" Guardian which means "promise the impossible" The usage for describing a girlfriend/boyfriend means "so great she/he is unbelievable" this is quite young US slang: I've never heard anyone say it (UK) [YOUNG US COMMENTERS: if you're a young native US speaker please could you comment about how this is used in your group(s) so I can edit it in here] "Unicorn" has some very specific sexual meanings which vary according to different social subgroups (a simple search will find them) which indicate rarity I'd suggest being very sure of your audience before using "unicorn" except in the primary, business, or political senses.
303274	From page 194 of the Player's Handbook: If the d20 roll for an attack is a 20, the attack hits regardless of any modifiers or the target’s AC. In addition, the attack is a critical hit, as explained later in this chapter. From page 196 of the Player's Handbook: When you score a critical hit, you get to roll extra dice for the attack's damage against the target. Roll all of the attack's damage dice twice and add then together. Then add any relevant modifiers as normal. This applies to all attacks, whether they are melee weapon attacks, ranged weapon attacks, melee spell attacks, ranged spell attacks, etc. If you are rolling a d20 versus AC, then you score a critical hit on a 20, and unless you have a class feature, feat, etc. that says otherwise, you roll damage dice twice when you get a critical hit.
332227	Spells fizzle in Advanced Dungeons & Dragons, 2nd Edition As other answers mention, the word fizzle can be traced back quite a ways, but as a Dungeons & Dragons game term it's the Player's Handbook (1989) for Advanced Dungeons and Dragons, 2nd Edition that I think first uses the word fizzle in an official capacity. On Wisdom on Chance of Spell Failure says Priests with low Wisdom scores run the risk of having their spells fizzle. Roll percentile dice every time the priest casts a spell; if the number rolled is less than or equal to the listed chance for spell failure, the spell is expended with absolutely no effect whatsoever. (111) (Emphasis mine. Page reference from the Player's Handbook (1995); your page numbers may vary.) In other words, in Dungeons & Dragons the term—so far as I can tell originally—was shorthand for what happens when a spell is used but does nothing. The Player's Handbook uses the term again later on Casting Spells but descriptively: [I]f the spellcaster is struck by a weapon or fails to make a saving throw before the spell is cast, the caster's concentration is disrupted. The spell is lost in a fizzle of useless energy and is wiped clean from the memory of the caster until it can be rememorized. (23) (Emphasis mine.) Unfamiliar as I am with the tournament scene at the time, I can't speak to whether the term fizzle was used earlier than 1989 in live settings. By way of personal experience, my last Advanced Dungeons and Dragons, Second Edition campaign was nearly two decades ago, and, while I played a wizard for a decade in that campaign, I've no recollection of any of my PC's interrupted spells fizzling—we just used the word failed. The Player's Handbooks (2000 and 2003) for 3e and 3.5e each use the word fizzle once in a similar descriptive context to the word's second use in Advanced Dungeons and Dragons, 2nd Edition: "[T]he spell fizzles with no effect" (125 and 140, respectively). Note: To go further afield, I suspect the increased popularity of the term fizzle comes from Magic: The Gathering which had a rule about when spells fizzle in one of its early rulebooks. (I think circa 1998 with the original Urza block, but I can't confirm this.) Although the term is considered archaic now, the shared player base of both Wizards of the Coast's major properties can't be ignored.
394169	The title of the previous show Avatar: The Last Airbender was accurate, the Fire Nation had wiped out all Airbenders while Aang was frozen. Tenzin and his 3 children are the only Airbenders left in Korra's time. In the S1E10, Turning the Tides, Lin refers to Tenzin and his kids as "the last airbenders". If you consider the Avatar: The Last Airbender comics canon, then there were some airbenders who survived the initial genocide. They were later lured with the hope of sanctuary, and killed by Admiral Zhao. The others dressed in that garb are Air Acolytes, who are people who seek to maintain the Air Nomad's culture while the Airbender population (hopefully) increases. They do not have the ability to bend.
553759	Have you gone to a library? You might have, and might have observed that the books on same topic are in same stack. Let chemists be the librarian of the library of elements. And he has got to arrange his elements into stacks. Okay? Chemist 1: How do I reduce the disorder in the arrangement of the these elements? Chemist 2: Umm ... we need some criteria. According to that criteria, we will stack the elements. Chemist 3: Let the criterion be electronic configuration. Chemist 4 (looks at you): Do you know about subshells and orbitals? Welcome to the world — sorry, shell — of electrons! An electron shell may be thought of as an orbit followed by electrons around an atom’s nucleus. The closest shell to the nucleus is called the “1 shell” (also called “K shell”), followed by the “2 shell” (or “L shell”), then the “3 shell” (or “M shell”), and so on farther and farther from the nucleus. The shells correspond with the principal quantum numbers (n = 1, 2, 3, 4 ...) or are labelled alphabetically with letters used in the X-ray notation (K, L, M, …). Each shell can contain only a fixed number of electrons. The electron shells are labelled K, L, M, N, O, P, and Q; or 1, 2, 3, 4, 5, 6, and 7; going from innermost shell outwards. Electrons in outer shells have higher average energy and travel farther from the nucleus than those in inner shells. Each shell is composed of one or more subshells, which are themselves composed of atomic orbitals. For example, the first (K) shell has one subshell, called 1s; the second (L) shell has two subshells, called 2s and 2p; the third shell has 3s, 3p, and 3d; the fourth shell has 4s, 4p, 4d and 4f. Each s subshell holds at most 2 electrons. Each p subshell holds at most 6 electrons. Each d subshell holds at most 10 electrons. Each f subshell holds at most 14 electrons. Row 1 contains only the elements that have only the K shell occupied*. Row 2 contains only the elements that have only the K and L shells occupied*. Row 3 contains only the elements that have only the K, L and M shells occupied*. And so on. * Occupied means that shell may or may not be filled, but there certainly are some electrons.
553809	Background The general arrangement of The Periodic Table is a result of the orbitals available to electrons bound to a single, isolated nucleus. Each orbital is described by a wave function, which is a regular function (similar to polynomials familiar to high school algebra) with respect to the $x$, $y$, and $z$ coordinates of space, and describes the behavior of the electrons occupying it. We can find these wave functions (and equivalently: the orbitals) by solving the Schrödinger Equation, which is a differential equation describing the system: one electron orbiting one proton in the case of hydrogen. A system with more than one electron is actually impossible to solve exactly, so we usually just think about hydrogen orbitals. The set of orbitals for any other element is more or less the same as that for hydrogen--just with different energies--so your question can be answered by considering hydrogen alone. Specifics Electrons in these orbitals have 4 characteristics, and no two electrons belonging to a single nucleus can have matching values for all 4 (The Pauli Exclusion Principle): Size Shape Orientation Spin For hydrogen: the size contains all of the information about the energy of the orbital. Denoted by the letter $n$. The shape reflects the angular momentum of the orbital. Denoted by $l$. The orientation reflects one (of three) components of the angular momentum, as a convention: the z-coordinate. Denoted by $m_l$. Unless you care about magnetism, the spin is only important because it allows you to put 2 electrons in one orbital (due to Pauli's principle). Denoted by $m_s$. Since there is an energy associated with angular momentum, the possible values of $l$ for any electron is constrained by its value of $n$. For example: if $n=2$, only $l=1$ and $l=0$ are possible. In the case of the first row elements (in their ground states): $n=1$ so $l=0$ without exception. The numbers of elements in the other rows are a result of rules governing possible orientations, $m_l$, of the orbitals (keeping in mind Pauli's principle, and that two spots are available per orbital due to spin, $m_s$). In case you're curious: if an electron has angular momentum $l=1$, the z-component of its angular momentum, $m_l$ can only have the values $1$, $0$ or $-1$. For $l=2$, $m_l=\{2,1,0,-1,-2\}$, and for the first row: $l=0$ implies that $m_l=0$ without exception. If you write out the number of possible orbitals following these rules: $$n=\{1,2,3,...\}$$ $$n \gt l \ge 0$$ $$+l \ge m_l \ge -l$$ $$m_s=\{-1/2,+1/2\}$$ ...where $n$ corresponds to the row number on The Periodic Table, you will find the pattern that you mentioned in your question. Image Ref: https://en.wikipedia.org/wiki/Spherical_harmonics
651584	There are many ways to answer this question. Basically, your choice is to use either 1) a physically-based model 2) a statistical model 3) a blend of the two (Kalman filter). Since you ask the question here, I assume you opted for 2. Do you have good reasons for that? If so, you need to fit a statistical model to your data, and use it to make predictions. You have 24 stations so a spatiotemporal model is warranted. How wide an area do they cover? How many different climate regimes are there? That will determine how complicated a spatial model you need. The temporal component of that could well be ARIMA: it's often a reasonable choice. Where did you get the idea that it only applied to seasonal data? Whatever you do, the atmospheric concentration of $CO_2$ has to be one of your predictors. If your data show a big trend from 1970 to present, $CO_2$ is the most likely culprit. Other indices of regional climate variability may be relevant too; depends on your region: where are your stations located?
1004495	Some (many) years ago, their Prism converter was good. Now they use their website to hack your computer - or so it seems. I simply updated what I had installed from them (Prism) and then decided to browse through the options...And there was the "TOOLBOX" with very short descriptions of what it supposed to offer. I clicked few links - nothing told me that I am installing applications. A bit later, while I was searching the web, a window comes up asking if I want to change my default searcg engine. I answered "NO" - and shortly after that I see a whole bunch of photoediting, sound-conversion, slide who and hell know what else installed on my computer. To top it off – the home page of both browsers I use changed to NCH, the Google Toolbar was replaced with something from NCH – of course, without anyone asking my permission. And that is with antivirus running. When I tried to uninstall the unwanted software using Windows Control Panel, the programs refused to uninstall, informing that I should finish the previuos "installation". (probably, another malicious code did not finish running by the time I switched off the internet connection just in case). I removed the NCH add-on in Firefox, changed the home page back to what it was – but when I restart Firefox, everything is back – which means the NCH gadgets and their home page. I had better luck with Explorer – there it cleaned up the NCH from the first try. Now back to uninstalling. I found the NCH folder and in the subfolders there (some 5 or 7 of them) were separate uninstallers for each one of their wonderful programs. Just one of them worked – the rest asked you for a feedback, tell you that all is uninstalled – and nothing changed. So I cleaned the registry with regedit – searching for "NCH Software" and other names in their folders and deleting each one of them. Still did not fix the Firefox. Now I have to run a deep virus scan and perhaps, restore the system to some previous points.
1338390	Yes, some diodes in the package shown will comfortably be able to handle 1 kV reverse standoff, and 10 Amperes forward current, at a typical ~1 Volt forward voltage. The two values are not applicable simultaneously, the first is for blocking and the second is for conduction. Adding a heat sink, a simple copper band looped around the diode body, would be recommended - The diode datasheet if you had one would typically tell you thermal dissipation ratings and required heat sinking for the rated forward current. I have some unmarked high power Schottky diodes in a similar package that can cope with 15 Amperes sustained current flow in forward bias, and the real problem I'm seeing is solder melting and flowing at the PCB junctions every now and then.
1649123	It turns out (he answered himself) that this functionality can be adjusted with CompizConfig Settings Manager. (To install CompizConfig, enter sudo aptitude install compizconfig-settings-manager from a terminal. It's also, as of this writing, available through the Ubuntu Software Centre.) To adjust the transparency of non-active windows (note these instructions have only been tested on version 14.04): Start CompizConfig. Go to the Effects menu (either click on Effects in the left pane or click All and scroll to the Effects section) Click TrailFocus. Its description is "Adjust the opacity, saturation and brightness of windows based on when they last had focus." Here you can choose either The Behaviour tab, to configure which window types (e.g. toolbar, utility, dialog, normal) that TrailFocus will affect the number of windows that TrailFocus will track (beyond which number it will consider a window "completly (sic) unfocused") which window in the switcher stack to start fading The Appearance tab, to configure the opacity, brightness and saturation levels of both focused and unfocused windows
2219998	I personally highly recommend using an alcohol stove (pepsi-can stove, or some other variant), especially when hiking solo. In my opinion, the weight benefits far exceed the disadvantages. The benefits of Alcohol*: An alcohol stove is usually much lighter than a comparable white gas/propage/kerosene/gasoline. An alcohol stove also has no moving parts that can malfunction. Quite reliable. Can be easily made even in the field, using two soda cans and a sharp knife. Alcohol is relatively easy to come by and better available than most butane canisters Disadvantages: Usually takes longer to boil water than more traditional stoves. In higher altitudes/colder weather it takes longer to prime the stove and get it going. In such conditions it will also take longer to boil the water/meal. (*We are talking about stove fuel here, not about drinking the stuff...)
2247931	The major intervals 2, 3, 6, and 7 come indeed from the major scale. However, as you noted, the corresponding minor intervals do not come from the (natural) minor scale, because then there wouldn't be any minor 2nd interval. All minor intervals can be obtained from the descending major scale. If we use C major as an example, a minor 2nd is the interval between C and the B below the C. A minor third is the interval from C down to A, a minor 6th from C down to E, and, finally, a minor seventh from C down to D. Equivalently, you get all the minor intervals (2, 3, 6, 7) from the phrygian mode, which is an inverted major scale in the sense that the sequence of intervals when ascending is the same as the sequence of intervals of a descending major scale.
2371424	I've already answered this question, but this is a different answer; I've recently started using a website called Strava (they do also have iPhone/Android apps as well as accepting GPX uploads which can be generated by many platforms and devices - I use MotionX-GPS for the iPhone). Their (I think unique) central point is to allow users to defined specific 'segments' of their ride and then anyone whose uploaded route passes over that segment is included in a virtual league table. This allows you to easily compare yourself to others over short routes, climbs, sprints and so on. So long as you cycle in reasonably populated areas, you'll be amazed at how many segments your ride already covers, at least around the London area, I was. (I've no connection to the website, apart from being a satisfied, paying customer.)
2377199	The parts that Blam refers to are known as the pawls and the ratchet inside the freehub. Slipping can happen for a number of reasons, including worn ratchet, worn pawls, weak springs, or excessive accumulation of grease & grime within the freehub. http://dirtmountainbike.com/features/work-freehub-body.html has a thorough explanation of the different freehub types. Depending on the hub you have, a repair consists of either cleaning, rebuilding or replacing the freehub. Some freehubs are rebuildable, others are not and must be replaced as a unit. That said, it's often possible to extend the life of a non-rebuildable freehub by flushing out the old grease & gunk and regreasing. The mechanic at your local bike shop can almost certainly take care of this for you. If you're more of the do-it-yourself type, http://www.parktool.com/blog/repair-help/freehub-service has step-by-step instructions for several different freehub types.
2380376	If your main worry is being seen by cars, then a superbright light isn't really the way forward. Besides being dazzling/blinding, a front light does very little for visibility from the sides and from behind, from which many (most?) collisions occur. A front light helps your visibility mainly when a car pulls out of or turns into a side road across your path while you approach. In my experience, in most of these cases the problem isn't that the driver didn't see me, but that they had difficulties judging my speed. Also, these are cases where I can mitigate some of the risk by reading the situation, observing the car (are they starting to move?) and being ready to brake. A front light doesn't protect you against close overtakes, right hooks (UK: left hooks) and all the other frequent types of collisions. If you are worried about visibility, then it's better to wear hi-vis and add reflectors or possibly several smaller, cheap lights on different parts of the bike. For the driver, one superbright light is just one point, whereas hi-vis, reflectors and several smaller lights will outline the shape and size of your bicycle and help drivers to judge distance and speed. I've also seen the suggestion to have a small light on the top tube that points at yourself to light up your own shape. The only real use for a very bright light is a dark unlit path (without pedestrians) where you want to see where you're going. If you go along unlit paths a lot, I would invest in a light with a proper shaped beam, like the B&M models, that light up the path properly but don't dazzle other users. I agree with everybody else that dazzling other users is a very bad idea, for many reasons (your own safety as well as etiquette).
271822	Because every living being still generates mana, as long as it is alive Whatever is living, for the same fact that it is alive, accumulates mana. The old machines kept the beings alive for thousands of years, which means that it could extract whatever mana they had at the beginning of the process, plus whatever mana they could generate (of course a smaller amount than in free life) in the course of the following years. Say that a being has 1.000 mana when it is captured. An amount of 2 mana per year is extracted from it, but in the meantime, it still could generate 1 mana per year. This means that you will need about 1.000+t-2t=0, so t=1.000 years to be depleted, while the evil lord has gained a total of 2.000 mana. Part of this is leaked, let's say 10%, so that the net amount is 1.800 mana. If the new model can extract 100 mana per year, the time for a full depletion will be a little more than 10 years, and the lord will gain 1.010 mana (without leak). So, at the beginning, the evil lord will be happy, because he will see an improved flow of mana, but when the process reaches its operating speed, he will discover that the average amount has been basically halved...
337937	Elves cannot naturally grow a beard Elves do not grow facial hair, according to the D&D 5th edition's Player's Handbook (p.21): Elves have no facial and little body hair. The item description says: you have a 50 percent chance each day at dawn of growing a full beard if you're capable of growing one Therefore, an elf cannot grow a beard even with this particular item. Although half-elves are described as able to grow beards, I'm unaware of any D&D product of any edition featuring a full elf with a natural beard. Earlier editions You asked in the comments about how elf chins were handled in previous editions of the game. D&D 4th edition's Player's Handbook (p.41) is less clear than its 5th edition counterpart, but the 4th edition book Wizards Presents Races and Classes confirms that male elves don't have beards: Elves retain several of their distinguishing characteristics from earlier editions, most notably the pointed ears and the slight tilt to the eyes. And male elves don't have facial hair. Remarkably, D&D 3rd edition actually has an explicit rule covering this case: elves cannot grow beards, but in at least one case, dwarven magic which causes beard growth still affects them normally. According to Magic of Faerun, p.117, the spell silverbeard: Your beard grows and turns to pure and magically hardened silver, increasing the armor bonus of your armor by +2. An outfit of regular clothing counts as armor that grants an AC bonus for the purpose of this spell. If you do not have a beard, you grow one for the duration of this spell (even if you are a creature that cannot normally grow a beard, such as an elf or a female human). You get a +2 circumstance bonus on Diplomacy checks against dwarves. Since the Forgotten Realms setting generally remains consistent between game editions, it is reasonably likely that the elves' complete inability to grow a beard described (rather than some kind of strict racial tradition of shaving regularly) also applies to the elves other editions of D&D, at least for that world. Editions prior to 3rd are unclear as to whether elves have beards. In AD&D 1st and 2nd edition's respective core rulebooks they are not described as having beards, but neither are they described as unable to grow beards in those editions of the game.
391438	JKR has said that Draco was "sobered" by his experience as a Death Eater, and that he does not owe Harry a life debt. Draco marries Astoria Greengrass, the younger sister of Daphne Greengrass, Draco's classmate. They have one son named Scorpius Hyperion Malfoy, who JKR has said has a lot to overcome, not the least of which is his name (she meant Malfoy; I thought Scorpius was worse than Malfoy ;). Draco is never a "nice man." He does acknowledge Harry in the Epilogue with a curt nod; JKR says that under no circumstances could Draco and Harry be friends. Here's a funny quote about Draco: Q: Does Malfoy owe Harry a debt? JKR: That's a great question and a lot of people wanted to know that. When Dumbledore said to Harry, Voldemort won't want a close associate who is in your debt, I wasn't implying by that there was any kind of magical bond there. It was more that Dumbldore's extensive wisdom and knowledge of human nature, he knew as Harry later thinks in book seven, he knew that Pettigrew would react a certain way to having saved his life. ... He's weak, fundamentally weak. Pettigrew is a very weak character. He's not someone I like at all. He's a weak person and he likes to gravitate to people who are stronger. Dumbledore is right. Pettigrew had an impulsive mercy... would Malfoy be in Harry's debt? I think the very worst burden Harry could have put Malfoy under was this one, that Malfoy has to feel any kind of gratitude. So I tried to show that slightly in the epilogue when they look slightly at each other and there's a, "Hi. It's so embarrassing, you saved my life. No one will ever let me forget it." I think, does he owe him a debt, probably not. I think Malfoy would go back to being an improved version of what he was but we shouldn't expect him to be a really great guy any time soon. JK Rowling at Carnegie Hall 10.20.07
478749	I think they could get into Hogwarts because Myrtle’s parents (who were muggles) got into Hogwarts to get her body. if Muggle parents can’t get into Hogwarts, how do they visit their child if a Muggle-born got into the Triwizard Tournament? So, yes: Muggle parents could get into Hogwarts but only if needed. I don’t think there’s a parent-teacher meeting at Hogwarts because - well, what would they speak about? Especially to the Muggle parents. ‘Your son got Troll for Transfigurations and failed to transform a rat to a goblet and vice-versa’? It would be an interesting conversation, though. Maybe they’d just send out a letter like how the Ministry did in OoTP.
547744	I'm no expert nor scholar, but from what I am reading in all of these explanations, and what I notice from the illustration, it becomes obvious...at least to me...which I feel may clarify the polarity change between the Galvanic cell and electrolytic cell for this user. As established and understood, the source of electrons and transfer of ions flows from the negative pole, (Anode) and is received by the positive pole (Cathode) (intentionally using most basic terms) the anode is negative here because the the flow originates FROM the electrolyte, into the light bulb, for which, if the terminals of the bulb were labeled, they would match the electrolyte in the other cell as it is the force coming from the bulb pushing the flow to the cell's cathode, and the cell's cathode is pulling from the bulb. In the electrolytic cell, the "electrolyte" is taking the role of the light bulb of the Galvanic cell, since the electrons are being SENT TO it from the power source, and is not in itself the SOURCE of flow, but is SUBJECT TO the force from the source of flow. SO just as the Galvanic cell's anode sends to the light bulb, and the electrolyte is labeled like the load of the galvanic cell, and transferring its incoming negative force from the current source, and this pushes through the electrolyte like the flow FROM the light bulb. It may be easier if you note that the SOURCE of power is NOT the electrolyte and technically, the black terminal of the power supply is the TRUE anode (Sending), and the red side the TRUE Cathode, (Receiving) but when identifying the reactive substance submerged/surrounded by the electrolytic substance, the anode is giving up its ions, which then add to the Cathode which is receiving them. Therefore the tags in the electrolytic cell are not naming the "source of flow", but the reaction of the substances involved, due TO the force/flow imposed on them from the power source, but is not THE source of power, and therefore should not be labeled AS one...and there are only two options for labeling them, and since it cannot be changed at the power source it can only b changed at the point of contact with the electrolyte! At least this is what I have come to understand by reviewing the comments and illustrations. I sincerely hope it helps clarify the rationale for the reversal of labels for this user and any others struggling with the concept of being due to the source of current having to be labeled as - Anode and + Cathode... forcing the object the current plays upon to be the opposite despite their poles and due to direction of flow.
588566	The 95% is not numerically attached at all to how confident you are that you've covered the true effect in your experiment. Perhaps recognizing that "interval using 95% coverage range calculation" might be a more accurate name for it. You can make the choice to decide that the interval contains the true value; and you'll be right if you do that consistently 95% of the time. But you really don't know how likely it is for your particular experiment without more information. Q1: Your first query conflates two things and misuses a term. No wonder you're confused. A narrower confidence interval may be more precise but, when calculated the same way, such as the 95% method, they all have the same accuracy. They capture the true value the same proportion of the time. Also, just because it's narrow doesn't mean you're less likely to encounter a sample that falls within that narrow confidence interval. A narrow confidence interval can be achieved one of three ways. The experimental method or nature of the data could just have very low variance. The confidence interval around the boiling point of tap water at sea level is pretty small, regardless of the sample size. The confidence interval around the average weight of people might be rather large because people are very variable but one can make that confidence interval smaller by just acquiring more observations. In that case, as you gain more certainty about where you believe the true value is, by collecting more samples and making a narrower confidence interval, then the probability of encountering an individual in that confidence interval does go down. (it goes down in any case when you increase sample size, but you may not bother collecting the big sample in the boiling water case). Finally, it could be narrow because your sample is unrepresentative. In that case you are actually more likely to have one of the 5% of intervals that does not contain the true value. It's a bit of a paradox regarding CI width and something you should check by knowing the literature and how variable this data typically is. Further consider that the confidence interval is about trying to estimate the true mean value of the population. If you knew that spot on then you'd be even more precise (and accurate) and not even have a range of estimates. But your probability of encountering an observation with that exact same value would be far lower than finding one within any particular sample based CI. Q2: A 99% confidence interval is wider than a 95%. Therefore, it's more likely that it will contain the true value. See the distinction above between precise and accurate, you're conflating the two. If I make a confidence interval narrower with lower variability and higher sample size it becomes more precise, the likely values cover a smaller range. If I increase the coverage by using a 99% calculation it becomes more accurate, the true value is more likely to be within the range.
1035333	Their products appear to do what they say they will do, and as far as I can tell do them well -- I've tried them so I know. That's the good news. The bad news is when the installation runs it tries to install a load of things on your system that you didn't ask for and didn't want, such as IE toolbars. It tried to change my IE homepage (without asking!) but Spybot told me about it as it attempted this, so I stopped this. I didn't catch a few other things, such as hosing up Internet Explorer so that whenever I try to start a new tab, it doesn't come up blank, but it runs to Google Mail! Which is really odd, actually. Gmail was set as my home page, and apparently, preventing NCH from changing my home page caused it to mess IE's tab-generating process up. I am not sure how to fix this. It also installed the Ask Toolbar without my permission. I don't know what else it installed (I'm still looking). When I uninstalled their product (the screen capture program), it didn't totally clean up after itself, either. The NCH Software folder was still in Program Files. I suspect other remnants remain.
1270480	easiest thing is web search and read articles related to subnet mask and subnet mask binary shorthand and CIDR and also check out subnet calculators the /32 is the CIDR (shorthand) and refers to how many 1's are in the subnet mask. For /32 that is 255.255.255.255 or 11111111.11111111.11111111.1111111 that means you can only have one ip address, on your network before needing a gateway/router to get outside that network. with /32 it's just you. A subnet mask is a number that defines a range of IP addresses available within a network CIDR = classless inter-domain routing what does using /32 mean : I don't believe it is an invalid setting however it effectively turns off networking... or limits the network to just you... you can only talk to yourself if you don't have a gateway set up to reach outside that netmask. what will its network id be: I assume you mean what will ip address be, and ip address will be whatever you set it to be. The IP address and subnet mask (which is what you are dealing with) are two different although related things. can a host exist without a network id [ip address?] : can you exist without having a first and last name or without an address? yes the host can exist. kinda need to better define what u mean by exist.
1371323	As the data says it mates with a "standard banana". Standard is 4mm. Something like this: Or this: Not this (but perhaps you can see the resemblance in the springy bits): The part you have (female) is just a hollow tube with no springy parts, so it depends on the male to supply the compliance. Some plugs have a cross-drilled hole so another banana plug can be inserted sideways. The screw and nuts are to fasten onto a ring terminal or onto a through-hole PCB. In the case of the PCB, a toothed lockwasher is a good idea. In the case of the terminal, a toothed "star" terminal can be used (photo from here). You drill a hole as the datasheet shows and attach the jack to a panel with the large nut. The datasheet indicates that the jack also accepts shrouded plugs (insulated on the outside of the metal and often with plastic at the end so that a human finger cannot contact the metal). This is commonly used on the meter end of test leads.
2184144	You could use RapidSprout.com, it comes with an extensive set of folder templates one of them being a house plant journal. Once you register select the category gardening then House Plant Journal and click on the create button. Next watering date will give you a visual alert by changing the color or the text as the date gets closer. There are many other folder templates that might be useful. It'll also work across all of your devices (desktop,phone,tablet) from the web browser. The folder is completely customizable using design mode. I am the owner of RapidSprout.com and hope you find the site useful. There is no fee to use the site. House Plant Journal 01. Plant 02. Location 03. Date Planted/Purchased 04. Cost 05. Last Watering Date 06. Next Watering Date (due date) 07. Light conditions Log (1-M) 01. Date 02. Description 02. Photo 03. Note
204232	There are any number of purpose built survival rifles and shotguns (and both) to choose from. These are intended for downed aircrews in hostile territory to hunt small and medium game, as well as self-defense in a pinch. They're designed to be light, compact, durable, and easy to use. These are all desirable for a hunting weapon to be shipped on a colony ship where space and weight are a premium. The current version in US Air Force service is the AR-7. Its a magazine fed simple blowback semi-automatic rifle. It weighs just over 1kg, and with the barrel removed is about half a meter long. All parts store in the stock, and it will float. It has a peep sight making it very easy to aim. The AR-7 fires .22 Long Rifle, but .22 Hornet might be more desirable for a space colony. Both have minimal recoil, and are very quiet making them very forgiving for an untrained shooter. While both fire the same 3 gram projectile, .22 Hornet's muzzle velocity is almost 2.5 faster with 7 times the kinetic energy. The resulting flatter trajectory makes it easier to aim. And the additional energy makes it effective against medium game such as turkeys, pigs, and goats. .22 Hornet is about twice the size and weight of .22 LR meaning you can carry half as much. This is offset because .22 Hornet is centerfire and the brass case can be reloaded. .22 LR is a rimfire cartridge and it cannot be reloaded. The colonists can save weight by carrying a limited amount of brass cases, and an extra supply of gunpowder, projectiles, and primers to reload them. Eventually they'd manufacture their own, this is late-19th century technology. Unlike fancy sci-fi weapons, the colonists will be able to maintain this weapon and manufacture ammunition without high-tech facilities. This should be sufficient for day-to-day pest control, hunting, and self-defense. Packing many very light survival rifles means putting more weapons in the hands of more colonists. A handful of larger, heavier weapons would be on hand to deal with larger threats should they appear.
433990	Within the marvel universe I don't know. It's called Illeism Illeism /ˈɪli.ɪzəm/ (from Latin ille meaning "he, that") is the act of referring to oneself in the third person instead of first person. Illeism is sometimes used in literature as a stylistic device. In real life usage, illeism can reflect a number of different stylistic intentions or involuntary circumstances. As far as I know its' not revealed in canon, but we can surmise: Mantis is of Asian ancestry (obviously): The enigmatic Mantis traces her roots back to the family of Vietnamese crimelord Monsieur Khruul who, disapproving of his sister Lua's marriage to German mercenary Gustav Brandt, hunted the couple across Indochina¹. ¹Source Created by Steve Englehart who also create the other martial arts expert Shang Chi indicating that he must have at least a cursory acquaintance with Asian customs. Look at this question it's not unheard of as a speech mechanism. Aside: Mantis will apparently feature in Guardians of the Galaxy Vol. 2. In October 2015, del Toro was confirmed to return and Pom Klementieff was cast as Mantis.
500869	The main thing about a Bridge camera is that it's "Bridging" the gap between a small point & shoot camera, and a larger DSLR. So the comparison of a bridge camera to a DSLR comes down, basically, to the following:- A larger optical zoom lens like a DSLR. Versatile, but not interchangeable. The sensor is generally not as advanced as a dedicated DSLR, and therefore Bridge cameras tend not to handle low light/high ISO situations as well as a DSLR (but better than a P&S). You won't get an optical viewfinder on a Bridge camera. It will be either an LCD display only or an EVF-Electronic Viewfinder (which mean when you look into the viewfinder eyehole you see the image of what the lens is seeing, as captured by the sensor, rather than the true image as reflected by a mirror). Of course, by its very definition, an SLR will have an optical viewfinder. A Bridge camera will generally have similar controls and handling to a DSLR, and be complete with Program, Aperture Priority, Shutter Speed Priority and Manual exposure programs, just as you would get on a DSLR and high-end compacts. You are usually able to shoot in RAW just like on DSLR's and high-end compacts. A good article on Bridge cameras can be found here. From personal experience, my old Boss once asked me about some issues he was having with his Fujifilm Bridge camera. Indoor photos of his daughter, when viewed at 100% had absolutely horrible red marks all over the photo - especially in the skin tones. So much so that even viewing at a reasonable smaller size on the monitor resulted in noticable red 'grain' in the photo. I took the camera and tried lots of things with it, but was unable to correct the fault. He asked me for a recommendation and (at that time) I suggested the Canon Powershot S90. He got one, and never had any problems with the photos from it. So if you are considering a Bridge camera - it may be worth instead to look at a high-end compact instead. As an aside I once heard it said that with Bridge cameras you essentially get the disadvantages of both systems -- the size and weight of a DSLR and the lack of flexibility of a point & shoot. I quite like the saying, but it's an individual viewpoint. Many people have Bridge cameras and are very happy with them.
725847	At the very least, you should have your name, contact information, and a bio of what you do. That's the minimal advertising necessary to serve as a useful "see my site for more details on what I do". Given that almost everyone who visits your site will either be looking for someone's name or a paper you've previously published, the next most useful information to include would be: - Lab members contact info & bios - Publications with downloadable links I would definitely recommend putting pictures up as well, so people will recognize your face when they see you at conferences. Same for lab members. Links to other affiliations is nice, but almost certainly not important. Practically no one will follow them. Whether to list your CV is up to you; people who need it will often ask you, but it won't hurt to have it live. Depending on your research, you can have a "recent news" section where you advertise any particularly notable publication or mention in the popular press. Finally, if you teach, I recommend putting links to the course website (which may or may not be part of your academic website), as many students will find your page by googling and will be looking for course info.
956499	The difference between the CPU fan and the system fan is that the former is the one attached to the heatsink of the processor, and the latter is generally on one of the sides of the case to exhaust hot air. The BIOS determines which is which, though, by the mere fact that one is plugged to the cpu_fan plug of the mainboard and the other is on the sys_fan, so it could be reversed without much problem if one would have any occult reason to do so (or just a broken plug). You can safely use the computer without a sys_fan as long as the cpu and the other components run at temperatures inside their safety ranges, which is quite probable that they do, even without system fan, as long as the computer isn't under heavy load or naturally power hungry.
1369460	The rating 2600mAh (or 2.6Ah) means the battery will produce 2600mA for one hour, or 1000mA for 2.6 hours of indeed 1mA for 2600 hours. The rating is the current multiplied by the time the battery can produce that current. In practice the rating depends on the current. The figure of 2600mAh will have been obtained for whatever current is optimal for that battery. Running at higher or lower current will give a shorter lifetime. Incidentally, the 9.62Wh rating is the current times the voltage times the time. So in this case the voltage times the current times the lifetime is 9.62Wh. If the battery voltage $V$ was constant the 9.62Wh would just be the 2.6Ah times $V$ (so presumably the battery voltage is around 3.7V). However the battery voltage changes as the battery discharges, so the relationship between the Wh and Ah ratings is a bit more complicated than this. As for your questions about charging, it's impossible to comment without knowing exactly what sort of battery it is. If it is a 3.7V battery that sounds like a lithium ion battery, in which case you may well have cooked it by connecting it to a 12V PSU. Lithium batteries need a special charger. It might be worth you asking on the Electrical Engineering SE as they tend to be more interested in the nitty gritty of anything electrical. But if you do post there be sure to give as many details about the battery as possible.
2242707	A good digital piano is better than a bad acoustic piano. The best digital pianos aren't as good as the best acoustic pianos. As a beginner, it's unlikely that you have the skill and experience to detect the nuance and detail that separates a good digital piano from a great acoustic piano. Pretty much anything made by a reputable brand and marketed as a "digital piano" (as opposed to a "keyboard" etc.) will have a keyboard feel that's close enough to a real piano for a beginner. Remember too that real pianos vary dramatically in feel. If you choose a real piano, you should factor in the cost of maintenance. Real pianos need regular tuning; an out-of-tune piano is no pleasure to play, nor to listen to. Digital pianos never go out of tune, and require very little maintenance. In favour of real pianos, there's nothing quite like taking the covers off a real piano, watching the intricate mechanisms, getting the full sound of the uncovered strings, seeing them vibrate, plucking or muting with your hands, etc.
2244534	One side effect of an upwards stroke is that you'll normally only hit the highest couple of strings. This upwards stroke starts at the highest strings, and (as cyco130 said) is usually a lot weaker, which means that you'll only hit two or three strings at most. More than that will usually sound clumsy, unless you really intend to go for that particular sound. A good example of that is the opening chords to Pink Floyd's Welcome to the Machine. Anyone will notice that those sound fairly peculiar, and that's because they're struck upwards. Since it's difficult to hit the lower sounding strings properly in an upwards stroke, you'll often see people striking every chord downwards, when the lower strings are most important. For this, a good example is Pennywise's Bro Hymn, a song that most people will immediately recognize. This song's riff consists entirely out of power chords, on the lower four strings, and each strike has almost the same force to it. The only way to achieve that sound is by striking every chord downwards, over and over again.
44283	Early as adverb means before the usual or expected time; earlier means before the present time or before the time one is referring to. So, the second sentence could be understood as asking to come before the present time. For example, if it's 10:00 AM when the question is asked, the other person could take you are asking to come a little earlier than 10:00 AM. The exact meaning depends on the context, though. For example, in the following sentence, the meaning would be different. Yesterday we met at 10:00 PM. Can you come over earlier, so we can go back home before my wife returns from work? I would use early if I am talking of the usual time I do something, or I am talking of the expected time something should happen. For example, if I am talking to a co-worker, I could ask Can you come early, tomorrow? to ask if my co-worker can come earlier than the usual time he starts to work.
455542	This is probably one of the books from the Pit Dragon trilogy by Jane Yolen, specifically the second one, Heart's Blood. Golden, Jakkin, and Akki flee to the mountains, but Golden is badly injured. Pursued by the Wardens, they are forced to leave Golden behind in a cave which they had sheltered in during Dark After, using Heart's Blood's body as a door and heater. Jakkin manumits the traitorous Erikkin, and Heart's Blood dies from a stinger shot in the neck, her body saving Jakkin and Akki. The only shelter they have during Dark After, is Heart's Blood's body, so they crawl into her birth sac. In the morning, Jakkin and Akki are reborn out of the dragon blood, and became the first real human Austarians, linked to each other and Heart's Blood's five hatchlings. Jakkin and Akki are male and female. Dragons are common on Austar IV. Jakkin and Akki gain special powers by nesting in the birth sac, but it's the ability to communicate with each other as dragons do. And, from the Google Books excerpt: Jakkin added, "They can't be ridden. With a weight on Heart's Blood's back she couldn't even raise her wings. And if you sat there without a saddle of some sort, your legs and groin would be slashed terribly by her scales. The scales move when she moves, and they slice at a touch."
497368	in fact if the lens front element rotates when focusing, then the petal lens hood is not good idea. I have a cheap Tamron 70-300 telezoom lens and it is shipped with standard "tube" hood. Second, the one you found looks like the one with screw-thread. I think that Canon also uses bayonet mount for hoods like my Pentax. So as I needed hood for my 18-55 mm lens, I first looked on Pentax website and found that the original hood is called "PH-RBA". Then I searched ebay and found some replacement hood for much smaller price, which had in description "Lens Hood for PENTAX SMC DA 18-55mm F3.5-5.6 AL II Lens replaces PH-RBA 52mm" and it had the same bayonet mount as the original lens hood.
520161	To understand the difference between a bridge camera and a DSLR, it is really necessary to understand the origin of the term "bridge camera". While a DSLR (digital single lens reflex) is a particular type of camera with a very well defined meaning (it uses a single lens which is used for both exposure and viewfinding), the term "bridge" simply means that it is bridging the gap between two different types of cameras. So, knowing that "bridge" camera is simply a marketing term, what was it that it was designed to be a bridge from and to? Traditionally there were two main types of cameras, your point and shoot cameras, which were designed to be small, simple to use, and basic for an average person to be able to take photographs. Historically, they typically had a fixed lens, a basic built in flash if any and a simple viewfinder that simply gave you an idea of what the lens would capture when you exposed the image. If present at all, settings like shutter speed were minimal. On the other side, you had interchangeable lens cameras with full ability to adjust (either manually or automatically) settings like shutter speed, aperture, focal length, etc. These cameras were much more advanced, generally larger and generally more complicated to use, especially outside of using automatic settings. SLRs are one example of this type of camera. Early on, the differences were more pronounced, however as cameras advanced, both of these extremes moved more towards the center. Point and shoot cameras now often do allow basic exposure adjustments to be made and the automatic shooting capability of DSLRs have made them much simpler for a novice to use and get ok results, however some of the advantages and disadvantages have remained. Generally, point and shoots still are smaller and lighter and DSLRs have far greater versatility and generally better image quality due to larger sensors and better optics. So, knowing those two extremes, a bridge camera means that it is a camera which specializes on trying to provide the advantages of both DSLRs and point and shoot cameras with as few of the disadvantages as they can. They are also sometimes referred to as hybrid cameras. Typically, they are larger than basic point and shoots and have lenses that have adjustable focal length, but they are typically not removable lenses. They generally use an electronic view finder to avoid the complexity of SLR optics. They generally have smaller sensors than a DSLR, but often larger than a typical point and shoot, so they split the difference in size and versatility without having all of the cost or complexity of a DSLR, but also with more versatility than a basic point and shoot. The exact differences will depend on the particular models you are comparing and some high end bridge cameras may actually perform better than cheap DSLRs in some situations, but the general idea is simply that they straddle the gap left between the design goals of a point and shoot and those of a DSLR. Perhaps the most consistent distinction in terms of what is being bridged is that of the level of control the camera gives the user. Ultimately, simple cameras tend to have simpler and more limited controls while high end cameras give the user direct control of every aspect of image capture. Bridge cameras sit in between the extremes of super simple with no control and complete control over every aspect of image creation. A more recent introduction to the space is mirrorless cameras which could arguably be considered a type of bridge camera, at least on the lower end (though they aren't typically called as such) as well since they feature generally smaller sensors and simplified bodies from those of DSLRs, but include interchangeable lens systems to improve versatility and quality over that of a bridge camera with a permanently installed lens. I would say that higher end mirrorless cameras could not be considered bridge as they have strong support for full lighting, exposure and lens selection control and are no longer really a bridge between almost no control and full control, but rather provide full control. So to break down the gamut of cameras, from simplest to most complex, you have the following: Point and Shoot / Compact - smallest size, most basic adjustments, cheapest, easiest to use Conventional Bridge/Hybrid - slightly larger, generally more adjustments, but often menu driven, zoom lens, but permanently attached, still very easy to use Mirrorless - still a small size. Camera body nearly resembles a point and shoot, however lenses are interchangeable. More adjustment options available. Often full adjustment is available, but may still use menus for some settings, more complicated to use as you need to consider lens selection and possibly exposure adjustments DSLR - large size, generally better image quality, full adjustments directly available on higher end models, most complicated bodies and thus generally most expensive, similar shooting complexity to mirrorless since full consideration of exposure, lens, lighting selections need to be considered That isn't a perfect list as there is cross over depending on how high end a particular model is, but it serves as a general guideline. Ultimately, when you are considering which camera to buy, you should look at the capabilities of the camera and your needs rather than considering if it is labeled as a "bridge" camera. Look for a camera that can get the shots you want and let you adjust what you want while taking care of the rest for you.
565061	Granite is not composed of the oxides listed, they are just a way of expressing the weight percentage of elements in the sample. Granite (and other rocks) are actually composed of minerals. All granites contain quartz + alkali feldspar + plagioclase feldspar. Biotite is also pretty common and a variety of other minerals can also be less commonly present. This is a phase diagram of the quartz - alkali feldspar - plagioclase feldspar system at 5 kbar pressure. The first melt forms in this system at the eutectic point at around 650 °C, but complete melting would not occur until a much higher temperature. I expect the last thing to melt would be left over quartz although it would first transform to tridymite and then cristobalite before melting finally melting.
640486	Or is the shape more complicated? Restricted cubic splines fit flexible functions to different sections of the data; cubic spline design matrices can be estimated with OLS. MARS accomplishes a similar effect (different models for different subsets of points), but discovers the subset locations on its own. Splines build up from this idea: a data set can be partitioned into different intervals, and each of those intervals can be modeled with some degree of accuracy as a constant. Alternatively, you can model each interval as a linear function. Still more elaborately, you can make the linear functions continuous at the interval boundaries. These boundaries are "knots." This solution is a piece-wise linear model. Restricted cubic splines further enforce that the function have several orders of differentiability at the knots, and that the function be linear in the intervals $(-\infty, k_1],[k_n,\infty)$, i.e. "outside" of the last knots. This linearity requirement is motivated by a desire to not over-extrapolate in very data-sparse regions. Restricted cubic splines allow for non-monotonic functions, e.g. the function can increase and then decrease and then increase again. How to select knot locations is a sticky wicket, since it will influence what the ultimate model looks like. Frank Harrell's book Regression Modeling Strategies has some recommendations based on quantiles.
867174	There is a related fallacy of "defining into existence" when implicitly defined entities are illicitly declared existent, versions of the ontological argument are often accused of defining God into existence. Kant clearly expressed the issue in his thesis that "existence is not a predicate". Even for ideal objects in mathematics it must be proved from axioms that objects fulfilling the defining conditions exists, the object is then said to be "well-defined". For example, Euclid defines equilateral triangle as a triangle with equal sides, but he gives a straightedge and compass construction of it before using it in demonstrations (in modern texts the two steps are often combined into a single "theorem-definition"). But in itself giving contradictory definitions with non-existent referents, and reasoning about them, is not a fallacy, although it does pose an old philosophical puzzle. Quine in On What There Is gave it a nickname that stuck:"Nonbeing must in some sense be, otherwise what is it that there is not? This tangled doctrine might be nicknamed Plato's beard". Plato mused over the nature of fleeting "sensibles", and famously assigned to them less than being, the becoming. This was a major point of difference between him and Aristotle, who saw becoming as a form of being, and argued against its dismissal by Parmenides and Plato. But objects nonexistent due to inconsistency, like round squares, pose the same logical problem: if round square is not what is it that there is not? One solution is due to Meinong: objects in logic may not exist but only "subsist", this is Meinong's version of becoming, but it also covers all sorts of fictions and absurdities. If you take this route you have to give up existential generalization, P(a) does not imply existence of x with property P, and allow contradictory sentences, P(a) and ¬P(a) may both hold if a is non-existent. If you give an argument with subsistent objects in the premises you may conclude all sorts of things about them, but it will not get you very much since none of them have to exist. To move from subsistence to existence would be exactly to commit the "defining into existence" fallacy. A more mainstream version of dealing with Plato's beard, one favored by Quine himself, is due to Russell. It involves eliminating defined objects from premises by using descriptions, before any logical analysis of arguments. Russell's way of talking about say round squares is to use a variable x with predicates R(x) and S(x), rather than a proper name with dubious existential status. The rest depends on how exactly you want to use round squares in premises. If you want to make any existential claim about them, e.g. "some round squares are green" ∃x(R(x)∧S(x)∧G(x)), then any premise involving it will come out as false, and any argument based on it will be unsound, even if valid. But something like "all round squares are round" ∀x(R(x)∧S(x) → R(x)) is not just true but even a logical tautology. For that matter, even "all round squares are green" ∀x(R(x)∧S(x) → G(x)) is a tautology, if we are assuming that R and S contradict each other. Plato's beard has an interesting application in mathematics. In proofs by contradiction negation of the intended conclusion is treated as an additional premise, and an auxiliary valid, but unsound argument is given using it. The contradiction in the conclusion of the auxiliary argument is then interpreted as entailing the intended conclusion. But at the onset of the auxiliary argument we do invoke inconsistent objects, implicitly or explicitly. For instance, Euclid's proof of the irrationality of square root of 2 ostensibly involves defining a rational number with square 2, and then reasoning about it. This non-existent number can be interpreted in Meinongian or in Russellian manner. See more in SEP's Nonexistent Objects, and Negative Existential Beliefs.
995712	chkdsk /r does the same thing as chkdsk /f only it also checks for bad sectors on the disk and recovers any readable information. Running chkdsk /r implies that also chkdsk /f is run. chkdsk /f only checks for disk errors, not bad sectors. Microsoft has a detailed page for chkdsk. The following is a snippet explaining /f and /r parameters. Fixing disk errors: Chkdsk corrects disk errors only if you specify the /f command-line option. Chkdsk must be able to lock the drive to correct errors. Because repairs usually change a disk's file allocation table and sometimes cause a loss of data, chkdsk sends a confirmation message. Finding physical disk errors: Use the /r command-line option to find physical disk errors in the file system.
997300	There is no such thing as a Domain Name Server. DNS stands for Domain Name System, which is simply a hierarchy of Name Servers that has the intent to translate host names into IP addresses on a global scale. A name server hosts or caches these translations, in the case where they are hosted the name server is often called a DNS Server. Counting all name servers is a bit tricky, because you can't simply enumerate all the domains. Let me give you an example on resolving superuser.com in a non-cached way: The name server that I use is 192.168.1.1. This is my local router which caches DNS entries, it has a Hosts file to reroute malicious domains. The router has the name servers 8.8.4.4 and 8.8.8.8 set, known as Google DNS, they also cache. Google DNS will contact authoritative root name servers, which are the top of the DNS hierarchy. Google DNS will contact the .com name servers, the IP of which it received from the ARNs. Google DNS will contact the DNS server for superuser.com, of which IP it received from .com. A simply whois reveals: NS1.SERVERFAULT.COM NS2.SERVERFAULT.COM NS3.SERVERFAULT.COM The IPs for these name servers are known as they are registered at the .com name server, when you register a new domain you always have to fill in the DNS servers that you use along their IP. Google DNS will contact the DNS servers of superuser.com to find the IP of superuser.com: nslookup superuser.com NS1.SERVERFAULT.COM Server: NS1.SERVERFAULT.COM Address: 64.34.119.33 Name: superuser.com Address: 64.34.119.12 I would suggest you to read through Domain Name System and Name Servers for more details. The term name servers are also used in different contexts, read Spiff's answer for more.
1165311	Before I begin answering the question, think about this: if DualShock uses Bluetooth, then how does the PlayStation establish a connection to all 4 controllers with a single radio? I use Scarlet.Crush's SCP drivers, and they seem to have great Bluetooth support (I use regular USB). They require sacrificing one Bluetooth dongle to install SCP drivers on it, which replace the original Bluetooth drivers/stack (meaning the dongle will be dedicated to connecting DualShock controllers and nothing more). The fact that plural in "controllers" is used frequently in the documentation confirms that you are able to connect all four controllers into a single dongle. Due to the controller's hardware limitations (4 lights) and SCP's own limitations as a result, you can only have up to four controllers connected at once. Since a concurrent connection to 4 devices are supported by a majority of Bluetooth radios (the forum post above lists them out) and this does not even come near to the spec's hard limit of 7, there is no doubt you will be able to connect all 4 controllers with a single dongle, regardless of whether they are DS3 or DS4, given that everything is correctly configured and paired up.
2217110	Natural vs synthetic I did a bit of research into this and found that there are two main kinds of paintbrush bristles: natural (usually made from animal hair) and synthetic (usually made from some combination of nylon and polyester). Each of these has its own advantages and disadvantages according to what kind of paint you're using. The TL;DR is that natural bristles are better for oil-based paint while synthetic bristles are better for water-based or latex paint. For more details, see this page. As a bonus, it also gives some information on the shape as well as the material of paintbrush bristles: Bristle Shape: Most paintbrushes available today are square-cut brushes. They're perfect for holding and laying paint onto virtually any surface. However, square-cut brushes don't provide as much control when painting into corners, up to adjacent surfaces, or along narrow edges or surfaces. For more precise control, use a sash brush, which has its bristles cut at a slight angle. Sash brushes are particularly well-suited for cutting in around the perimeter of a room. Bristle Tips: Better quality brushes have bristles with flagged, or split, ends. Flagged bristles hold more paint and spread paint more smoothly. Some brushes, especially sash brushes, have tipped ends, which should not be confused with flagged ends. Tipped brushes come to a point; they're not cut flat and straight, as is a standard brush. Professional painters favor tipped brushes because they provide greater control and allow you to apply paint more precisely. More details on different types This list goes into more detail on the usages of synthetic and various types of natural bristles, although it doesn't distinguish between different types of synthetic material: Badger For blending oil paint on canvas, Badger Hair is an age-old tradtion. It comes from various parts of the world and is more readily available than most animal hair, although the quality varies greatly. Badger hair is thickest at the point, and relatively thin at the root, so it has a distinctive "bushy" appearance. MEDIA: oil Camel Hair Camel Hair does not come from camels at all. It is found in watercolor and lettering brushes and usually is made of squirrel, goat, ox, pony or a blend of several hairs, depending on the desired softness and intended cost of the brush. MEDIA: lettering, tempera, watercolor Hog Bristle Hog Bristle is obtained from hogs in several parts of the world, the most sought after coming from China. Bristle is unlike any other natural filler in that it forms a V-shaped split or "flag" at the tip and tends to have a natural curve. A brush with "interlocked" bristles, with the curves formed inward to the ferrule, has a natural resistance to fraying and spreads medium to thick paints smoothly and evenly. A selection of pure hog bristle brushes is recommended for oil and acrylic painting, and is a far less expensive alternative to good-quality softer hairs. MEDIA: acrylic, oil Kevrin/Mongoose Hair Kevrin/Mongoose Hair is strong, resilient, and makes a good long-wearing, medium to professional quality brush for oil and acrylic painting. MEDIA: acrylic, oil Kolinsky Sable Kolinsky Sable is not really from a sable at all, but comes from the tail of a species of mink that is a member of the weasel family found in Siberia and northeastern China. It is generally conceded to be the best material for oil and watercolor brushes due to its strength, spring and ability to retain its shape ("snap"). It holds a very fine point or edge. This is considered a professional grade of hair, and if properly cared for, Kolinsky will last for many years. MEDIA, oil, watercolor Ox Hair The best quality comes from the ears of cattle or oxen. The Ox Hair has a very strong body with silken texture, is very resilient, has good "snap", but lacks a fine tip. Therefore, it is most useful in medium gradewash brushes, or flat shaped brushes. Frequently, ox hair is blended with other natural hair to increase the resiliency of a brush. MEDIA: lettering, watercolor Pony Hair Pony Hair is soft but strong, from mature animals at least 2 years of age. It is primarily used for scholastic grade brushes, but often blended with other hairs for inexpensive watercolor and touch-up brushes. MEDIA: acrylic, scholastic, tempera, watercolor Red Sable Red Sable is obtained from any member of the weasel family with "red" hair, not at all from the animal known as the sable. It is found in a variety of brush styles for many varied mediums, with quality and characteristics varying greatly. A good quality pure Red Sable is a good alternative to the more expensive Kolinsky, with similar performance and durability. Often, weasel hair is blended with ox hair to make a more economical brush, but the fine point is sacrificed. MEDIA: oil, watercolor Sabeline Sabeline is actually select, light-colored ox hair dyed to resembled red sable. Lettering and watercolor brushes often use Sabeline mixed with Sable to lower the cost of a brush. MEDIA: lettering, watercolor Squirrel Gray Squirrel (Talayoutky), most highly in demand for lettering brushes and quills, is native to Russia and nearly always fell in short supply. Brown squirrel (Kazan) is more readily available, and is used mainly for medium quality and scholastic watercolor brushes. A very fine, thin hair, taken from squirrel tails, it points as well as Kolinsky, but has very little "snap" because the hair is not very resilient. It works best with liquid paints and inks. MEDIA: lettering, watercolor Synthetic Synthetics are man-made of either nylon or polyester filaments. They can be tapered, tipped, flagged, abraded or etched to increase color carrying ability. Often, synthetic filaments are dyed and baked to make them softer and more absorbent. The common name for this filament is "Taklon". Advantages of synthetic brushes are: 1) They are less prone to damage from solvents, insects or paints. 2) They are easier to keep clean than animal hair brushes because the filaments don't have animal scale structures to trap paint. 3) They are less prone to breakage and are durable on many different surfaces. 4) They are better suited for painting with acrylics because a synthetic filament will withstand the caustic nature of acrylic paints with less damage. MEDIA: all Finally, this list goes into even greater detail on a huge variety of types of bristle, falling into four main families: animal hair, vegetable fibre, synthetic, and wire brush. Within each of these families, several different materials are described and compared. It's too long to copy it all here, but should be useful as further reading if the above isn't detailed enough.
2259929	A good way of thinking about it is as a clockwork watch or clockwork mechanism or machine. You could have two watches keeping the same time but with different time signatures. Think of the second hand as the pulse with its tick, tock, tick, tock and the beat as the mechanism driving the second hand as 123, 123, 123, 123. Each tick or tock is supported by three beats. A beat behind the second hand pulse of 1234, 1234, 1234, 1234 would be a 16/4 time signature. A beat that is the same as the pulse 1234, 1234, e.t.c. would be in common time. An old mantelpiece clock could be imagined in cut time 2/2. That's why trying to determine the time signature of a tune by counting foot taps as beats only works in 4/4 or if you double or half your tap interval to an 8/4 or 2/4, e.t.c. Complex time signatures can't be determined that way. For example, if you tap out a 6/8 jig, you'd fool yourself into thinking it's in 2/8 time, i.e. two beats to every bar whereas you are actually tapping out groups of three beats, 123, 123. A common question in traditional music that might help is the difference between a jig and a reel. To real (forgive the pun) traditional musicians, who have learned by ear and never seen a musical score, the reply will be something using words; if you can say 'jiggery, jiggery,' to the music, it's a jig and if you can say 'this is how a reel goes, this is how a reel goes,' it's a reel. The jiggery is Ji Ge Ry, 123, beat on the capital letter, and this is how a reel goes is Thisis Howa Reel Goes, 1234. Therefore, a jig is in 6/8 time (usually) 123, 123, i.e. 6 X 8th notes (beats) per bar and a reel is in 4/4 time 4 X 4 notes (beats) per bar. To understand the 123 grouping think of a waltz which is often (usually in 3/4 time, i.e. three quarter notes per bar. You'll find yourself saying 123, 123, 123, 123 while tapping out the pulse as one tap on the 1 of each 123 grouping.
2380373	Blinding road users will be the result of the following factors: Total light output Mirror design (how is the light shaped) How you aimed your light Most trail lights (and high output battery powered lights) use a mirror that casts the light in a symmetrical shape. This means light is cast up, down, left and right. Light cast above the horizon is what binds other road users. Light above the horizon is however great for trail riding as it lets you see overhanging branches and other impediments. Car running lights (i.e. not high beams) are designed with a horizontal cut-off, where light does not shine above the horizon (actually a low percentage does, this called spill light). If the car light is aimed correctly, the the horizontal cut-off falls below oncoming road users line of vision. This is why you are typically not horribly blinded by oncoming cars, if they are a) using their running lights and b) have their lights aimed correctly. High beams do not have a horizontal cut-off, which is the primary reason you get blinded so badly. Some bike lights (those that are approved for German roads) will have a mirror that has this sharp horizontal cut-off. They usually will usually be indicated by the some statement on StVZO compliance. Most dynamo lights (e.g., B & M, Schmidt, etc) will have this mirror design. There are also a few battery powered lights (e.g., some B & M models), but they are few and far between. If you have a light with a symmetrical beam, you can lessen the blinding effect by pointing the light down (as suggested in @Batman's answer), however due to the symmetrical nature of the beam you will still blind road users more than if you had a light with a horizontal cutoff and was aimed correctly as there will still be more spill light above the horizon. This effect is also confounded by how narrowly or wide the symmetrical beam is focused. Wide flood lights will almost always blind, despite how much you aim them down, spot lights will blind less when pointed down. Finally, total output does have some impact too, but it is also confounded with mirror design (e.g., high output with a horizontal cut-off may blind less than a low output symmetrical beam). What really determines whether or not you blind other users is the total amount of light shining above the horizon at their eyes. In your case your 750 lumen lights are likely trail lights with a wide symmetrical beam. If you run them at full output you will likely blind others unless you severely aim it downwards.
2382077	I just tried using a sackbarrow as a trailer, and it was workable, but not recommended. That's a "trailgator" kids bike comealong joiner. The clamp that goes on the kid's bike's head tube is bolted to the handle of the barrow, the eagle-eyed will notice a spare crank arm used as packing for this test. The arm can be almost twice as long, but compressed was long enough for this test. Problems: The small ~6 inch wheels are terribly bouncy and noisy at any pressure. Adding some weight certainly helped this. Lack of rotational joint meant there was often a barrow wheel off the ground when empty. Sharp turns brought the main beam in contact with the rider's thigh. Most of the weight is on two quick release bolts, so that's the limiting factor. These two bolts (one vertical and one horizontal) provide the freedom for the main beam to move up/down and left/right. On the other hand, it definitely worked and would let you tow the box or maybe 50 kilograms of stuff. I should have fastened it lower on the seat post, but that would mean the rack was unusable. That weird black arm is supposed to clip to the kid's handlebars to stop them turning while being towed.
395795	I'm unaware of any canon answers so I will hazard a reasonable guess. It seems exceptionally unlikely that Dumbledore would allow any policy or circumstance which made it impossible for a parent to visit with their child. Parents are, after all, the child's first teacher/protector/champion/consoler/cheering section and in times of triumph/stress/trauma, most children will turn to their parent. Dumbledore has consistently shown that the welfare of his students is a primary concern and so he would insure that all of his students could avail themselves of whatever parents/guardians they had. On the other hand, I think that muggle parents would feel exceptionally uncomfortable traveling to Hogwarts under most circumstances. I can just imagine one of Hermione's dentist parents doing side-along-apparation with Dumbledore. Generally, I think that the comment by Anthony Grist is probably correct (families of witches and wizards are more like squibs) and thus they could travel to Hogwarts. I think it's fairly rare though and that's why we don't see any instances of it in the books.
419075	J. K. Rowling's Draco entry on Pottermore, added December 2014, directly addressed your question. The biggest revelation was that he became less of a pure-blood fanatic: The events of Draco’s late teens forever changed his life. He had had the beliefs with which he had grown up challenged in the most frightening way: he had experienced terror and despair, seen his parents suffer for their allegiance, and had witnessed the crumbling of all that his family had believed in. People whom Draco had been raised, or else had learned, to hate, such as Dumbledore, had offered him help and kindness, and Harry Potter had given him his life. After the events of the second wizarding war, Lucius found his son as affectionate as ever, but refusing to follow the same old pure-blood line. Draco married the younger sister of a fellow Slytherin. Astoria Greengrass, who had gone through a similar (though less violent and frightening) conversion from pure-blood ideals to a more tolerant life view, was felt by Narcissa and Lucius to be something of a disappointment as a daughter-in-law. They had had high hopes of a girl whose family featured on the ‘Sacred Twenty-Eight’, but as Astoria refused to raise their grandson Scorpius in the belief that Muggles were scum, family gatherings were often fraught with tension. Also, he seemingly mellowed out a bit, leading a life of leisure instead of working to overturn the forces of light or establish dominion over Muggles, like Lucius did: I imagine that Draco grew up to lead a modified version of his father’s existence; independently wealthy, without any need to work, Draco inhabits Malfoy Manor with his wife and son. I see in his hobbies further confirmation of his dual nature. The collection of Dark artefacts harks back to family history, even though he keeps them in glass cases and does not use them. However, his strange interest in alchemical manuscripts, from which he never attempts to make a Philosopher’s Stone, hints at a wish for something other than wealth, perhaps even the wish to be a better man. I have high hopes that he will raise Scorpius to be a much kinder and more tolerant Malfoy than he was in his own youth.
422231	****POTENTIAL SPOILERS**** As DDFirst Name Dd stated, I believe that Catelyn stated that Eddards Grand-Aunt married into another house, which I believe is house Royce, although I may be wrong about this. If for whatever reason these distant relatives are ineligible to inherit, such as dying without issue, then there would likely be another house who can trace descent through a grandparent or great grandparent to a direct male-line ancestor of Robb. Unfortunately, it would seem that Westeros, or at least the north, does not have a directly clear system for dealing with succession, and as such the claimant with the most direct blood relation to the current Stark's of Winterfell may not be the best potential claimant. In Westeros there are numerous examples of claimants with lesser claims being favored over the most direct heir, such as the first Lord Paramount of the Reach, who was granted dominion over Highgarden and the Reach despite the fact that while numerous Reachman houses claimed direct descent to the Gardeners through the male line, such as the houses of Oakheart, Redwyne, Fossoway, Oakenshield, Tarly, and many others. This is because in Westerosi culture the ultimate authority is the King. If a potential claimant has no real chance of holding said title, it would be unlikely that the current king would appoint another person to said title. As Robb is the King in the North, so long as that kingdom continues to exist, his designated heir, Jon in the books, if the will of Robb had been read, and only if Jon was willing to forsake his vows, and the other northern houses were willing to accept his as their king, then he would become the new Lord of Winterfell. However practicality would likely dictate that another, such as Lord Karstark, or possibly even a member of house Royce, if they are in fact the house that Catlyn mentions, would step up to claim Winterfell. In the end, the heir to Winterfell is whoever is able to hold it, be it a potential husband to Sansa or Arya, a distant cousin backed by the other northern houses, or even the Karstarks, any could claim legitimacy, and in the end, sucession in Westeros is not about who has the best claim, but who has the most power.
471424	Snape’s matches Lily’s as he loved her. The reason that Snape’s Patronus matches Lily’s is because he was in love with her, as Harry tells the Dark Lord. “You never saw Snape cast a Patronus, did you, Riddle?’ Voldemort did not answer. They continued to circle each other like wolves about to tear each other apart. ‘Snape’s Patronus was a doe,’ said Harry, ‘the same as my mother’s, because he loved her for nearly all of his life, from the time when they were children.” - Harry Potter and the Deathly Hallows, Chapter 36 (The Flaw in the Plan) His Patronus is the same as hers because of his feelings for her - it doesn’t mean they’re related in any way.
516542	According to the Wikipedia article comparing all Canon EF-S 18-55mm version the STM version has (in addition to the new STM motor) a new optical design (13 elements in 11 groups vs. 11 elements in 9 groups), internal focusing and an extra diaphragm blade (7 vs. 6) So, the EF-S 18-55mm IS STM is not just the EF-S 18-55mm IS II with the new motor but a completely new lens that seams to be slightly better than the old design in every way. Even if you don't need the advantage of the STM motor for video I see no reason to buy the older version (unless it's cheaper), I also don't see a compelling reason to upgrade for someone that already has the IS II but the new STM version is better. BTW, you can usually buy seconds hand kit lenses for next to nothing because a lot of people want to get rid of them when they upgrade, a quick look on eBay shows that the EF-S 18-55mm IS II has been sold for as little as $40
808563	The reason for this is quite simple. While we orbit the sun, the moon is orbiting us. Look at the direction of the sunlight (this will show where the Sun is), then look at the position of the Moon. Let us take the Full Moon as an example. Imagine, in this 2D image, the Earth is rotating anti-clockwise. As the Sun is on one side, the moon is on the other. So Sunset and Moonrise will occur at close to the same time. Now let us look at the first quarter. At sunset, the moon is going to be almost directly overhead, which means moonrise occurred hours previously. Using a 2D visual representation makes it easy to visualise. Of course, it is not always so black and white, as the moons orbit is not a perfect circle same as ours is not perfect around the sun (hence different rise times throughout the year during the same phases), then there is axial tilt etc, etc. But this will give you a pretty good idea. The closer to the full moon it is, the closer Moonrise and Sunset will be.
1131494	I have had a cable of 30M be faulty, and a cable tester (albeit a cheap one) showed it as OK / didn't detect a fault. It may be that longer cables can be trodden on and that makes them less reliable(by damaging them). The kind of ethernet cables that I find to be reliable, have been one with a rugged jacket, they are expensive, and maybe a better quality build too. I used to get cables from a company that specialised in cables, but I just found them bad quality! But when I got a few rugged cables (and it would have been a specialist company making them), I found those were very reliable. So, maybe as a rule of thumb to get a quality cable, you could look for rugged jacket ones from a company that makes the rugged jacket ones, if you're willing to pay the price for such cables.
1227461	Another option is to get rid of CoreStorage if an OS X machine is available to you. This would also get rid of decryption if you're using it and you would have to wait until the decrypt is finished (plugged into power and booted into OS X, even recovery). You would need to boot to a disk that isn't the one in mind, preferably internet recovery (if available, command-option-r on reboot). Open up the terminal and do a: diskutil cs list The output should show your CoreStorage volumes and all, one of them is its Revertible status. If it indicates Yes then you'll be in good shape to proceed. Next you would run: diskutil cs revert /dev/ diskXsY (Where X is the disk number and Y is the partition number). You can check its status afterwards with the same "diskutil cs list" command. If it wasn't encrypted it should already be back to a standard GPT partition layout and you can try to mount it again in Arch. It should still be journaled which will keep it read-only, if you want to toggle that you can do so in Disk Utility. If it was encrypted the process will take a while but "diskutil cs list" will show you the progress as a percentage. I've had no issues mounting non-CoreStorage HFS+ drives and partitions on Arch myself. I did eventually move the data, repartition as ext4 and move the data back to them.
1500561	Is my solution reliable in the long term? No. A typical microcontroller IO pin has what is called three state logic or tri state: The pin can be in 3 states: Input, with the output driver transistors disabled, the pin is high impedance. Output low, the top output driver transistor is off and the bottom one is sinking current. Output high, the bottom output driver transistor is off and the top one is sourcing current. In your circuit, posted above, it is safe to assume the pin is always configured as an output, either low (MOSFET/LED off) or high (MOSFET/LED on). So it is always either sinking or sourcing current. When you close the switch on your diagram when the microcontroller output is low, current will flow trough the 100 ohm resistor, trough the bottom output driver transistor to ground. The only thing limiting current is the 100 ohm resistor so that bottom transistor has to sink 36mA. This is much more then a typical microcontroller pin is rated for and can damage it.
58198	One of the functions of money is that it acts as a common measure of market values as well as the typical medium of exchange. In the US, the dollar is that common measure and typical medium. Consequently, if money is involved in a retail transaction in the US, dollars need not be explicitly mentioned. An exchange involves at least two different parties and at least two different items. A phrase like "2 for 5" is an abbreviation for "2 A's in exchange for 5 B's," and what A and B are must be filled in by context. In the Us, at least either A or B is very likely to be dollars. With Burger King, which does not engage in barter but does sell hamburgers, A and B are likely to be hamburgers and dollars. How do you know which is which? You have to know that, at present, getting five hamburgers for two dollars is extremely unlikely. Language does not exist in a social vacuum, and people who write ads try to take the common understandings of the time and place into account.
128017	Well, within any discussion of literature -- any answer given on this SE for example -- there tend to be lots of ideas postulated. That is, simply, that they are taken as accepted truths by the writer, and usually by the readers as well. They are postulates in context -- simply the things we think we all agree on in order to be able to talk about the question we are answering. Of course, such postulates can be challenged and sometimes are. Here are some of the things that I postulate here on a regular basis: All literature is moral -- it is about a choice of values Literature is an experience, not a proposition All stories have story shape Story shape is driven by desire But these are just postulates in context. If challenged, I could produce argument based on evidence to support them. They are not axiomatic statements in the strong sense of a geometric axiom, for example. I don't believe that there are any axioms in this sense in literature. The study of literature is based on the study of aesthetics, psychology, and sociology, and I think that any statement you could make about literature specifically could be shown to be an instance of a more general statement in those fields. The danger in literature, I think, is quite the opposite though, not a dearth of axioms but gross surplus of facile rules of thumb that are often taken as axiomatic but are, in fact, misleading at best and outright wrong at worst. Finally, I think it is worth saying that the writing of a good story, despite all the advice on can find on structure, character development, etc. remains largely an exercise of tacit knowledge and skill. We cannot fully describe what we are doing when we write in objective terms. We learn it by osmosis and inform it with individual experience. If there are axioms, I think that they are axioms we have not yet learned to articulate, and I suspect we never will be able to articulate them.
139168	Worry about this later Names are easy. A quick run of Find/Replace, and suddenly, every mention of Corona is replaced with Prominence, or Flare, or whatever you want. Write your story using whatever name you are most comfortable with, and worry about the name once you get closer to publication. You should make note of any instances of the name that won't be easily caught by find and replace (such as the name getting cut short, puns on the name, or symbols based on the name, etc) so that you remember to change them later. That said, you probably don't have much to worry about. It sounds like you have clear sun related imagery in the book, so unless Corona is the first sun-related name mentioned in the book readers should have no problem making the proper associations. This is particularly true if your story is set in a secondary world, which will further isolate the readers from associations with real current events. Give yourself some time to wait until the current crisis is past and the media frenzy has died down, then give your book to beta readers and see if they comment on the name. If your beta readers report that the name Corona is pulling them out of the story, then worry about changing it. Not before.
217868	Infrasound. Those people are folowing The Hum. On our own Earth there is nothing conclusive about that, but it is not a stretch for it to be a real thing in a fictional world. What matters there is that the nomads either feel the minute planetary vibration on their skin rather than hearing it, or if they do pick it up with their ears, their brain processes it differently. Or they might be "feeling" the vibrations of tectonic plates, crushing against each other - the paths could exist along fault lines (and maybe magma plumes); As an alternative, rather than sounds, their ears might be picking up variations in the gravity of the planet itself (through the vestibular system). Our Earth's gravity is not homogeneous throughout the planet, though we are not sensitive enough to detect its variations. The nomad people in your story might be different from us in that aspect.
402926	Melkor, "he who arises in might" is as his creator made him. As far as Tolkien allows us to know, Ilúvatar understood Melkor's addition to the design and any changes he made to the works of others, only enhanced their beauty, functionality or overall quality in some way. This was as Ilúvatar decided it to be. As a creation myth it is almost necessary to have a force which opposes the general thread of the myth, lest there be no source for challenge, growth, development or change in the mythos. In his way Tolkien was ensuring his universe would have similar forces for change taking place through out the work. Does this inconvenience the creations? Yes. Does it force them to grow and evolve? Yes. Do they always make the best decisions? No. If they did, they would have learned nothing from their existence. Tolkien's work and his characters resemble most creation mythos with the strongest and brightest member of the pantheon having a frustrated itch they cannot scratch. Melkor's was a desire to create life, a power left only to Ilúvatar. Consider Lucifer who also wanted dominion over something that was uniquely his. I would consider everything that happened, as it should be, as Ilúvatar in his infinite wisdom allowed to take place. Could he change it? Sure. But if he did, what was the point of bringing Creation into existence at all if he was going to micromanage it?
440713	In the CW show, Barry Allen has gotten exponentially faster. in the start of the show, when he ran down a tornado, he was probably running around 300 mph, because the fastest tornado on record was 318 mph, and a young weather wizard couldn't have matched that. Later, in episode 6, he performs a supersonic punch, traveling at a bit over 800 mph. The speed of sound is 761 mph, and he was likely running a little faster to pull it off. Closer to the end of season 1, he accidentally time travels while building a wind wall while fighting the other weather wizard. Barry claims on a treadmill he was replicating that speed, with the treadmill monitor reading at around 900 mph. To artificially travel to the night his mom died, He was traveling over Mach 2, or 1500 mph. In the middle of season 2, he managed to leap across a bridge, which was calculated at Mach 3.3. When he acquired the tachyon splicer, he traveled "four times faster then ever before", which would calculate to around Mach 13.2. Keep in mind that his top speed so far is only 0.0015% lightspeed, so he still has a long way to run. But after the events of "The Runaway Dinosaur", who knows what he is capable of now? Perhaps he is capable of running faster than even Zoom! Zoom originally traveled at around the speed Barry could achieve through the Tachyon device. Now that his powers have doubled, Barry would have to run at 0.003% lightspeed, around Mach 27, to beat Zoom. This would be like trying to outrun a space shuttle taking off. Interestingly enough, if Barry takes all of Zoom's Speed (I think he might at the end of the season), then he could become faster than Voyager 1, the Fastest man-made object ever, currently traveling at Mach 50. Interesting!
554673	Both $U$ and $H$ are not directly related to any particular process. They are physical properties of the material being processed, and are unique functions of the thermodynamic state of the material, and not the process. They are directly proportional to the amount of material, and its thermodynamic state is characterized by its temperature and pressure (and composition for a multicomponent system). The internal energy is a fundamental property, but the enthalpy is a defined property given by $H = U + PV$, and is just a convenient parameter to work with is solving many kinds of thermodynamics problems. For a process carried out at constant pressure in a closed system, the amount of heat $Q$ added to the system turns out to be equal to the change in enthalpy between the initial state of the material and the final state of the material. For a chemical reaction carried out at constant pressure, the amount of heat $Q$ that must be added to the system in order for the final temperature of the products to equal the initial temperature of the reactants turns out to be equal to the enthalpy of the pure products minus the enthalpy of the pure reactants at that temperature. Both these results follow from the first law of thermdynamics. For a chemical reaction, generally both the internal energy and the enthalpy change between the initial and final equilibrium states. And what about cases where $P$ is not constant? What happens then? Can we calculate the value of $ΔH$? And does $ΔH$ even have a meaning in this case? Since $H$ is just defined as $U + PV$, we can always calculate the change in enthalpy between two thermodynamic equilibrium states of a system. $\Delta H$ certainly has a value in this case, even if it is not equal to the amount of heat added for a process between the two states. The critical thing to remember is that $U$ and $H$ are physical properties of the materials comprising a system, and are independent of any specific process.
977851	I've used WavePad from NCH Software for a couple of weeks now. It's a fantastic audio file editor. It has a few minor bugs in the interface, but does a great job of carefully controlled improvement of .mp3 files. NCH is in business to make money - surprise, surprise! So, they do their best to sell you other software. If you let it, it will install a thing called the NCH toolbar in your browsers. This has links to software that some paranoid utilties call a trojan. My wife installed it by accident and it took me all of 3 minutes to get rid of it completely. If you say yes to extras and demos, NCH will install things you may not want. On the other hand, they may be useful to large numbers of people. And, it's very easy to get rid of them if you find you don't want them. I can't comment on NCH's support, I haven't needed it. But, for a company that is claimed to have poor support, they go to great lengths to get your feedback and to provide software updates and access to beta upgrades. I have tried a couple of their demos, a video convertor, for example. I found it a very good buy decided I didn't really need it. The demo uninstalled quite well, but Revo Uninstaller found a few residual Registry entries and files that would have been deleted on reboot. That's fairly standard for Windows software and, if incomplete uninstalls worry you - get Revo! In short, NCH sells good software, so get rid of the trojan checkers and try using your brain instead. You'll find it's cheaper, quicker, less worrying, and much more reliable!
990836	Since you installed a new instance of Windows 7, all your programs will need to be reinstalled since they must all write to the new registry. I will assume that you have only one disk, but with two partitions, but even if you have two disks, I would do the same. First, backup your data if you have not already. You are doing a lot to your system, and if you make a mistake, you will be glad you did. Second, I would run some kind of serious disk checking utility to make sure your initial problems were not hardware-related (it does not sound that way, but now is the time to find out). I have professional tools to do that, so I am not sure what to recommend here. You could ask that in another question. You can then do either of the following: You can re-install all your programs on D:, and then move your data there. You could then free up C: for whatever else. I do not like this idea. Frankly, I do not like having my system partition as D, so I would probably save my data, then reformat the whole thing again, and put Windows on the first partition, C:. I prefer this because with the OS on Disk 0, partition 1, you do not risk partition changes that might throw off the BCD store (do a search here for BCDedit and look at the problems non-geeks have with this issue). Depending on the size of the drive, you could again make it two partitions (if so, leave plenty on the C partition...I would leave at least 25 GB, preferably 50GB, but that is just personal preference), or even just one partition. Of course, if you have two drives, one would be C:, and the other D:. You have probably not done much to your new D: Windows install, so you will not lose a lot of time this way.
1250570	Page 21 of the "Product Manual - Seagate": Applicable to: Standard models: ST3000DM008, ST2000DM006, ST1000DM010 and ST500DM009 Self-Encryption models: ST3000DM009 and ST2000DM007 "3.3 SATA cables and connectors The SATA interface cable consists of four conductors in two differential pairs, plus three ground connections. The cable size may be 30 to 26 AWG with a maximum length of one meter (39.37 inches). See Table 7 for connector pin definitions. Either end of the SATA signal cable can be attached to the drive or host. For direct backplane connection, the drive connectors are inserted directly into the host receptacle. The drive and the host receptacle incorporate features that enable the direct connection to be hot pluggable and blind mateable. For installations which require cables, users can connect the drive as illustrated in Figure 1. Each cable is keyed to ensure correct orientation. BarraCuda drives support latching SATA connectors.
2178529	Below are a few more sites that contain a lot of good composting information that you may find helpful/useful: Composting Council of Canada At Home With Compost: Clues on Composting The composter contents should be moist like a wrung-out sponge. If the contents are too dry, it will take overly long to compost; and if too wet, the contents may begin to smell. Troubleshooting If the pile does not decrease in size or generate heat, composting may need a boost. If the pile is dry, add water - mixing thoroughly. If the pile is wet and muddy, spread it in the sun and add dry material. Remember to save "old" compost to mix with incoming material. Create Your Own Compost Pile Having the right amount of greens, browns, and water is important for compost development. Ideally, your compost pile should have an equal amount of browns to greens and alternate layers of organic materials of different-size particles. The brown materials provide carbon for your compost and the green materials provide nitrogen, while the water provides moisture to help breakdown the organic matter. Backyard Composting Approach One 1 - Select a dry, shady spot near a water source for your compost pile or bin. 3 - Moisten dry materials as they are added. 5 - Optional: Cover top of compost with a tarp to keep it moist. Backyard Composting Approach Two 6 - Top with a 3-inch layer of brown materials, adding water until moist. 7 - Turn your compost pile every week or two with a pitchfork to distribute air and moisture. Move the dry materials from the edges into the middle of the pile. Continue this practice until the pile does not re-heat much after turning. Making and Using Compost Location Because the compost pile may need to be kept moist during dry weather, a convenient source of water should be available. But don’t locate the pile where water may stand. Excess moisture in the bottom of the pile can cause the process to stop or lead to odor problems. Layering Lightly water each layer as it is added. The entire pile should be as wet as a well-wrung sponge. Achieving this result is easier if you water each layer of dry material while building the pile rather than trying to wet the entire pile after it is built. Care of the pile Decomposition will occur even if a compost pile is ignored after it has been built, but it will occur at a slower rate. Adding water to maintain moist conditions and turning the pile to improve aeration will speed the process. To check the moisture content of the pile, squeeze a handful of compost. If a few drops of water can be squeezed out, moisture is about right. If no drops fall, the pile is too dry. If water trickles out, the pile is too wet. Cover the pile with plastic or other materials during wet weather to avoid excessive moisture buildup. Piles may be turned by slicing through them with a spade and turning over each slice. The main objectives of turning are to aerate the pile and to shift materials from the outside closer to the center, where they may also be heated and decomposed. Moisten dry spots in the pile by spraying with water during turning. US Composting Council
2240630	One more thing to consider is how the keys feel to play (I'm sure there's a technical term for it, but I don't know it, sorry). Basically the key resistance to being played. If you get yourself a cheap and simple musical keyboard, you'll notice very quickly that the keys tend to feel very differently - they tend to react to a much lighter touch which has its advantages when playing, but it works against you when learning to play (similar to learning to type on a mechanical typewriter like I did - still glad for it today!). A piano uses a hammer to hit the strings inside which requires a certain amount of force. Most simpler keyboards don't have that. So my recommendation is to include this in your search parameters and make sure to test a bunch of different instruments before buying. I used to have a digital piano (ages ago so I don't remember the brand) that felt very similar to a real piano, and it worked really well for my lessons and for strengthening my fingers.
2242177	An acoustic piano can be heard in adjacent flats and rooms by your neighbours. This may make you to practice less, avoid Sunday, do not use late night or morning hours you otherwise may have and the like. Acoustic piano may have better sound, keyboard feeling, external look and the like. However digital piano has sound regulator and the phone jack. Hopefully digital piano could be acceptable replacement at home. We do not need to have its quality better, just "good enough". Update 1: It may be regulations in some countries that defend your (or at least your child) rights to play the instrument as long as certain rules (silence times and limited number of hours) are followed, and the landlord may actually have no right to ban this even if it is written on the renting contract. I was not initially aware about this. Talk to your music teacher who must be aware. Headphones are still required to practice without any limitations. Update 2: It is important to understand the difference between the "keyboard" and "digital piano" or "stage piano". The lower end keyboard may lack multiple key sensitivity levels, pedals, be limited in range and polyphony, keys may feel completely differently, so understandable why many teachers see it only applicable to the very first lessons, if any. The differences between high end digital piano keyboard and the mechanical keyboard of the acustic piano are already subtle.
62053	They're not quite synonymous, although in this context some of them are interchangeable. Get back refers to the arrival. If you got back home at 3AM, it means you entered your home at 3AM, even if you've left earlier. Go back refers to the departure. If you went back home at 3AM, it means you left the place you had been at previously at 3AM, but arrived later, or even not at all. Come back refers to the arrival just like get back, with a caveat - if someone tells you to come back it means they're at the place they want you to be in. So your mom could tell you to come back home if she's waiting for you, but a friend you're out with would tell you to get or go back home. Arrive is more or less the same as get back in this context. Maybe with a little more emphasis on the journey - to me, arriving somewhere seems like a more arduous process than just getting somewhere. (Also, you can arrive somewhere you haven't been yet). Return in this context is somewhat ambiguous, although I'd read it as referring to the arrival rather than the departure. It's also more formal than the first three.
312226	I'm not sure this has a "right" mechanical answer. My sense is that it would be dictated by the setting and how all that stuff works in your game. Just as an exercise though, I can see a couple of ways to handle it. First, it could work a lot like the Necros in The Chronicles of Riddick. You kill the current Lord and you get his/her stuff. In this case, killing the Lord while difficult might not be nearly as hard as keeping your position later. Second, the Lordship could be based on being attuned to the magical nature of that level of Hell. Taking over means getting enough support (followers, magical energy, whatnot) to attune yourself to that level which would necessarily oust the current ruler. There are lots of other ways to deal with this as well. Probably a number of them documented in supplements. Regardless, I'd never make the solution a purely mechanical issue. Becoming one of the Lords of the Nine Hells ought to be very much a role-playing and story shaped proposition.
337938	Standard PHB Elves cannot grow beards (but Half-Elves can). As the PHB and the basic rules state: Elves have no facial and little body hair. and: Half-elf men do have facial hair, and sometimes grow beards to mask their elven ancestry. The fact that Elves cannot grow beards is specifically mentioned and is a known fact about the species - Half-Elves sometimes do it deliberately so that they look less like elves! You would expect a Belt of Dwarvenkind to cause a Half-Elf to grow a beard but not an Elf. You are, of course, your DM, and in your setting it might be different - you could decide that Elves can grow beards normally, or just that your special cursed version of the Belt of Dwarvenkind causes beard growth even in individuals who could not normally grow beards, such as elves or most women. Since it's intended to be a negative effect in context, it makes sense that it overrides the normal rules. BONUS PREVIOUS EDITIONS SECTION (a.k.a. I looked it up and now the question's changed scope I don't want to to just discard half my work) The subject of Elves and facial hair has been handled consistently since 3rd edition. 4e In 4e Elves sort of got split up as a race, becoming Elves or Eladrin. Eladrin, who are thematically more in line with the standard "high/moon elf" of earlier work, are described such: Eladrin can’t grow facial hair and have little body hair. The later description of Elves omits that specific detail: Elves have little body hair, but they favor a wild and loose look to their hair. However, the Wizards Presents Races and Classes preview book, which came out shortly before 4e's release and talked about the design of the edition, does state: Elves retain several of their distinguishing characteristics from earlier editions, most notably the pointed ears and the slight tilt to the eyes. And male elves don't have facial hair. As far as I can tell, though, no such item as the Belt of Dwarvenkind exists in 4e. 3/3.5e The 3.5 PHB, on page 15, says of the physical description of Elves: Elves have no facial or body hair. The same is not mentioned in the description of Half-Elves, which does clarify that: ... their actual skin tone, hair colour and other details vary just as human features do. (However, the 3e Belt of Dwarvenkind doesn't mention anything about causing beard growth.) Tolkien This particular facet of Elven biology appears to be in reference to the works of Tolkien which heavily inspired D&D; as per this answer over in the Sci-Fi/Fantasy stack, the Elves of Tolkien's works were almost entirely beardless, variously described as being unable to grow beards or (perhaps due to having to justify having accidentally described certain elves as having beards) only being able to do so when extremely old.
407491	I think the reason for other Kryptonians gaining their powers relatively quickly is that planet Krypton possesses conditions that are naturally more challenging that Earth, e.g. higher gravity, a less nourishing atmosphere and higher air pressure etc. Their bodies were naturally stronger and tougher upon arriving on Earth, providing intrinsically elevated physical abilities prior to yellow sunlight exposure. This may be why Kara seems stronger than Kal in so many iterations of the canon. However, I believe that Kal has a different advantage in that the amount of time spent on Earth, particularly in growing up under its yellow rays, has developed his ability to absorb radiation more efficiently. This therefore allows him to perform greater feats at full strength, making him unique and, ultimately, the most powerful 'superman'. (Note: I'm watching Man of Steel at the moment so this explanation is somewhat influenced by aspects of the movie's more grounded logic, which brings some interesting theories to the table.)
441070	So the question we're trying to answer here is how fast the Flash's top speed is right? If that's the case then there's actually a lot of ways to answer this question. In Flash: The Human Race, the Flash was able to beat instantaneous teleportation by absorbing the kinetic energy of everyone on Earth. By going this fast, the Flash ran faster than a planck instant therefore breaking what we call "speed" and "time". A planck instant (called planck time in real life) is the smallest unit by which we measure time and speed. So when the Flash ran this fast, he was everywhere and nowhere at the same time. So to beat instantaneous teleportation, the Flash had to go faster than a planck instant which leads me to say that instantaneous teleportation has to be a little slower than the speed of light. Before I get into more, I want to say that teleportation does not equal moving at high speeds, it's the transfer of information from point A to point B. This transfer, although seen as instantaneous, will still take time. Moving back to what I was saying before, teleportation is not faster than light. Einstein says that no information can travel faster than the speed of light. It's just not possible. But we go back to the Flash, he runs faster than a planck instant which is way faster than light. This is possible for two reasons: 1. It's a comic 2. He is not actually transferring info. He's just running faster than light by tapping into the Speed Force and absorbing the kinetic energy of all the people on Earth So there's my opinion on the Flash's top speed. However, we can also argue that the Flash doesn't really have a speed cap because there will always be the Speed Force. It literally says that since Barry Allen created the Speed Force and generates it with every step he takes, he can "reach any speed he imagines". If he wants to go faster than he just needs to generate more speed (sounds dumb and obvious, I know). The Flash's speed cap is therefore, unknown. We do know that he doesn't like to run faster than Mach 10 (7672.69 m/h according to google conversions) in Earth's environment because the results will be catastrophic. Just to let ya'all know, it was Wally West that ran faster than a planck instant not Barry Allen. Also here's a list of some conversions: Mach 2- 1534.54 m/h Mach 10- 7672.69 m/h SoS- 767.269 m/h (343 metres per second) SoL- 671 million m/h (exact value is 299,792,458 metres per second) Planck Instant- Undetermined. This is unable to be measured by the current technology that we have today. "As of May 2010, the smallest time interval that was directly measured was on the order of 12 attoseconds (12 × 10−18 seconds), about 10 24<---this is suppose to be an exponent) times larger than the Planck time."- Wikipedia
453663	They are not related, it is Snape's profound love for Lily that causes his Patronus to be a doe. The Patronus, asserted Spangle, represents that which is hidden, unknown but necessary within the personality. ‘For it is evident,’ he writes, in his masterwork ‘Charms of Defence and Deterrence‘… that a human confronted with inhuman evil, such as the Dementor, must draw upon resources he or she may never have needed, and the Patronus is the awakened secret self that lies dormant until needed, but which must now be brought to light...’ ... The form of a Patronus may change during the course of a witch or wizard’s life. Instances have been known of the form of the Patronus transforming due to bereavement,falling in love or profound shifts in a person’s character. Thus Nymphadora Tonks’s Patronus changes from a jack rabbit to a wolf (not a werewolf) when she falls in love with Remus Lupin. Some witches and wizards may be unable to produce a Patronus at all until they have undergone some kind of psychic shock. Patronus Charm by J.K. Rowling I don't think it is official known if Snape's Patronus changed at any point, however his happiest memories even from childhood were that of Lily Evans. Since the Patronus requires happy thoughts, it is only natural for Severus to draw on these. "But this is touching, Severus" said Dumbledore seriously. "Have you grown to care for the boy, after all?" "For him?" shouted Snape. "Expecto Patronum!" From the tip of his wand burst the silver doe: She landed on the office floor, bounded across the office, and soared out of the window. Dumbledore watched her fly away, and as he silvery glow faded he turned back to Snape, and his eyes were full of tears. "After all this time?" "Always" said Snape. Harry Potter and the Deathly Hallows
526048	Just pick a choice at random. If you see no reason why one choice will be superior to another, there is no reason to let decision paralysis and the myth of "the right choice" to hobble you. Pick a look you want to go for, any look, and then start systematically selecting some from your endless tools and exercising getting to that look until you feel you can pull it off reasonably well. Note which process gives you the best result. Then pick another look, rinse, repeat. With time, you might develop a narrow "style" and create a toolchain for yourself which gives your signature look without much effort. Or you might find that you are a good experimenter, giving each new project a unique feel. Or turn out to be somewhere in the middle. In any case, whatever you learn while learning to create the first look, will make you better at making the second. And the first and second will make you better at trying the third. And so on. The decision to rely on presets or not is not really important. It resolves itself in the process of finding out how to get to the look you are aiming for in the current project. And please don't let others tell you that you are doing something wrong if you are using the camera's WB or similar! Most ambitioned photographers do end up doing most of that stuff manually, but only because they find that having the additional control makes it easier to achieve whatever they are going for. Once you have a goal towards you are working, you will find for yourself where you need or want the extra control and where a preset is sufficient. The constraints of film may have helped you focus, because each frame "counted" more. But you don't need external constraints to focus, once you know how focusing works. The upside of the unconstrained digital environment is that it makes it safe to fail - you have as many tries as you need to achieve good results (and don't forget to not let the perfect be the enemy of the good). These are the best prerequisites for learning - go out there, use them, and shoot.
793952	From what I understand, GRE is one of the lesser important factors in whether a department should decide to admit a student or not. Since a PhD is about research, research experience/potential/output is what people care about in this case, not so much numbers like GPA/GRE. If the department requires it regardless, then there's nothing you can do about that. But if it's not required, don't worry about it so much and focus on getting good recommendations and producing good research since that will matter much more. Remember that due to the current pandemic situation, people have had increased difficulty just being able to take the GRE exam. So generally departments are understanding of the situation. But even in normal times, GRE was just really a filtering mechanism, and not really the main point of attention for those responsible for graduate/PhD admissions.
1037274	I have removed the NCH programs in the following manner, on Windows 7 Ultimate 64 bit: Using Windows Explorer (located on your task bar at the bottom of you screen) navigate to Program Files (86)/NCH SOFTWARE. Right click on the subdirectory NCH SOFTWARE. When the window opens with the function list then left click on “rename” in the list. Rename the sub directory NCH SOFTWARE to ###.NCH SOFTWARE where ### is something that you can remember very easy or put it on note paper. Press “ENTER”. Double click the new name and you will display a series of subdirectories. Explore each one and use the “UNISTALL” programs as you find them. There isn’t an uninstall program in every subdirectory but you must use all of them. Close Windows Explorer. In the next steps it is very important that you make no changes to the registry other than the one I am going to tell you about. Click on the Windows emblem in the lower left corner of you task bar. In the “Search Programs and Files windows type cmd. The top of the search windows will have a section labeled “PROGRAMS” click on the program titled “CMD”. In the black window that opens type regedit. In the Regedit window on the left side is the display of the registry. Highlight “computer”. In the regeditor window in the upper command bar click on “edit” in the drop down window select “find”. Enter “NCH” in the find window and click find next. The regeditor will stop at the first instance of “NCH”. When regedit finds NCH there should be a yellow square just to the left of the NCH. Right click on “NCH” in the drop down window select “RENAME” change the name to “###NCH###” where ### is something easy for you to remember or put it on note paper. Press Enter. Use the “F3” to fined next and continue until the find box displays the massage “Finished searching through the registry”. Now reboot. After the reboot check your program list and it should be clear of all NCH software. If you are sure all of the programs are disabled then you can delete the sub directory ###NCH SOFTWARE in Program Files (86). PS: NCH is not “legit”. Any company that causes a program to be installed on your computer without your permission is not “legit”. Any company that designs their program so it is hidden from the Control Panel for removing programs and hides there “UNINSTALL” programs in the directory tree and then charges to tell you where it is, is defiantly not “legit”
1042985	From what I understand, MS-DOS is the disk operating system that Microsoft released. The command prompt is a non-graphical interface that allows you to interact with your operating system. Command Prompt is a command line interpreter application available in most Windows operating systems, officially called the Windows Command Processor but sometimes called the command shell. Command Prompt is a Windows program that emulates many of the command line abilities available in MS-DOS but it is not actually MS-DOS. Command Prompt is a GUI version of command.com in MS-DOS. cmd.exe is a native Windows application usually running in a Win32 console. This allows it to take advantage of features available to native programs on the platform that are otherwise unavailable to DOS programs. For example, since cmd.exe is a native text-mode application on OS/2, it can use real pipes in command pipelines, allowing both sides of the pipeline to run concurrently. As a result, it is possible to redirect the standard error in cmd.exe, unlike COMMAND.COM. (COMMAND.COM uses temporary files, and runs the two sides serially, one after the other.) In reality, cmd.exe is a Windows program that acts as a DOS-like command line interpreter. It is generally compatible, but provides extensions which address some of the limitations of COMMAND.COM (above explanations are referred by Wikipedia).
1270481	/32 addressing Generally speaking, /32 means that the network has only a single IPv4 address and all traffic will go directly between the device with that IPv4 address and the default gateway. The device would not be able to communicate with other devices on the network. There are a couple of possible reasons for this that I've seen. It could be: A webserver serving multiple sites with each site bound to a specific IPv4 address A loopback address used for testing. Isolating a machine from the network to allow only statically set routes to connect. (For decommissioning, for example.) Network ID The network ID portion of an IP address is determined by the subnet mask. For example: A /24 IPv4 network has a subnet mask of 1111.1111.1111.0000, meaning the first 3 octets are the network ID and the last octet is used for assigning host IDs (256 available IDs, though usually some are reserved). A /16 IPv4 network has a subnet mask of 1111.1111.0000.0000, meaning the first 2 octets are the network ID and the last octet is used for assigning host IDs (65536 available IDs, though usually some are reserved). In the case of /32, this doesn't apply as the address is both a network ID and host ID. /31 addresses are also all host IDs with no reserved 0th address.
1316953	As clabacchio said, some capacitors are unpolarized, so it's perfectly fine to put positive and negative voltages on them. However, it is still possible to put a AC signal thru a polarized capacitor. This is done by adding a DC bias of at least half the AC peak-peak voltage. The entire signal is then still positive, but AC-wise the capacitor acts on it normally. Nowadays, polarized capacitors are mostly used for bulk storage on power supplies to reduce ripple and to provide short term high current. A nominal 12V supply, for example, may have 1Vpp AC ripple on it. That means the voltage is from 11.5V to 12.5V, which is fine for a electrolytic or other polarized cap. However, the large value of the cap will be applied to providing current to counter the 1Vpp AC voltage swing. Put another way, polarized caps must always have a positive voltage on them, but there is no such restriction on current.
1428252	Although some parts of the story are not completely clear to me, the overall situation seems to be a known problem. Why this can happen Connecting signals to an unpowered IC (in your case the second FPGA) is usually outside of that IC's specification (with a few exceptions, typically on ICs which are specifically designed for bus isolation - see below). Check that device's datasheet, to see if the input voltage specification mentions Vcc / Vdd, or a specific voltage. If it mentions voltages referenced to Vcc / Vdd then think about what that means, when the device is unpowered. If you need help interpreting the datasheet of your FPGA, then supply a link to its electrical specifications page, and we can try to find the relevant part for you. If you do connect signals to such an unpowered IC, then this tends to try to power the unpowered IC through the ESD protection structures on those signal pins of the unpowered IC. However the IC was never intended to be powered through its signal pins, those signals may be unable to supply the necessary current to power the IC (of course, they were never designed to do that) and so the signal voltages may go out-of-specification, the IC may not be powered correctly (since this method of supplying power was never intended) and a variety of incorrect behaviour can be seen. See the questions & answers to these previous topics, for similar problems: Isolate microcontroller from board and use other one Unpowered devices on I2C/SPI bus how to fix it? Use appropriate bus isolation ICs, which are designed to allow one part of a bus to be unpowered, without affecting other devices on the powered part of the bus. For example, TI and Analog Devices (among many other manufacturers) make such devices, depending on your speed, current, package, cost, availability and other requirements. In some cases, the 74LCX125 (which has a specification that allows for active input signals, even when it is unpowered) is an example of a type of IC which can be used to buffer signals to an unpowered device i.e. the 74LCX125 and the unpowered device would be connected to the same power rail, and therefore become powered or unpowered together.
2295828	You'll probably have an easier time using a picture hanger than a screw, and it will leave your wall in better shape when you remove it. Picture hangers transfer the downward force into pressure into the wall because the nail is mounted at an angle. The screw, on the other hand, is being bent because you're acting as a lever, where the stud is the fulcrum, the drywall is just empty space, and the wire is the force applied at the end. Even if you get a stronger screw, you're still placing a significant twisting force into the stud. You can't use your typical picture hanger for a task like this. The small hangers that come in most kits are rated to only 20-30 lbs. However, you can find hangers like this one that is rated to 100 lbs (and I'd still use two of them, since it will make adjusting for level much easier and reduce the risk of failure). The other option is called a french cleat which are two interlocking rails, one that attaches to the wall, and the other to what you're hanging. As long as you install them both straight and level, you don't need to adjust the mirror for level, and it distributes the weight across a larger area, reducing the risk of a failure.
188475	I know that the majority of the hills and valleys in Scotland, north England and Wales were formed by glaciation, and the rivers that then followed those paths. Based on that I would make the huuuge assumption that without ice, those "indents" into what was once the surface level of the ground would never have been made. This would give large and high plateau areas instead. Another interesting thing to note is that since the ice of the last ice age disappeared from Great Britain, it's northern end has been "bouncing back" due to the absence of the weight of the ice. That is, the northern end of the island is gaining altitude, whilst the southern end is effectively sinking into the sea in balance. Without the ice, this also would not be happening. Without the ice, the British Isles would also most likely still be joined together (one British Isle, singular), and probably also still joined to Europe as your lovely diagram states. This would likely have rather huge effects on the biodiversity of the Isles, the path human development and their cultures took, and all historical events that have resulted since human settlement. Edit: To clarify, the separation of the British Isles from mainland Europe is thought to have occurred due to "two catastrophic glacial lake outburst floods" caused by the breaching of an extremely large lake under what is now the North Sea. This is not ice directly on the British Isles, but arguably the removal of that ice contributed to the breaching of the lake. Pretty big hypothetical you got there.
331476	EDIT: As @Wyrmwood pointed and I missed: assuming a BAB of 4 or higher Then I will consider it as so from now on. I believe the main advantage of Total Defense over Combat Expertise and Fighting Defensively is the possibility of a safer approach or crossing a threatened area generating AoO before your attack, specially with 5 ranks in Tumble. Total Defense is clearly a better option for those that need the extra AC now and are not threatening anyone and/or can't attack. Even more to those that also are in the threatening area of an enemy that you can't hit melee from your position (bigger enemy or reach weapons). Imagine these scenarios: • Level 9: Two Athach surprised the party in a closed space and you (a Rogue) are alone at the other side, with no way out except step between/alongside them. It would be hard to tumble all that threatening area at this level, unless you have enough speed and confidence. However, you may use your standard action to get a +6 dodge bonus to AC and try to pass alive against the 2 AoO. A level 9 Rogue, for example, usually have an AC between 21 to 25 at level 9, with +6 she goes between 27 to 31 against the +16 to hit of the athaches (+12 in a full attack). You may not have enough speed to cross this huge area, but maybe enough to reach to cross one and stay close to the rest of the party (at least close enough for the cleric reach with Revivify). • Level 6: An already hurt human Scout must cross the battle to reach the cleric to receive healing, but with 5 thugs on his way, even with his 40ft.(12m) speed, quick tumble while avoiding 5 AdO is too much (DC 33). Thanks to his Mobility feat (normal feat for as Scout at level 4 bonus feat) he already has +4 to AC against AdO for crossing this death corridor, using the Total Defense standard action, the aforementioned scout has +10 extra dodge bonus to his AC to escape his predicament and reach the healing mach..., I mean, the cleric. If you change to people that can't tumble his way out and have Combat Expertise (Fighters, Crusaders etc), both scenario are still true, but they may have a reach weapon that allow them to use combat expertise from relative safety, but everything goes down when you give longspears (or spiked chains if you are really mean) to the ogres or fighting a Gargantuan Monstrous Centipede, basically anything with more reach than you.
397301	Yes, Superman was really super even compared to other Kryptonians. (Or at least he was until the DCnU New 52 changed the DC Universe, yet again.) Under the original premise, as the Last Son of Krypton, Kal-El/Superman gained his powers due to the slow and long-term exposure of his body to the radiation of our yellow sun. This made him a force to be reckoned with in comparison to other Kryptonians because of his much greater strength, durability, experience and control in the use of his many powers. Superman and the rays of the Sun Yes, according to writers who wanted to boost Superman's powers in the early 1950's he gained extraordinary abilities after his exposure to the Earth's yellow sun. Early Superman was only capable of leaping a quarter of a mile and running faster than a freight train. These modest feats would still make him amazing by the standards of the early 1940-1950s. Take a look at these clips from Secret Origins #1. Early Superman being heroic, leaping tall buildings and chasing cars on foot. No, there is nothing currently in science that would explain this, so don't think too deeply, the writers who conceived of Superman's powers beyond those that were derived from Earth's lessened gravity. They knew next to nothing about stars, solar energy, radiation or properties of stars. They did not realize how little difference there is between a red sun and a yellow one besides color, energy output and the star's life-span. This exposure to a yellow sun would activate a process by which his Kryptonian cells would become super-charged and along with the reduced gravity of Earth, make him capable of a host of amazing superhuman abilities, making him one of the physically most power powerful beings on the planet. That said, over the years, there have been many reboots and changes to the premise of how quickly Kal-El would gain his powers (one continuity had him gain his powers as a child and have an entire career of superherodom as Superboy.) This was later retconned out of existence. Most tales now have Superman gaining his powers as an adult after years of exposure to solar radiation. This however does not explain the rapid speed that most Kryptonians seem to gain their powers once exposed to the yellow sun of Earth. In the new Krypton stories, the Kryptonians also possess superpowers and this was not after decades of exposure. So what makes Superman super? What make Superman super has been characterized by the RESTRAINT he has in the use of his powers. Even when Kryptonians have had powers from the sun, he was often considered stronger due to the amount of exposure he had compared to theirs. Current DCnU seems to be working toward the idea of Kryptonians needing time to gain powers under a yellow sun. Supergirl's spaceship had a device designed to charge her cells with yellow sun radiation. In earlier continuities, Superman was considered to have a store of internalized energy that had built up over the decades, making him stronger, tougher, with greater endurance than a Kryptonian who found themselves empowered by the sun but not with the longevity Superman would have had being continuously exposed to the power-giving radiations. His other advantage, played up by writers was his experience with using his superpowers. This may not be as apparent with the reboot of the DCnU but in earlier continuities, his experience being Superman, the use of his powers, the vulnerabilities he had to learn to overcome gave him a decided advantage in a fight with other Kryptonians. Imagine discovering yourself with the ability to hear all along the auditory range and not having practice discerning which sounds were important, how to differentiate sound levels, and controlling what ranges you were interested in hearing sounds at. Supergirl is overwhelmed by her new super-senses. Supergirl #2 Now add to that visual acuity through the entire electromagnetic spectrum, telescopic, microscopic visions, energy projection from your eyes, a sense of smell ten thousand times better than a human and all of this happening simultaneously in addition to having strength millions of times greater than you previously had before, all of this would make for a confusing time as you learned to adjust. Did I mention, flying? In the previous DCU all Kryptonians under a yellow sun, possess vast superhuman strength, speed, and stamina, invulnerability; flight; super breath; x-ray vision; telescopic and microscopic vision; freeze breath; heat vision; and super hearing. If they are trained properly, they will be able to use these abilities with some degree of effectiveness. Why does Supergirl in the DCnU appear more powerful than Superman? If previous continuities are any gauge, Kryptonians grow more powerful, the longer they remain under a yellow sun. So both Superman and Supergirl, assuming they do not deplete their store of internal energy (See Doomsday vs Superman in the Death of Superman) will continue to slowly grow more powerful over time. Supergirl has appeared in conflicts with Superman to be more physically powerful. Superman asserts he has spent his time as a superhuman learning how to restrain his powers to do as little collateral damage as possible. Exercising restraint often means having to take significant abuse on Superman's part. Where Supergirl, new to the fragility of the Earth's environment has not yet learned how to control the amount of damage she causes when she uses her powers at their highest settings. If this does not change, she will most assuredly kill someone, most likely as an unintended consequence of using her powers without a degree of discretion.
400406	There's no prize in assimilating Earth in the past. Borg are driven to assimilate species only if they can add to the collective. Humans are biologically inferior to species that the Borg have already assimilated. The Borg are more interested in the Federation's technology. Traveling back in time to assimilate pre-warp Earth would gain them nothing but a biologically unremarkable species with no redundant vital organs, etc. What the Borg ought to do instead is send more than one ship to assimilate Earth. We've heard about he Borg assimilating other Delta Quadrant species (like the one in VOY "Hope and Fear".) He spoke of 'hundreds of cubes' when the Borg finally got his species. Both times the Borg launched an attack on Earth, it was just a single vessel that juuuuust about succeeded. Sending two ships would be a better idea. Or three. Or fifteen.
843924	For a quick simple explanation: In both gradient descent (GD) and stochastic gradient descent (SGD), you update a set of parameters in an iterative manner to minimize an error function. While in GD, you have to run through ALL the samples in your training set to do a single update for a parameter in a particular iteration, in SGD, on the other hand, you use ONLY ONE or SUBSET of training sample from your training set to do the update for a parameter in a particular iteration. If you use SUBSET, it is called Minibatch Stochastic gradient Descent. Thus, if the number of training samples are large, in fact very large, then using gradient descent may take too long because in every iteration when you are updating the values of the parameters, you are running through the complete training set. On the other hand, using SGD will be faster because you use only one training sample and it starts improving itself right away from the first sample. SGD often converges much faster compared to GD but the error function is not as well minimized as in the case of GD. Often in most cases, the close approximation that you get in SGD for the parameter values are enough because they reach the optimal values and keep oscillating there. If you need an example of this with a practical case, check Andrew NG's notes here where he clearly shows you the steps involved in both the cases. cs229-notes Source: Quora Thread
907519	Size is the actual size of the file in bytes. Size on disk is the actual amount of space being taken up on the disk. They differ because the disk is divided into tracks and sectors, and can allocate blocks of discrete size. For a more detailed explanation, see this text which I copied from another site: We know that a disk is made up of Tracks and Sectors. In Windows that means the OS allocates space for files in "clusters" or "allocation units". The size of a cluster can vary, but typical ranges are from 512 bytes to 32K or more. For example, on my C:\ drive, the allocation unit is 4096 bytes. This means that Windows will allocate 4096 bytes for any file or portion of a file that is from 1 to 4096 bytes in length. If I have a file that is 17KB (kilo bytes), then the Size on disk would be 20.48 KB (or 20480 bytes). The calculation would be 4096 (1 allocation unit) x 5 = 20480 bytes. It takes 5 allocation units to hold a 17KB file. Another example would be if I have a file that is 2000 bytes in size. The file size on disk would be 4096 bytes. The reason is, because even though the entire file can fit inside one allocation unit, it still takes up 4096 of space (one allocation unit) on disk (only one file can use an allocation unit and cannot be shared with other files). So the size on disk is the space of all those sectors in which the file is saved. That means,usually, the size on disk is always greater than the actual size. So the actual size of a file(s) or folder(s) should always be taken from the Size value when viewing the properties window. Source: What's The Difference Between Size And Size On Disk In Windows Folder Properties.
1438631	I would say that it does not matter, but there are trade-offs for each type of current sensing. Assuming the voltage source is always DC: High-side current sensing often needs a precision voltage divider to get within the common mode range of the op-amp/comparator. An option in some cases is an op-amp designed for high-side current sensing, but it may need supply voltage greater than what your sensing the current on. The sense resistor need to be greater then 1 ohm most times, and as high as ten ohms, thus loosing some voltage across it. Low side current sensing is preferred in many cases where you already have an isolated source. The sense resistor can often be less than 1 ohm so voltage drop is tiny. The penalty is if a serious over-current or in-rush current exist. It can damage a low-ohm resistor, so it should be over-sized if possible. As far as random oscillation goes, you can put a 100nF capacitor across the 10 K resistor of U1. In addition you have no bypass capacitors on your power supply input and output. At least 470 uF from U3 collector to PSU ground and from U3 emitter to PSU ground. One of the main reasons for using capacitors is to stop spurious oscillations. A 'loose' rule is 2,000 uF per each amp of current consumed by the load.
1893274	If it were me, with only 5 desktops to worry about, I probably wouldn't bother with it. There are 3 aspects to WSUS that make it a necessity once you reach a certain size: It cuts down network usage. Every update is downloaded once only. It allows you to set policies and be selective about what you apply. If you run bespoke, business critical software, WSUS is a must to allow you to withhold patches so they can be tested. It gives you a centralised reporting mechanism for seeing which machines have been updated properly. With 5 PCs: 1 is really not an issue and 2 you can probably deal with - If you only used boxed products, then it's incredibly rare that the critical and security updates will cause you any grief (Just don't install drivers from Windows update). 3 depends on how much control you give your users over their PCs and how much visibility you need over their update status. If you turn off WSUS, then I'd recommend giving your desktops a manual health check once a month, or so.
1898417	If you have a wildcard certificate you can do named-based virtual hosting just like you do without SSL. When negotiating an SSL connection, your web server needs to select a certificate BEFORE any http protocol headers have been received -- which means that, without SNI, Apache can't select between multiple name-based virtual hosts. This is why in the past you needed a separate ip address for every virtual host hosted on your system. Using SNI, the client is able to provide the server with the name of the host to which it wishes to connect. This allows the server to select the appropriate virtual host configuration, and hence the appropriate certificate. If you're using a wildcard certificate, you sidestep this problem as long as all of your virtual hosts share a common parent domain. In this case, SNI is unnecessary. Because the certificate is valid for any of your hosts, there's no requirement that your web server is able to identify the appropriate virtual host at the beginning of the SSL negotiation...which means you can use the HTTP headers to identify the host, and proceed with normal name-based virtual hosting. Using Apache, your configuration would look something like this: NameVirtualHost *:443 <VirtualHost *:443> ServerName foo.example.com DocumentRoot /sites/foo.example.com/html SSLEngine On # ...other SSL parameters... </VirtualHost> <VirtualHost *:443> ServerName bar.example.com DocumentRoot /sites/bar.example.com/html SSLEngine On # ...other SSL parameters... </VirtualHost> We're been running this sort of configuration in a production situation for a few years now without problems.
2247934	I'm not sure what you mean by “the natural scales formulae”, but it should be clear that any “natural scale” will not “naturally” have steps of the same size. The diatonic scales were discovered long before the 12-edo tuning that we now use for playing these scales on piano etc., and for measuring the size of intervals therein. The original derivation uses no equally-spaced grid at all, but defines intervals by their frequency ratio. For the purposes of “harmonic music” we basically need the Ptolemaic scale of just intonation. You get it by making the I, IV and V chords just major chords, which are the “ideal consonant sound”: I is, well, the base frequency, by convention we call it 1/1. iii has to be the the pure major third in the I chord, that requires a relative frequency 5/4. V is the pure fifth in the I chord, rel.freq. 3/2. IV is the pure fourth (so I will be the fifth of the IV chord) ⇒ relative frequency 4/3. vi is the pure major third above IV, rel.freq. 4/3 · 5/4 = 5/3. ii is the fifth in the V chord (one octave down), rel.freq. 3/4 · 3/2 = 9/8. vii is the pure1 major third above V, rel.freq. 3/2 · 5/4 = 15/8. Now... if you order these and do the maths, you'll find there are actually not just two, but three different steps! Namely, The greater tone is found between I and ii as well as IV and V and also vi and vii, with ratio 9/8 each. That is 204 cents (i.e., a little bit wider than a whole tone step on a 12-edo instrument such as piano). The lesser tone (not to be confused with minor) is found between ii and iii as well as V and vi, with ratio 10/9, which is 182 cents. Significantly smaller than a whole tone in a 12-edo. The semitone is found between iii and IV as well as vii and I, with ratio 16/15, or 112 cents. A bit wider than a 12-edo semitone. Now, while the major chords sound indeed amazing in the Ptomemaic scale, other things you'd like to do musically are complicated by all these different intervals; that's why most western instruments with fixed pitch detune the steps a bit, so the system becomes easier to overview for composers and players. The greater and lesser tones are reasonably similar, so if you approximate them both by one single size in between you can still have pretty consonant chords in your scale. That's the idea behind meantone temperaments (12-edo is one of these). OTOH, the semitone is arguably not similar to either of the whole tone steps, so if tried to also include these in a “one size, fits all” step, the chords would really sound out of tune2. But it's quite close to half the size of a whole step. 12-edo makes it exactly half the size, so your overall scale then lies on a fixed grid of semitones, where whole notes simply are a double step. 1It is widely accepted that at least the vii note, which is the leading tone from the dominant to the tonic, should typically be played higher than this value, to emphasise that the dominant is a dissonance that wants to resolve to the tonic. 2Which doesn't mean you can't use such a scale musically.
2428193	It didn't damage your battery or the charging at all. Because: All batteries in automotive created for simultaneously charging and discharging otherwise your car will not have an alternator in the first place. Your charger (SMPS type or Transformer type) has an output diode to maintain the current flow in a single direction, so the current from your battery would not affect the charger. Almost all chargers would work with a limited current. Even without a current limiter, the charge current will reduce constantly with the voltage increase. (SO don't worry about blowing up your charger). And all charger basically using voltage limiter And it wouldn't damage your electronic component in your car nor the alternator. Because the alternator has the diode to block the reverse current. The main concerns are: Your battery didn't charge at full capacity if your battery charger current is lower than your lamps. Your battery charger would be hot or warmer because it took longer than it should. Your lamps would be hot enough to melt some plastic near them, check if something out of order near your lamp. If your cable to the lamps using small wire could be hot enough to melt too, check it again.
119948	I answer your question for APA. Psychological papers are very rigidly formatted, so possibly you have more leeway when following MLA, but I would suspect that the basics still apply. To answer your question, we must first understand what the purpose of the headings is. To understand that, let's take a step back and look at the paper's title. The APA Manual says that A title should summarize the main idea of the manuscript simply and, if possible, with style. It should be a concise statement of the main topic and should identify the variables and theoretical issues under investigation and the relationship between them. An example of a good title is "Effect of Transformed Letters on Reading Speed." A title should be fully explanatory when standing alone. Although its principal function is to inform the reader about the study, a title is also used as a statement of article content for abstracting and reference purposes in databases such as APA's PsycINFO. A good title is easily shortened to the running head used within the published article. (APA, 2009, p. 23) As an article in the APA Style Blog explains, a title should not be a question: A great title gives away the ending. If your title is in the form of a yes–no question, try rephrasing it so that the question is answered or the answer at least alluded to. This primes the reader for deeper comprehension. If Philip K. Dick had written for an academic audience, you might be perusing Androids Dream of Electric Sheep: Empathy in Nonhuman Species before bed tonight. (http://blog.apastyle.org/apastyle/2010/07/five-steps-to-a-great-title.html) Why does the title of an academic paper have to "give away the ending"? Let's take another step back and look at the purpose of academic writing. Academic writing, while it certainly profits from being entertaining, has the main purpose of transporting information. Throughout the APA Manual the basic requirement for academic writing is emphasized repeatedly, for example in the title of chapter 3: Writing Clearly and Concisely. The prime objective of scientific reporting is clear communication. You can achieve this by presenting ideas in an orderly manner and by expressing yourself smoothly and precisely. Now, if we want to understand what makes a good section heading, we only have to think of the heading as the title to that section and keep in mind the basic purpose of academic writing. Most academics have to read several articles each day, besides doing their research, writing their own papers, holding classes, correcting student work, and taking care of administration. For that reason, exerimental papers in the natural sciences all have the same structure, and the main sections usually all have the same headings: Introduction, Methods, Results, Discussion. For most natural scientists writing up their experimental findings, your question of phrasing a section heading as a question cannot arise, because the headings are predefined. But even if you deviate from this dogmatic style, your headings still have the purpose of organizing your communication and identifying structural elements: In scientific writing, sound organizational structure is the key to clear, precise, and logical communication. This includes the use of headings to effectively organzie the ideas within a study as well as seriation to highlight important items within sections. Concise headings help the reader anticipate key points and track the development of your argument. Taking all this together, if you wrote your paper according to APA stlye, your section headings must not be phrased as questions. But "Why Eating Vegetables is Important" is not a good section heading either, because it does not "give away the ending". A good section heading might be something like: Vegetables protect the body from oxidant stress that is: a good section heading will be the answer to the question.
266865	If we're talking hard sci-fi, I think we just come back to the usual problem that any attacker can just accelerate any projectile to near light speed and chuck it at whatever they want to destroy, and the target has no practical way of defending themselves. If you want to soften your sci-fi, then it's basically up to you what you want to make up to get around this problem. This might be a bit of a hippy-ish answer that doesn't mean the spirit of your question, but couldn't there be a negotiated outcome to this problem? Both factions obviously value the stargates greatly, and both factions have the ability to destroy the stargates at any time, so either conflict breaks out and the stargates are all very quickly destroyed, either deliberately or accidentally. Or, both sides sit down and hammer out a compromise - stargates can be used for space travel on weekdays, but must be reserved for religious veneration on weekends - something like that?
397300	What makes Superman Super (that is, extraordinary) is not merely the set of powers he has as a Kryptonian under a yellow sun. Those powers are standard for any Kryptonians on Earth. What makes him special is his personality. The way he uses those powers for good is what makes him exceptional. The story Red Sun is all about this, as it has Superman's ship land in the USSR instead of Kansas, so he's raised by Soviets instead of the Kents. But purely in terms of powers, he has no abnormal powers for a Kryptonian. Any other Kryptonian on Earth would gain powers roughly identical to Superman's. Admittedly the varying physical strength of various Kryptonians would still apply. So Supergirl would be physically weaker than Superman, simply due to her smaller size and lower muscle mass. It's unclear from the question what canon or timeframe we should be pulling from here, but in pre-New 52 DC Universe, Zod and friends escaped from the Phantom Zone and were physical equals to Superman. Later, the shrunken bottle city of Kandor was embiggened, which released 100,000 Kryptonians on Earth, and they were roughly as strong as Superman. Superman maintained an advantage over them in combat due to his greater experience with his powers. The other Kryptonians were used to their standard (roughly human-level) level of strength/speed/etc when they received their powers, which took some adjustment.
402929	Melkor's "fall" was that he wanted to make new things, that he wanted to go beyond the bounds of his own intrinsic abilities and nature, that he wanted to be more than what he was (there are interesting parallels to this in other "falls" in the Silmarillion & associated works, but they're for another time): But as the theme progressed, it came into the heart of Melkor to interweave matters of his own imagining that were not in accord with the theme of Iluvatar, for he sought therein to increase the power and glory of the part assigned to himself. To Melkor among the Ainur had been given the greatest gifts of power and knowledge, and he had a share in all the gifts of his brethren. He had gone often alone into the void places seeking the Imperishable Flame; for desire grew hot within him to bring into Being things of his own, and it seemed to him that Iluvatar took no thought for the Void, and he was impatient of its emptiness. However: But being alone he had begun to conceive thoughts of his own unlike those of his brethren. So Melkor's discord was of his own imagining, but did Iluvatar create him with the capability to imagine this discord, or did he come upon it on his own? Let's ask Iluvatar... This is your minstrelsy; and each of you shall find contained herein, amid the design that I set before you, all those things which it may seem that he himself devised or added. And thou, Melkor, wilt discover all the secret thoughts of thy mind, and wilt perceive that they are but a part of the whole and tributary to its glory. (My emphasis) And (in case we were in any doubt)... And thou, Melkor, shalt see that no theme may be played that hath not its uttermost source in me, nor can any alter the music in my despite. For he that attempteth this shall prove but mine instrument in the devising of things more wonderful, which he himself hath not imagined. This makes it clear. It seems to the Ainur as if they devised things on their own, but ultimately even these things that it seems to them are their own doing are a part of the Music as directed by Iluvatar. Just to reinforce the point; there is only one order of being in Tolkien which has the ability to go beyond the bounds of the music as directed by Iluvatar, and that's Men, and the ability was an explicit gift from Iluvatar: '...But to the Atani I will give a new gift.' Therefore to willed that the hearts of Men should seek beyond the world and should find no rest therein; but they should have a virtue to shape their life, amid the powers and chances of the world, beyond the Music of the Ainur, which is as fate to all things else... Note in particular the phrase "new gift" here; this is something else that no other being has had before.
631735	You want some sort of bootstrap or method for generating independent measurements of performance. You can't look at the k cross validation folds or divide the test set into k partitions as the observations won't be independent. This can and will introduce significant bias in the estimate of variance. See for example Yoshua Bengio's "No Unbiased Estimator of the Variance of K-Fold Cross-Validation" It isn't even really valid to look at best and worst case performance on the CV folds since they aren't really independent draws...some folds will just have much worse or much better performance. You could do an out-of-bag estimates of performance where you essentially repeatedly bootstrapping training data sets and get performance on the rest of the data. See this write up by Breiman and the referenced earlier work by Tibshirani on estimating performance variance this way If that is computationally prohibitive because you have a ton of data i'd wonder about bootstrapping or otherwise resampling just the holdout set but I can't think of or find a reference for that off hand.
1270523	What you're looking at are not subnet masks. They are indications of the length of the routing table¹ prefixes. A naïve implementation of a routing table would list every possible IP address so that, given any IP address, you'd look up that exact one and get back the routing information² associated with it. Clearly some sort of compression is needed. The nature of routing information is that adjacent addresses are likely to use the same information, so we can use a form of radix tree to compress these together. Here, briefly, is how it works. Given the numbers 0-7, we can represent them in binary as so: 0 000 1 001 2 010 3 011 4 100 5 101 6 110 7 111 Now if we have two routing table entries, one for addresses 0 and 1, and another for addreses 2 and 3, we can store them under the binary prefixes that these share. If we use a . to indicate the "unused" bit after the end of the prefix, we have 00. for the range 0-1 and 01. for the range 2-3. A standard way of representing this is with the lowest number from the range followed by the length of the prefix; in this case these would be 0/2 for the range 0-1 and 2/2 for the range 2-3. But what happens if we want to look up the routing information for address 6? Normally we'd add a "default" set of routing information with prefix 0/0, i.e., matching any bits at all and then when we search we look for the most specific information i.e, the longest matching prefix, we can find. So the full routing table we've just described is: 0/2 00. Matches addresses 1 and 2. 2/2 01. Matches addresses 3 and 4. 0/0 ... Matches any address. Subnet masks can be described with prefixes in the same way, and so this scheme is often used for that. But keep in mind that just because this scheme can be used for describing subnets does not mean that it's used only for describing subnets. As an example of routing table prefixes not being subnets, you could have two network interfaces connected to the same network, say, 192.168.2.0/24. (This could be implemented by connecting two separate network cards to the same switch, each with its own cable.) You could then set up the routing table to "balance" outgoing traffic across the two interfaces by using two routing table entries: 192.168.2.0/25 eth0 # range ...2.0 to ...2.127 192.168.2.128/25 eth1 # range ...2.128 to ...2.255 This would send packets destined to addresses 0-127 on that network out eth0, but packets destined to addresses 128-255 on that network out eth1. This is a bad way of doing this (for reasons I won't get into here), but demonstrates how routing prefixes and network addresses might not match. ¹ The Wikipedia article on routing tables unfortunately says that the prefix field holds the "Network ID." While this may be true in certain specific implementations of routing tables, it's not always a network ID in the general case, as seen in both the example you provide and my example later in this answer. ² This routing information typically includes things like what interface to use, what router to contact on that interface, if any, the MAC address of a host for hosts directly reachable through that interface, what source address we should put on the packet if the host has multiple source addresses, security information, and so on. There's a huge variety of data that could be there, but none of that is important for the purposes of this discussion since we're talking just about how you look up the correct data set for a given address, not what's in the data set itself.
1855229	I've had pretty good luck with servers from Aberdeen. They are typically re-branded SuperMicro servers. You may also want to look into Silicon Mechanics although they only offer 3 a year warranty. Edit: I should have also mentioned that Aberdeen sells on-site support contracts that are managed by a third party. They can tell you more about that if you contact them. I haven't had any experience with this so I can't comment on how good it is. My experience with warranty issues with Aberdeen have mostly been drive and power supply failures. For drives I normally keep a hot-spare in the array and a cold spare on-site so dealing with this failure is't a big deal. With their XDAS storage stuff I've had a lot of PSU issues so I like to keep a cold spare PSU on site if possible. But they can normally overnight you parts.
2162139	A nice way to tell the sex of a corn snake is by the shape of the tail. Reptiles have what's referred to as a hemipenis, and because of the way it's positioned in their tail, the male's tail will be thicker after the cloacal opening when compared with a female, who's tail will taper immediately after the cloacal. (Source) Another, potentially more reliable method, is by counting the scales after the cloacal. Simply count the rows from the cloacal to the tip of the tail. 130 or less is a good sign that you have a female. 140 or more is a good sign that you have a male. If you count somewhere in between 130 and 140 then it's not going to be definitive to say. In this case I would suggest also looking at the shape of the tail for that thicker section. Note: Unless you have an extremely well behaved snake, it's going to be hard to count the scales on it. So I would suggest taking a picture, or even using one if it's shed skin. Of course these are all going to be reliable to a fault, and aside from putting two snakes together and waiting to see if they mate, the only way to know for sure is by probing or popping the cloacal opening to see the sex organs. As I've mentioned in one of my other answers I'm against these practices because I believe it's an unnecessary risk considering the damages that can be caused by it. While it's debatable about whether or not snakes are less at risk to the damage than lizards, I would insist that anyone wanting to perform the procedure themselves have hands-on training from someone with experience (and that you can trust) first. Only someone with training should probe a snake. My suggestion is to try the non-invasive methods first, then if you're not convinced after that, you can take it to a reptile vet to have it sexed. As a new pet, it's a good idea to have a check-up from a vet anyways, so you can have it checked for parasites at the same time.
2219913	Acrylic and metal have very different expansion coefficients, so you need something that will not only bond with both materials but will remain flexible. The question isn't clear as to whether the metal will be sealing the snow globe (described as a jar cap). If so, the adhesive and the bond also need to be unaffected by the liquid in the globe. Common liquids for this purpose are water, glycerin, or baby oil/mineral oil. Water or oil can be a problem for many adhesives. Dow Corning DOWSIL 832 Multi-Surface Adhesive Sealant This is the best adhesive I can think of for this purpose. It's a silicone adhesive and sealant designed to bond strongly to acrylic and many other plastics and most common metals (not all silicones bond well with acrylic). This will also be impervious to any of the liquids typically used in a snow globe if it is being used to seal the globe. E6000 This is another adhesive that ought to work but I've never tested it for this purpose. It bonds strongly with many plastics and most metals. Once it dries, it isn't affected by the liquids typically used in a snow globe.
2240629	If you want to compare acoustic piano and digital ones, they are more or less the same instrument, digital pianos are just cheaper, lighter and quieter substitutes. If you want to be as close as possible to the feel of a real piano, you'll have to chose wisely and to still invest a good amount of money. The additional features (organ sounds and stuff) are mostly gadgets in that regard. If you can afford the cost, the weight and the sonic disturbance of the real one, there's not much of a discussion here. You will hear everything and its opposite concerning digital pianos: some people claiming to having played acoustic pianos their whole life would say this one is really good while other, of the same background, would say it is a complete steal and would not lay eyes on anything costing less than 2000 dollars. I would say you're good in the $900-$1300 range, and you surely can have a bargain buying second hand. Yamaha is a good pick, but Roland too, in my personal experience. If you know how to play a few chords, the best solution is still to go to a shop and make your own opinion. Digital piano might be as far to real piano as purists claim, but for now the only thing that matters is that it suits you. You'll have all the occasion to be picky in few years, when you're a more experienced player.
2404563	They will probably work out to be the same. An automatic transmission is inherently more complicated which means more can go wrong and usually does (more so than manuals). The increased complexity also makes them more expensive, heavier, less fuel efficient etc. A manual transmission is less complicated which means there is less that can go wrong. Through normal use a manual transmission should far outlive an automatic transmission with regards to absolute lifespan. HOWEVER, a manual transmission requires the use of a clutch which will wear out quite quickly relative to an automatic transmissions life-cycle. If you are not able to replace a clutch yourself (which requires removing the transmission) then you will be paying quite a bit more maintenance on the manual transmission every time the clutch wears out (anywhere from 2-8 years). With the automatic transmission there is less high ticket maintenance required besides fluid flushes. If your automatic transmission dies however then it will probably be at-least $1000 more expensive than the equivalent manual transmission to replace. So it probably depends how long he wants to keep the vehicle and whether he cares about having to replace clutches or is able to do that himself to save money.
2412073	I had a revelation after the manual transmission in my '97 Ford was replaced three times under warranty: Quality is more important than any inherent design advantage of automatic vs manual. As I see it, manufacturers make a lot of automatic transmissions and they put a lot of effort into making them reliable and durable. They don't sell many manuals in the US, so they don't put the development effort into them. As a result, I got a series of bad transmissions until they finally put a stop ship on them, and a couple months later I finally got one that lasted over 100k miles. But even though this one has been "trouble free", it is still somewhat balky and sometimes doesn't want to go into gear on the first try, especially as it gets older. It's really embarrassing when you roar away from the light in first and then can't find second. I see a similar thing with crank windows. Most cars have power windows nowadays, and if you find one that does have manual windows (like my Ford), they're cheaply made and don't wind as smoothly as they used to. I've never worn out an automatic transmission, or a manual for that matter.
2418715	Putting transmission fluid into your engine shouldn't have hurt anything, and as you've found out, may help it a little by cleaning stuff out. Obviously, it's not necessarily a good thing, especially considering if you have too much fluid in the crankcase. It is my opinion you should get the "oil" changed as soon as possible and try not to run it too long. The transmission fluid will not be providing exactly what the engine needs in order to be properly lubricated and you could be causing your engine damage by continuing to run it with the tranny fluid in there. As you've suggested, there is a real chance of blowing out seals due to having too much fluid in the engine. You also run the risk of the crankshaft hitting the fluid which can cause damage to the engine (if this were happening, you'd most likely already know it). Once the fluid is changed (along with the filter), you should be in good shape. Just don't run it too much until you are able to.
188651	I think the key hear is in how the elves are deploying the weapon. If its just a matter of the elves opening a jar and releasing the swarm, after which the insects, which I presume have been trained for this very operation, slide over to Earth space and explode themselves, then I would go for destroying the bugs before they go. If these insects are telepathically directed, then I would either a) try to convince who ever is controlling them that this weapon will toast them too, or b) neutralize their psychic influence. Also, here's a question for the those hear that are more knowledgable in physics: is their anyway to intensify the bugs containment fields, such that the field is so strong that it contains the explosive energy, much like a bottle of compressed gas? Also, if these insects are able to slide between dimensions, is there anyway for humans to "wall off" a strategically important site and prevent such intrusion? If I understand correctly, the elves are in a different dimension. If that is the case, then the "latest intellegence reports" would have had to be generated based off of a) some earth technolgy capable of peering into the Elven dimension, 2) some earth spy actually physically enter the Elven dimension, or 3) an intellegence agency interrogated one of the Elven officers that would know such information, or 4) a defecting elf gave or sold the info to Earth intel If 1) is the case, then technology that can look into other dimensions may be able to block incoming traffic or attack remotely. If 2), then there is obvious earth technology that is capable of opening a door, and thus may be able to close one as well. If 3) is true, then that means individual elves can be beaten, and if the leaders of this weapons launch can be eliminated, it might buy Earth more time or, if security has been that well compromised, even a way to detonate the bugs on the elven dimension. If 4) is true, that means Elves can be bought or moral is not 100% secure. This means that, given the right persuasion, the elves can turn on their military leadership and either destroy the weapon or themselves in the process. Overall though, the humans may be screwed, but there is nothing left to do but try and fight. Giving up only ensures death, or enslavement, what ever the elven object is.
303276	Yes, you roll twice as many damage dice for the spell on a crit The rule on critical hits on page 196 of the PHB says: When you score a critical hit, you get to roll extra dice for the attack's damage against the target. Roll all of the attack's damage dice twice and add then together. Then add any relevant modifiers as normal. Note that this only refers to the attack - it doesn't say weapon attack, or anything else that would mean that this did not apply to spell attacks. When you get a critical hit with a spell attack, you roll all damage dice twice. So a critical hit with the cantrip Fire Bolt would deal 2d10 damage instead of 1d10. A critical hit with the 1st-level spell Chromatic Orb would do 6d8 damage instead of 3d8. And on a critical hit, Guiding Bolt would do 8d6 damage instead of 4d6.
375476	Since the other answers have been written, a card has been released that explicitly allows activating loyalty abilities any time you could play an instant: Teferi, Temporal Archmage from Commander 2014. He's a planeswalker with a relevant ultimate: −10: You get an emblem with "You may activate loyalty abilities of planeswalkers you control on any player's turn any time you could cast an instant." So if you manage to get him to 10 loyalty and activate this ability, you will be able to play loyalty abilities of planeswalkers at instant speed. It's not an exciting combo or abuse of the rules, but it can still be a lot of fun in a slow multiplayer game—exactly what the whole Commander 2014 set is all about! As for activating loyalty abilities multiple times in a turn, that is possible with The Chain Veil. A card first printed in 2015, long after the question was originally asked.
478059	I’d say she had a form of the Shining. I would argue that even Louis had the ability. Both communicated with the dead, and Ellie, as mentioned previously, had premonitions of the events to come. One could also easily look at Louis’ conversations with Victor as Louis’ ability to shine. If we look at The Shining, Danny Torrence was able to: communicate in some form or another with the dead, and Tony was Danny’s older, future self trying to steer him in the right direction to avoid death. Danny also possessed the ability to see the future in some capacity. It’s also arguable that all of the Torrences (at the very least, Jack) had a form of the Shining. It seems to be hereditary in this case if Jack passed it down to Danny. One could also argue that Louis passed it down to his kids. It gets a little tricky with Pet Sematary, however. It’s clearly a little ambiguous as to whether or not the influence of the Wendigo is what is exclusively driving all of our characters toward their collective fates. It influences Judd to show Louis the place, it clearly influences Louis to make the poor decisions he makes, so it could be argued that Pascow is telling Louis exactly what the Wendigo wants him to hear. I believe the Shining is an ability that cross-pollinates into many different King novels, and I believe this to be one of them. My opinion is that Ellie and possibly Louis have the Shine.
788183	Actually, you have a lot of freedom to do it as best pleases you. You could even create an alter ego (as I have here) under which to publish. But there are two constraints. The first is that you probably want to choose a name that you will be happy with over your career, so that people won't get confused by seeing different names from the same author. The second is that you want people to be able to find and connect with you. Mostly that will be via email, I suspect, but if someone calls up your university and asks for you by your public persona name it should be easy to reach you personally. If you just use the name you have used here, few people outside your own culture would even notice and just assume that your "family" name is Sabu. Some names in Western European culture arose in just that way. Others arose from peoples occupation (Taylor and Smith, for example). But people might also want to refer to you as Professor Sabu, rather than Professor Aaron, which you might prefer. But, don't worry that there are conventions that restrict your choices here. Assume that you have control over your own name.
2167722	Most of this is going to come from what I remember from a University assignment a decade ago. There is scientific evidence suggests that a cats purr can aid healing. A cat’s purr frequency is between 25 & 150 Hertz. google the low end is a similar frequency to the one that medical professionals use in vibrational therapies to promote tissue regeneration. Known benefits of a cat purring *Lowering stress — petting a purring cat can calm you *A cat’s purr can decrease the symptoms of dyspnoea (difficulty breathing) in both cats and humans *Lower blood pressure by interacting with the cat and hearing the purring sound *Reducing the risk of heart disease (cat owners have 40% less risk of having a heart attack. Probably because of lowered BP) *Purr vibrations help to heal infections, swelling, bone healing and growth, pain relief, muscle growth and repair, tendon repair and joint mobility
2291814	It sounds like the controller needs to be reset and the remotes reprogrammed. Usually this requires physical access to the opener, but if you have a hardwired remote it might be possible to pair it via the keypad. Check the manual for your opener. But back to the problem of how to open it. If the garage does not have an alternative access there should be a manual cable release which disconnects the door from the opener chain so that you can manually open it. Often this is in the form of a small key near your garage door. With the key you can open the lock and pull the manual release. (source: garage-door-automation.co.uk) If the installation was done correctly, you have one of these you just need to find it. If you don't have the key a locksmith should be able to open it for you. If you do not have a manual release then I think you will have to resort to breaking a window.
61274	The phrase by training basically means the same thing as the expressions by trade and by profession. I would even go so far as to say that they can be used pretty much interchangeably in everyday conversation. When you say that you are a lawyer, an electrician, an engineer etc. by training, this means that you received a formal education (or training) in your particular area of expertise. In other words, saying that you are somebody by training puts emphasis the fact that you are legally qualified to do your job. The opposite expression of by training would be by vocation. A vocation, simply put, is the thing that you actually want to do in life as opposed to what you've been formally taught in school as a profession. Yet another way to describe this situation is to say that although you studied one thing in school, something else has been your calling in life. Examples: I'm a mathematician by trade, but a writer by vocation. I studied math at the university, but have never really worked as a mathematician because I always wanted to be a writer. Even though I studied medicine in college, working as an architect has always been my calling.
193864	Heat drives a compound out of solution Heat can drive moisture out of a substance. If some substance mixed with water is a very viscous fluid, then driving the water out with heat could leave you with a solid. According to various pottery blogs, moist clay is about 30% water, all of which is driven out in the process of firing. A viscous mixture in solution (not necessarily a solution of water) could be heated in such a way as to drive off the solution and precipitate the results. I can think of a real life example of this: dissolve a pen's worth of ink in hair spray. Mixed together you have a black inky goo. When the alcohols in the hairspray evaporate, a hardened black mass is left. The alcohols in hairspray evaporate at room temperature, but just imagine instead a solvent that needs to be heated to be driven off. Chemical reaction at high temperature The second possibility is if the substance underwent a chemical reaction at a high enough temperature and changed into something else that had a higher melting point, then it could theoretically solidify as the temperature went up. Clay doesn't quite undergo this reaction, but it does undergo chemical changes when fired. Clay consists of a variety of minerals the most important of which for pottery are SiO$_2$ and Al$_2$O$_3$, both of which come from feldspars in the clay. Firing the clay burns off organic impurities, and removes the hydrated water and K$_2$O. Increasing the heat still further causes cross-link bonds to form between sheets of SiO$_2$ and Al$_2$O$_3$, forming a compound called kaolinite, which gives pottery its strength and hardness. Conclusion So it is plausible for a material to be heated and change its mechanical properties such that a fluid compound mixture precipitates into a solid material. The caveat is, I can't think of any way this could be a metal, since metal alloys don't form the strong covalent bonds in the clay example. It would much more likely be some sort of ceramic like the clay example. The other big caveat is that neither process is reversible. If you drive off a solvent with heat, then cooling down the resulting substance will not turn it liquid again. In the hairspray-ink example, you could re-dissolve the black mass by soaking it in rubbing alcohol, but it would take a long time (unless you ground the mass into powder first). Same with the clay example, cooling down the clay gives you hardened pottery, not lumps of crumbly minerals.
345977	If you want to base your D&D vision off Tolkien, of note is that two Elves in his works did have beards: Círdan the Shipwright: Círdan had a beard, which was rare for Elves, and silver hair like Thingol his overlord and kinsman. He was of great age at the time of the War of the Ring: perhaps the oldest of the Telerin Elves or even of all the elves remaining in Middle-earth. He may have been one of the elves who awoke near Cuiviénen and therefore without a mother or father. and Mahtan Urundil: Mahtan had a beard, which was unusual for an Elf, especially one as young as he. Elves could only grow beards from the third cycle of their lives, while Mahtan was an exception in being only early in his second. These both describe beards on elves being exceptionally rare, as very few elves are old enough, even at thousands of years. But it doesn't say it was impossible, only rare. It seems to me that if only one in a thousand elves had beards, it would be "common knowledge" that none could grow them. You can still make the item as obnoxious as you want working around descriptive limitations or descriptions in the PHB. Elves might not be able to grow beards or moustaches, but what about sideburns? Eyebrows? Eyelashes? Nose hair? Ear hair? Have the same volume of hair grow that would fill out a dwarven beard, but since there are so many fewer follicles, have the above grow to something absurd like 9 feet long. Additionally, have an NPC (or PC) who's not too fond of your elf player meticulously collect the hairs after they're cut off and continuously craft clothing out of it. This would also be a good reason why the Belt was "lost" or considered "cursed" in the first place--dwarves aren't likely keen on eyebrows to the floor instead of a beard either.
370699	Literally just played a game in which one of the stacks (the one containing 4 cards) was lead by the 9 of diamonds, and the cards inside of it were the King of Spades, the 5 of diamonds, the 10 of spades, and the 10 of clubs (I know this because I had the entire field solved except for this stack and used process of elimination). As far as I can see this makes the game impossible. I have a 9 of diamonds in which can never be moved, as the two 10s that it's eligible to rest upon are trapped underneath it in the stack face down. Attempting to get rid of the 9 by moving it to the diamond stack would also be fruitless, as the 5 of diamonds is stuck underneath it too. Unless someone can tell me some way that this could be solved, I'm pretty darned certain that if a card that is leading a stack is covering a stack that contains the two cards it is capable of resting on, and a lower number of it's own suit, then the game is made impossible right from the get-go.
398590	Angel's hair style is simple and no mirror is actually needed. I carry the same style and have for over 10 years. Shaving by touch is easy for a man, especially a man with a vampire's healing abilities in case of a wee nick, and Angel probably befriends a barber in town and pays extra for an after-hours, no mirror, no questions asked haircut. Also it is shown in flashbacks that Angelus had a moustache and long hair and Angel had a mullet in the 80's so they must grow hair. Just a quick mention, in After The Fall (the official continuation of Angel by IDW comics before Dark Horse got the licence and continued it with Angel and Faith), he does mention that it is hard learning to shave again as a human so that implies he didn't need to shave as a vampire, but I take any universe based continuity from those comics with a pinch of salt as Joss was not directly involved.
457614	The Faceless Men obviously have access to some kind of magic: When they wear a face their physique/body and voice changes as well. They can preserve the faces in the hall without rot. With that in mind it is easy to assume that a fully trained Faceless Man could have a stronger connection to the magic and be able to use faces of those that are still alive. As @Skooba puts it so well on his answer to a related question on MTVSE I'll quote some of it here: Jaqen seems to be the leader of the group. This would imply he has a greater or direct interaction with the many faced (similar to how R'hollor will "speak" through the Red Priests). While the extent of this is not fully defined, I believe this example proves this point. We could also speculate that because of this it appears he may even be able to use any face he wants and not just those of the dead. A few other speculations as to how it worked: Arya was "drugged" and so it was actually just an hallucination. When Arya joined the Faceless Men, even though not one of them yet, she donated her face, though subconsciously. This can also explain why The Waif appears to have Jaqen's face on underneath in the same scene. So any Faceless Man's, recruit or otherwise, face is available to all. As for what it means, well that's opinion based: She's been accepted into the Faceless Men. She's been offered up to the Many Faced God. etc. Overall you're not supposed to question the How's and the Why's... It's magic.
939081	I have used express invoice for a year now, and it was great until developed a bug. I was on the internet for days trying to figure out this bug, that I discovered other users also encountered. No solution was working including an upgraded download. I would have bought the paid version but was wary considering their support policy. Try contacting this company for anything..they make it very very difficult. There is actually no way to contact the company unless you purchase support. First two levels of support cost 40 and 57 dollars US and only entitle you to a very limited amount of emails from support...and they will only spend 10 minutes on each email. I chose the platinum support, 9 -10 minute emails and two 15 minute phone calls only from 9 to five for 63 bucks US, I must use them all over a three month period or I lose what I have bought and the cheaper support pkgs. Are even shorter in terms of access. So far, I have paid and they are already past the 24 hour turnaround time promised for a response. They also make you agree to no refund even if they do not fix your problem. Buy at your own risk, this company has blatantly decided to make support a frustrating endeavor for their users.
1236302	Is a way to open and access the cropped version of the image or other information in the .AAE file? .aae files are only used by iOS and OS X 10.10+. They can be viewed by a text editor to see what edits were made to the photo, but won't allow you to access the modified photo in Windows. An AAE file contains edits made to an image using the Photos app on an iOS device. It is used to transfer non-destructive edits a user has made to .JPG images in iOS to the macOS system. AAE files can be found accompanying the images for which they contain edits. More Information AAE files are used by iOS 8 and later and OS X 10.10 and later. If you import pictures from an iOS device to Windows, the JPEG images will only get transferred and not the AAE files, which will cause you to lose your edits. Also, AAE files can be deleted without erasing your pictures but any edits made to them will be removed. The AAE file is referenced by the Photos app when opening the JPG file in which it is associated. It can also be opened by text editors such as TextEdit and Notepad to view the edits made to the corresponding photo. Source .AAE File Extension So how can I access the modified photo on Windows? Use any other photo editing app on your iOS device. Open the app and import the photo in it, and then save it again without making any changes. The only thing you need to be careful of here is that the app you use doesn’t add a watermark and that it doesn’t compress the photo, or crop it. You’re obviously going to want a free app in this case so we recommend Snapseed by Google or Darkroom by Adobe. Both let you save a copy of a photo without having to make single change to it. Once you’ve saved a copy, simply connect your phone to your PC/Mac and copy it from the device’s storage like you would any other photo. Source How To Import A Photo Edited On Your iPhone To Your Computer
2295908	The neutral and ground MUST NOT be bonded at a sub-panel. They should only be bonded at the main service panel. If you bond them anywhere other than the main service, the neutral return current now has multiple paths, including though your ground wire. You should be able to buy a second bar for the sub-panel if it really is meant to be used as a sub-panel. The neutral bar will need to be isolated (it should have plastic insulator separating it from the case). The ground bar should be bonded to the case. The ground wire from the house must be connected to the sub-panel ground. Since it is a detached building the ground rods are also required by code and should be tied to the sub-panel ground. The ground to the service is the most important because it will provide the low resistance path back to the service in case of a fault.
155949	Disclaimer: My science levels are all over the place so this may not be 100% accurate. I'm specifically concerned about my first paragraph which is a alternative interpretation of Gödel's Incompleteness Theorems. It takes a different view on the matter, one that I feel is correct but am not certain of. I added a second concrete example to illustrate the thought process. Slightly unrelated is Turing's Proof which rankles me and may be related to decoding the universe. See Note2 for an argument on Turing's Proof that I way more certain of than I am of my argument on Gödel. Our current math theorems only tells us that we can never have a complete system in the sense that we can never know with certainty that our axioms and such are complete, etc. But this rides on the assumption that the parts our math doesn't allow us to grasp aren't the ones that override this assumption. (Our current axiom set roughly says "You can't have all the rules because you can't logically get to some of them, no matter what set of axioms you pick" but there may be a rule that we have to hit by chance or take on faith, since we can't get to it logically by our current axiom set per Gödel, that translates out to roughly: "Disregard all other rules. The last axiom of math is the 5th item on your shopping list on every billionth day. Just take my word for it."). Like all science we may discover that we need to rewrite the axioms when we hit new areas of math. This could open the way to us discovering the true set of axioms that explains all (if they exist). That is, by virtue of logic failing we could potential be forced to have our minds wander until we hit the right answer by chance (which sounds a lot like the current state of affairs for our current search for a ToE). A good example for the possible last axiom (well, maybe for a moral system and not a mathematical one) would be the rule: "Everything is a grey-area of some extent, there are no black and white rules." which seems decent if you can apply it to just about everything. But when you get around applying that rule to itself it becomes a statement of "Sometimes things are black and white, because this rule is a grey-area itself." So do you edit it to "Everything is grey except for this rule." or do you take it as it stands or do you toss it completely. The right course of action seems difficult. Assuming that this is one of the true axioms of the universe the two framings have different outcomes: strict rules with a loophole written in (that may or may not be exploited by the universe at any given moment), or with exceptions only for themselves. Either way its status as an axiom relegates it to the "take it on faith" principle which in the case of this self-paradoxical rule is a little harder to swallow that 1+1=2. So even if the universe is deterministic to a fault we would most likely need a lucky guess or a change in mathematics to get all the rules right. It could be that even without perfect rules we could move towards a snapshot of the universe at time T. Our certainty would never reach 100% but we could get very very close. If your predicting the future accurately left and right though, then you pretty much don't care if you're 100% right, you might just assume you are spot-on which is basically what Bayesian statistics would tell you. Sure you missed that thing-a-ma-what's-it axiom, but that only causes a simulation glitch once every billion years... Do you care? If the universe is boot-strappable from a small set of data and has implicit T states, then we could operate on all of this data and recreate a time-location-state(which is what you're asking, so this is the caveat). The simulation could even reduce as far as a random seed number. This may be a number with only finite possibilities. We could test the parameters until we reached one that modeled our current T value correctly. This would get us to the point of modeling the universe without violating the Heisenberg Uncertainty Principle or any other building blocks. If the universe fails any of these assumptions (is not deterministic, etc.), then our math can give us possible futures with error measures. You could extract information as long as your signal-to-noise ratio for the universe was relatively decent. Non-implicit universes would have diminishing returns on the signal over time and increased noise (which would model our heat as information loss perfectly!). Note: Figured I'd add that our current science makes the needed assumptions when it assumes to know the effects of the constants on the universe. "Our Constants are so finely tuned it must be the work of an intelligent design". What gets more in the way is the problem of storing a given snapshot of the universe so that we can compute on it. If there isn't a small boot-strappable data set then it can't be done. There are various physical effects that operate as a whole and not additively, so you would need an atom to record all the information about that atom, etc. resulting in the universe. Otherwise you'd need a frequent snapshot of the area of interest to work off of. If you could acquire a frequent snapshot of an area there becomes little need to forecast very far ahead which reduces the error we can have in T+1 allowing more inaccurate rules. (Our weather forecasting is an example. Snapshots of poor detail are acquired and a simulation plots out 7 days. Days closer to the start of the simulation are more accurate. Increasing resolution, simulation frequency, or computing power increases accuracy overall). Note2: So this isn't directly related except for the fact that if I'm right all of a sudden we can compute Chaitin's Constant which will probably give us a decent platform to create our boot-strappable data set (it also flirts with violating Gödel's Incompleteness Theorems)... So Turing's Proof has always rankled me because it amounts to saying "If you give me a program H that computes Halt() I can give you a program B that always invalidates H" the problem is that his formulation involves B containing H which amounts to saying "I can construct a wrapper function/super-set to H that invalidates it" so the implicit assumption is B is always bigger than H. You can in fact (I wrote a proof) construct an H that uses B to expand itself recursively. This makes sure H is always able to get the correct solution for Halt() as long as H is at-least 1 bit larger than B. If you extend this out to infinity then technically Turing's Proof is right because both H and B will end up at the same infinite size and we can't decide when their the same size (at-least my function can't, although it would be possible if you made a quantum extension of my algorithm (but that may give B new tricks of subverting H as written)) so we end up with an infinitesimal fraction of all programs that are undecidable. But that just means your constant has an infinitesimal error and so is still usable for our purposes. Edit2: Oh yeah your questions... How precise of an estimation could we get of the future? It depends, see the other answers. Can a weather forecast for the next day be 100% reliable? I'm pretty sure we can already do this, we just don't run them every day. It's run the minimum amount of times for tolerable accuracy because weather "people"/stations pool money to run a simulation on a supercomputer (or they did anyway...) Can we answer questions like "if hitler had died as a kid" with 100% reliability? If we achieve exactly 99.999% accuracy in our rule set for time-steps of 1 yr (noting we'll never reach 100% unless we just take it on faith and it turns out to actually be our magical rule set) and get a perfect snapshot today (2014) then your looking at 99.874% accuracy on our Hitler predictions. So no, not 100% at that point but pretty damn close. How much further could we predict from T, with good accuracy, knowing that there is randomness? Well if you compute Chaitin's Constant for your universe you can actually predict your randomness given enough bits of information (this is exactly the same as predicting the seed of a random number generator given x bits where Chaitin's is your seed and the rule set is the generator. You tweak things snipped long explanation until your correct and then randomness doesn't matter). If we take the other track and assume you can't then you have the same situation as for the Hitler situation. The perfection of your rule set determines how close you can get. You multiply the accuracy every time-step (so starting with .999999999999 you lose 1 off the least significant digit each step and there are Z steps each second which is at least the speed of light divided by the number of planck lengths in a meter in magnitude (so 1.855492(18) x10^43) which means for an accuracy to the 12 decimal place you lose at least (.999999999999 accuracy to the 2 x10^43 ticks/sec to the 31600800 sec/yr) .2% accuracy each year (I think I did that right...)). So if we place our limit for good accuracy at 90% then we have 50 years.
402928	Not only was Melkor given the greatest gift of power and knowledge of all the Ainur, he also shared in all the abilities of all the others. The Ainur were said to know only the part of the mind of Ilúvatar from where they came, and so he was closest in all things to Ilúvatar himself. Perhaps this is why he was not as content with merely expounding the theme of Ilúvatar.. To the question of why he was tolerated: “[Ilúvatar: ] 'Seest thou not how here in this little realm in the Deeps of Time Melkor hath made war upon thy province? He hath bethought him of bitter cold immoderate, and yet hath not destroyed the beauty of thy fountains, nor of my clear pools. Behold the snow, and the cunning work of frost! Melkor hath devised heats and fire without restraint, and hath not dried up thy desire nor utterly quelled the music of the sea. Behold rather the height and glory of the clouds, and the everchanging mists; and listen to the fall of rain upon the Earth! And in these clouds thou art drawn nearer to Manwe, thy friend, whom thou lovest.' J.R.R. Tolkien, The Silmarillion. (To which Ulmo responded that he had neither anticipated rain nor conceived of snow).
402987	No. As is demonstrated many times in the series, if there is bloodlines to work out, people will tend to do that to find out who the heir is, for example: The complex Arryn family tree ends with Harry the Heir The Frey constantly argue about their lines of succession There are also examples when people just take what they want with physical force or general consensus, such as the dothraki and ironborn, or the wildlings. Or in a rather general way, the way Robert took his throne, and Renly tried to, by combination of both. A convoluted bloodline has also been the Blackfyres' biggest motivation. I believe that there will always be heirs to be found in major houses. You might have to go back through the generations, but I doubt very much that anyone would ever resort to such generic family ties as those between Stark and Karstark. If no "direct" blood relative could be found, whatever the king or ruling house in the north would probably decide who takes over Winterfell. And anyone who takes Winterfell without the support of the North would probably sit rather insecurely on their lordship.
448692	I know I'm late to answer this but I think the answer to that might be more meta in nature. Perhaps the reason why Clint was not entranced by Wanda's magic is simply because the Hawkeye character, as far as the MCU goes, has very little development in his past. I.e. there's nothing really to show the viewers if Wanda were cause him to hallucinate. Aside from the Avengers context we know little about Clint. And I know you might say the same thing for Natasha / Black Widow, but she's a bit more fleshed out as a character in spite of not having her own movie to show flashbacks to. Clint is the perfect candidate to stop Wanda but also be easily stopped by her brother and whose omission of their past is inconsequential to the viewer. As well he also filled the role of being the guy to pilot the ship back and provide a safe haven for the Avengers when they retreat with their tails between their leg. Had he been affected to, there might not have been that opportunity. His private life was a good plot device.
843926	The inclusion of the word stochastic simply means the random samples from the training data are chosen in each run to update parameter during optimisation, within the framework of gradient descent. Doing so not only computed errors and updates weights in faster iterations (because we only process a small selection of samples in one go), it also often helps to move towards an optimum more quickly. Have a look at the answers here, for more information as to why using stochastic minibatches for training offers advantages. One perhaps downside, is that the path to the optimum (assuming it would always be the same optimum) can be much noisier. So instead of a nice smooth loss curve, showing how the error descreases in each iteration of gradient descent, you might see something like this: We clearly see the loss decreasing over time, however there are large variations from epoch to epoch (training batch to training batch), so the curve is noisy. This is simply because we compute the mean error over our stochastically/randomly selected subset, from the entire dataset, in each iteration. Some samples will produce high error, some low. So the average can vary, depending on which samples we randomly used for one iteration of gradient descent.
2380370	Yeah, it's like overkill if you're riding on the street. I use a Busch & Muller lamp powered by a dynamo hub and it puts out plenty of light even when riding downhill on potholed roads. Also keep in mind lumens is only one factor in determining light quality. It's sort of like having a computer with a fast processor but not enough memory. More important are the actual optics which disburse the light. A lot of lights - even really expensive ones - come with nothing more than a plain lens on them which means a lot of the light they put out isn't lighting up the ground in front of you. No point in having 750 lumens if most of it doesn't illuminate the ground in front of you. Peter White has some good examples of how important beam pattern is in determining how good a light is in the real world: http://www.peterwhitecycles.com/headlights.asp Another problem is where the light is mounted. A powerful light mounted up high (helmet or handlebars) can wash out the terrain making it tricky to spot a pothole. There's a reason why randonneurs - who often ride throughout the night - prefer to mount their lights lower (usually on the fork) If people are wincing when you approach then your light is almost certainly aimed too high.
257385	Cube or rectangular The shape will depend on a lot of factors, so I will make some assumptions. I am assuming you have artificial gravity, so no need for long rotating cylinders or donut shapes. I am assuming that the shape has no influence in space due to speed or ftl travel. Since it is built in space I assume some standard manufacturing. This is quite important since one-offs space ships can be completely different. The most efficient way of constructing large objects is quite often modular. You can have a lot of factories creating modular modules which will be coupled together to create a spaceship. Modules will probably be rectangular in certain sizes for easy assembly. Basically you would stack them like cargo containers. They would also be rectangular since flat surfaces that you can screw together are much easier to make than rounded surfaces. That goes for the outside, but also for all machinery on the inside. In the real world, things are usually rounded only for function or aesthetics. In the case of aesthetics most machines on the inside are quite square. If for some reason you would need a sphere shape, for less outer area compared to volume you would probably only make the outer shape spherical, much like rounded office buildings. As a last remark, for slower than light colonial ships I believe hollowing out asteroids (or clomping them together depending on the wanted size) and covering them in a thick sheet of ice as protection for interstellar radiation would be most efficient.
372106	There used to be a long shot that could make this happen: You start by playing the Mycosynth Lattice which turns all your permanents into artifacts, including planeswalkers. Then you play March Of the Machines, turning your planeswalker into an artifact creature with power and toughness equal to its casting cost. Then you use the ability of an Experiment Kraj to put a +1/+1 counter on the planeswalker artifact creature. Now since the planeswalker artifact creature has a +1/+1 counter on it, the Experiment Kraj can use all of the activated abilities of the planeswalker without any of the restrictions of a planeswalker. Sadly since the time of that post they have extensively written into the rules that there is no way to use a loyalty ability of a permanent in any way other than a sorcery and it can only be used once per turn. 209.2. An activated ability with a loyalty symbol in its cost is a loyalty ability. Loyalty abilities follow special rules: A player may activate a loyalty ability of a permanent he or she controls any time he or she has priority and the stack is empty during a main phase of his or her turn, but only if none of that permanent's loyalty abilities have been activated that turn. See rule 606, "Loyalty Abilities." 606.3. A player may activate a loyalty ability of a permanent he or she controls any time he or she has priority and the stack is empty during a main phase of his or her turn, but only if no player has previously activated a loyalty ability of that permanent that turn. To date with the exception of copying an activated ability, there is no way to use a loyalty ability more than once and you can never use them at a time other than when you could cast a sorcery, because they have restricted the use of the loyalty ability itself, not just the way a planeswalker specifically uses them.
1987437	This is a tough problem. I think the easiest method would be to prepare a hard disk with a completely configured OS and just ship it to the remote location and have them install it into this machine. After all, this is not rocket science and can be done by untrained people with proper directions. If that's not possible, you will need at least the possibility to add some statements to the DHCP server (next-server and filename) for this machine to allow booting via PXE from the linux server, and a static IP address for the machine from the DHCP. After that, I would try to boot a live system via PXE and use it to download an image of an installed system and drop it onto the disk with dd or something similar. It should also be possible to prepare a kickstart file for CentOS (or Fedora) that allows to completely install a system without any interaction (via PXE), but getting this right will take a lot of time.
2188979	It is very important to keep water and temperature in balance in a compost heap. The bacteria need water to assist the decomposition process, but too much water will slow down or stop the process completely. Water should be added little and often, but only as necessary. A handy tool for compost is a thin slightly rusty iron rod about 4 feet long. Shove the rod into the pile using your best rapier thrust technique, and as you do this feel the consistency of the materials it passes through. Maybe you feel twigs and other hard stuff, maybe it is consistently smooth and open. Push in as far as it will go and pull it back out, and inspect the surface of the rod for signs of dryness or physical water. Then put the rod back in and leave it there for half an hour, then withdraw again and feel the temperature of the rusty rod, getting your hands nicely dirty and feeling the quality of the compost it passed through. If your hands get really smeary dirty the pile is probably too wet already and needs drying out and rebuilding. If the rod feels cool or only slightly warm then the engine is not running. Maybe it has finished decomposing, or it's time to rebuild the heap, moisturizing, but not wetting, as required. Buckets of water are only required if the pile is running really hot and shows a dry rod test.
2380374	Yes. Blinding oncoming traffic is certainly not in your best interest. Operating multiple running lights like you see on a semi truck would be better than purchasing a high power front or rear facing light. A brighter rear red light, with a touch of blue for colorblindness like stoplights have, is good to see you from behind. A more powerful front facing light will generally not increase reaction time of oncoming traffic. Drivers will have to make out your shape to influence reactions. While the oncoming driver is blinded, you are reducing the time they have to ensure your safety. To explain the point people are making here. Imagine a house at the end of a dark street. The home owners point the super bright lights towards oncoming traffic. Drivers are unlikely to make out the fact there is a house because of the high power lights and the property is suffering traffic damage. When the owner finally turns the lights around towards the home, blinding drivers was then stopped and the shape of home was made out at a much further distance allowing safe traffic to resume. So definitely have your headlight. Just keep it dim enough where it is comfortable for you and everyone else to look directly into and aim it properly. If it blinds you, you bet it's going to blind traffic. Increasing lumens of an already good light will not increase your safety. It might, however, make you a target if they are airplane runway bright. If your friends are saying it is too bright, you should pay attention to them.
59172	All three of your sentences are grammatically well-formed, but they mean different things. I wasn't able to ride a bike until I was 20 means that you learned how to ride a bike when you were 20—before that you could not ride a bike. I was able to ride a bike until I was 20 means that before you were 20 you were able to ride a bike but at that age something happened—perhaps you lost a leg!—after which you were no longer able to ride a bike. I had been able to ride a bike until I was 20 describes the same sequence of events of facts as 2., but is used when your current topic is a past situation—some time before the present but after your 20th year. For instance: When I was in graduate school some years ago, a friend invited me to go on a bicycle trip. I had to decline; I had been able to ride a bike until I was 20, but in my junior year I was in an accident that messed up my ankle. The preposition until designates a timespan lasting up to the timepoint named by its object, and ending at that point.
435302	Well it really depends on the writer. In some i rember one time vs anti moinitor (not sure if that was spelled correctly) he had run 10 times the speed of light straining every muscle he had. In the CW tv series he tops off around mach 2. And the trillion times the speed of light the writer also said it was a hair under the speed of light. The writer got the math wrong. Anyways the point is Barry is faster than light in most situations but how much faster varies on the writers and in the tv show he tops off around mach 2 and even in the show he has feats which show him going much faster. For example when he saved Harrison Wells from a bolt of lightning. He was running 3-4 times the speed of the lightning. Lightning travels on average 220,000 mph. Much slower than light but much faster than mach 2 which is around 1500 mph
598016	I am adding to some good answers here that I gave upvotes to. I think there is a little more that should be said to completely clear up the conclusion. I like the terms accurate and correct as Efron defines them. I gave a lengthy discussion on this very recently on a different question. Moderate whuber really liked that answer. I will not go to the same lnegth to repeat that here. However to Efron accuracy relates to the confidence level and correctness to the width or tightness of the interval. But you can't talk about tightness without considering accuracy first. Some confidence intervals are exact those are accurate because they have the actual coverage that they advertise. A 95% confidence interval can also be approximate because it uses an asymptotic distribution. Approximate intervals based on asymptotics are for a finite sample size n not going to have the advertised coverage which is the coverage you would get if the asymptotic distributionwere the exact distribution. So an approximate interval could undercover (i.e. advertise 95% when its actual coverage is only 91%) or in the rare but less serious case overcover (i.e. advertised coverage is 95% but actual in 98%). In the former case we worry about how close the actual coverage is to the advertised coverage). A measure of closeness is the order of accuracy which could be say 1/√n or 1/n. If the actual confidence level is close we call it accurate. Accuray is important with bootstrap confidence intervals which are never exact but some variants are more accurate than others. This definition of accuracy may be different to the one the OP is referring to but it should be clear now what Efron's definition is and why it is important to be accurate. Now if you have two methods that are exact we can prefer one over the other if for any confidence level it has the smaller expected width. A confidence interval that is best in this sense (sometime called shortest) would be the one to choose. But this required exactness. If the confidence level is only approximate we could be comparing apples and oranges. One could be narrower than another only because it is less accurate and hence has a lower actual coverage than its advertised coverage. If two confidence intervals are both very accurate or one is exact and the other very accurate comparing expected width may be okay because at least now we are looking at just two two varieties of apples.
1388942	A Schmitt trigger inverter is a bad idea for the first inverter which is driving the crystal directly. It may not even oscillate at all as shown, or oscillate at some undesired frequency. Note resistor R1. That is supposed to bias the inverter as a linear amplifier close to the middle of its output range. The little bit of noise generated by the inverter will be filtered by the crystal so that the part of the noise at the crystal frequency makes it back to the input of the inverter with a phase shift. It gets amplified by the inverter, filtered thru the crystal again, etc. Eventually oscillations build up to a steady level, which can take 100s of cycles or more. This assumes the first inverter is roughly a linear amplifier. A Schmitt trigger makes it highly non-linear. It will introduce frequencies of its own, and possibly overdrive the crystal. Crystals are highly tuned filters, but giving them crap to filter is not going to result in good frequency accuracy, and may allow for stable oscillations at other than the desired frequency. The second inverter being a Schmitt trigger does make some sense. The first inverter really produces a analog signal. It will be more of a sine wave than a square wave, and probably not full rail to rail amplitude. Normally, amplifying and clipping this by running thru another inverter is good enough. The Schmitt trigger should make the digital output signal a little cleaner. Usually Schmitt triggers aren't used in crystal drivers. This is because they can't be used for the first inverter, and it's easier to use multiple inverters on the same chip. The 74HC04 you mention has 6 of them on a chip, for example. Again, most of the time following the first stage with just another inverter gets you a good enough square wave. If you really need fast edges and the crystal frequency is low, then a Schmitt trigger can help. You can still do that with a 74HC04. I'd use one inverter to run the crystal, a second just as a buffer, then two with a little DC feedback around them to make the Schmitt trigger. The reason that takes two inverters is that you need positive gain. Here is what I'm talking about: Again, for many applications the output from IC1B will be good enough. Note also that this circuit requires a parallel resonant crystal. This means its frequency is specified where the phase shift is right for feedback around a amplifier with negative gain. A series resonant crystal will work but the frequency will be off a little.
553754	the number of elements in a particular period is equal to the number of vacant orbitals available to be filled in the particular shell this also follows the n+l rule according to the energies of the orbitals. Coming to first period in the first shell only one sub shell is there which is 1s and two electrons can be successively filled hence two elements are present in the first period. Second shell has two sub shells 2s and 2p which have a total of four orbitals hence eight electrons can be successively filled in the four orbitals and hence 2nd period has eight elements. The third shell has an exception due to energy considerations because of the n+l rule though the third period has three sub shells 3s , 3p and 3d and total of 9 orbitals i.e one 3s orbital three 3p orbitals and five 3d orbitals but because 3d orbitals can be filled only after 4s orbitals due to the n+l rule only four orbitals are available which are the one 3s and three 3p orbitalshence eight electrons can be successively filled and hence eight elements are present in the third period. the fourth shell has similar story with four sub shells 4s 4p 4d and 4f but because of the n+l rule or the madelung energy ordering rule 4d orbitals are filled after 5s orbitals and 4f orbitals after the 6s orbitals but here the 3d orbitals are also available to be filled up so a total of 9 orbitals i.e one 4s three 4p and five 3d orbitals are available the next periods follow suit and things happen in a similar manner . Hope it helps .
